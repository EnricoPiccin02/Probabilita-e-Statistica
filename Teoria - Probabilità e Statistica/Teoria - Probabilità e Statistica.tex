\documentclass[a4paper]{extarticle}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\selectlanguage{italian}
\usepackage[table]{xcolor}
\usepackage{xcolor}
\usepackage{circuitikz}
\usetikzlibrary{positioning, circuits.logic.US}
\usetikzlibrary{shapes.geometric, arrows}
\usetikzlibrary {shapes.gates.logic.US, shapes.gates.logic.IEC, calc}
\tikzset {branch/.style={fill, shape = circle, minimum size = 3pt, inner sep = 0pt}}
\usetikzlibrary{matrix,calc}
\usepackage{multirow}
\usepackage{float}
\usepackage{geometry}
\usepackage{tabularx}
\usepackage{pgf-pie}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color, soul}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{subfig}
\graphicspath{ {./img/} }
\newtheorem{theorem}{Teorema}[section]
\newtheorem{corollary}{Corollario}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

% Specifiche
\geometry{
 a4paper,
 top=20mm,
 left=30mm,
 right=30mm,
 bottom=30mm
}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LO]{\nouppercase{\leftmark}}
\fancyfoot[CE, CO]{\thepage}
\addtolength{\headheight}{1em}
\addtolength{\footskip}{-0.5em}

\newcommand{\quotes}[1]{``#1''}
\renewcommand\tabularxcolumn[1]{>{\vspace{\fill}}m{#1}<{\vspace{\fill}}}
\renewcommand\arraystretch{}
\newcolumntype{P}{>{\centering\arraybackslash}X}

\title{\textbf{Università di Trieste\\ \vspace{1em}
Laurea in ingegneria elettronica e informatica}}
\author{Enrico Piccin - Corso di Probabilità e Statistica - Prof. Marco Barchiesi}
\date{Anno Accademico 2021/2022 - 3 Marzo 2022}

\begin{document}

\vspace{-10mm}
\maketitle

\tableofcontents
\newpage

\noindent
\begin{center}
  3 Marzo 2022
\end{center}

\section{Introduzione}
Si supponga di stare in un \textbf{universo deterministico}, ovvero tale per cui tutto ciò che accadrà in futuro è determinato dalla situazione nel preciso istante in cui si sta vivendo.\\
Dal punto di vista fisico, si supponga di voler analizzare un certo fenomeno, a patto di conoscere
\begin{enumerate}
  \item la legge che regola tale fenomeno
  \item i dati iniziali (riferiti allo stato iniziale del fenomeno)
  \item le condizioni esterne al fenomeno oggetto di interesse
\end{enumerate}
è sempre possibile predire quello che accadrà nel futuro relativamente al fenomeno oggetto di studio.

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri il \textbf{lancio di un dado}. Taluno è un fenomeno oggetto di studio e, come tale, deve essere analizzato conoscendo
\begin{enumerate}
  \item la legge che regola il fenomeno: la legge di caduta dei gravi
  \item i dati iniziali del problema: peso del dado, altezza inziale, forza di attrazione gravitazionale, etc.
  \item le condizioni esterne: vento, umidità, stabilità dell'aria, etc.
\end{enumerate}
Naturalmente, attraverso queste informazioni, è possibile predire il comportamento del dado: quando esso viene lasciato, cade e si schianta al suolo.\\
Tuttavia, se ora si volesse anche sapere su che faccia il dado atterrerà, non si ha a disposizione un legge fisica che ne regola tale fenomeno, in quanto la legge di caduta dei gravi presuppone il corpo come puntiforme; inoltre il movimento dell'aria influenza significativamente la rotazione del corpo.\\
Pertanto, per la determinazione dell'esito di tale fenomeno, non si hanno a disposizione informazioni sufficienti: non si conosce la legge che regola il fenomeno, i dati iniziali sono scarsamente influenti e le condizioni esterne sono troppo variabili. Ciò fa sì che l'output finale di tale fenomeno sia completamente sconosciuto, in quanto l'evento oggetto d'analisi è totalmente \textbf{casuale}, o più propriamente \textbf{aleatorio}.\\
Si noti, ovviamente, che anche per fenomeni apparentemente facili da predire, le condizioni iniziali che vengono poste per lo studio degli stessi comportano sempre un margine di incertezza e, quindi, di aleatorietà: non si può sempre sapere con precisione assoluta lo stato iniziale del sistema oggetto di studio.\\
Per cercare di far fronte a tale incertezza si può
\begin{itemize}
  \item impiegare una legge molto più particolareggiata (più vicina alla perfezione) che regola il fenomeno interessato; misurare con maggiore precisione i dati iniziali e definire con più raffinatezza le conidizione esterne; tuttavia, tale procedimento comporterebbe un lavoro molto oneroso e scarsamente proficuo;
  \item cercare di capire quali sono i possibili output del fenomeno (ossia le $6$ facce del dado) e associare a ciascuno di tali output un valore che fornisca un'informazione di carattere quantitativo in riferimento alla possibilità che esso sia l'effettivo output del fenomeno interessato.
\end{itemize}
Da quest'ultima alternativa segue la definizione di \textbf{probabilità}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{PROBABILITÀ}}\\
    \parbox{\linewidth}{La \textbf{probabilità} è un modo per \textbf{quantificare} quanto un possibile risultato sia \textbf{facilmente ottenibile}.\vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri il ancio di un dado a $6$ facce e si prendano in considerazione dei possibili risultati
\begin{enumerate}
  \item esce il numero $6$
  \item esce un numero pari
  \item esce un numero $\leq 6$
  \item esce un numero $\leq 4$
  \item esce un numero $\geq 7$
\end{enumerate}
Si capisce facilmente come il primo risultato (o evento) sia molto elementare, in quanto prende in considerazione una sola faccia del dado, mentre i restanti sono dei risultati (o eventi) più complessi, che si ottengono tramite aggregazione dei risultati elementari.\\
Dal punto di vista matematica, per l'analisi di questo fenomeno, si definisce un insieme $\Omega$ dei possibili risultati elementari del lancio di un dado, ovvero
\[\Omega = \left\{1,2,3,4,5,6\right\}\]
Naturalmente, ora, i risultati che sono stati esposti in principio non sono altro che dei \textbf{sottoinsiemi} dell'insieme $\Omega$ appena definito, come mostrato di seguito:
\begin{enumerate}
  \item \(A = \left\{6\right\}\)
  \item \(A = \left\{2,4,6\right\}\)
  \item \(A = \left\{1,2,3,4,5,6\right\} = \Omega\)
  \item \(A = \left\{1,2,3,4\right\}\)
  \item \(A = \varnothing\)
\end{enumerate}
Per attribuire a ciascuno di tali risultati un valore quantitativo che ne descriva la possibilità di verificarsi, si definisce $p = p(A)$ come la \textbf{probabilità associata al risultato $A$}, ovverosia un numero all'interno di una scala che, per convenzione, viene indicata nell'intervallo $\left[0,1\right]$, che quantifica la facilità con cui il risultato si presenta.\\
Per esempio, la probabilità che esca un numero maggiore di $7$ nel lancio di un dado a $6$ facce è ovviamente nulla, in quanto a tale evento viene associato l'insieme vuoto. Questo significa che tale risultato (o evento) è \textbf{impossibile}, pertanto si assegna ad esso un valore di probabilità di fondo scala, ovvero
\[p(\varnothing) = 0\]
Analogamente, la probabilità che esca un numero minore o uguale a $6$ nel lancio di un dado è ovviamente massima, in quanto a tale evento viene associato l'insieme $\Omega$ stesso. Questo significa che tale risultato (o evento) è \textbf{certo}, pertanto si assegna ad esso un valore di probabilità di fine scala, ovvero
\[p(\Omega) = 1\]
È facile capire che se si considerano due eventi a cui sono associati due sottinsiemi $A$ e $B$ disgiunti, tali per cui $A \cap B = \varnothing$, allora si avrà che
\[p(A \cup B) = p(A) + p(B)\]
Inoltre, se il dado è regolare, ha senso ed è plausibile associare lo stesso valore di probabilità a ciascuno degli eventi elementari, ovvero
\[p \left(\left\{1\right\}\right) = p \left(\left\{2\right\}\right) = p \left(\left\{3\right\}\right) = p \left(\left\{4\right\}\right) = p \left(\left\{5\right\}\right) = p \left(\left\{6\right\}\right)\]
e se ora si sommano le probabilità di tutti gli eventi elementari, non si può non ottenere la probabilità dell'evento certo, ovvero
\[p \left(\left\{1\right\}\right) + p \left(\left\{2\right\}\right) + p \left(\left\{3\right\}\right) + p \left(\left\{4\right\}\right) + p \left(\left\{5\right\}\right) + p \left(\left\{6\right\}\right) = p(\Omega) = 1\]
Per implicazione logica, siccome la somma delle probabilità degli eventi elementari è pari a $1$ ed essi sono \textbf{equiprobabili}, deve essere necessariamente che
\[p \left(\left\{1\right\}\right) = p \left(\left\{2\right\}\right) = p \left(\left\{3\right\}\right) = p \left(\left\{4\right\}\right) = p \left(\left\{5\right\}\right) = p \left(\left\{6\right\}\right) = \frac{1}{6}\]
A partire da tale evidenza, è possibile ora andare ad associare agli eventi complessi, aggregati di eventi elementari, una probabilità, come di seguito esposto
\[p \left(\left\{2,4,6\right\}\right) = p \left(\left\{2\right\}\right) + p \left(\left\{4\right\}\right) + p \left(\left\{6\right\}\right) = \frac{3}{6} = \frac{1}{2}\]
e similmente
\[p \left(\left\{1,2,3,4\right\}\right) = p \left(\left\{1\right\}\right) + p \left(\left\{2\right\}\right) + p \left(\left\{3\right\}\right) + p \left(\left\{4\right\}\right) = \frac{4}{6} = \frac{2}{3}\]
Naturalmente, ora, se si dovesse definire la probabilità associata alla somma di due eventi non disgiunti, non si può ricorrere alla formula precedentemente esposta, in quanto bisogna anche tenere conto delle sovrapposizioni. Infatti
\[\frac{7}{6} = p \left(\left\{2,4,6\right\}\right) + p \left(\left\{1,2,3,4\right\}\right) \neq p \left(\left\{1,2,3,4,6\right\}\right) = \frac{5}{6}\]
questo perché, per quanto si è detto, i due sottoinsieme associati ai rispettivi risultati non sono disgiunti, in quanto \(\left\{2,4,6\right\} \cap \left\{1,2,3,4\right\} = \left\{2,4\right\}\)

\vspace{1em}
\subsection{Matematica della probabilità}
Il compito della probabilità è quello di fornire delle regole, a partire dalle quali riuscire ad attribuire una valutazione quantitativa della possibilità di verificarsi di eventi più complessi, \textbf{basandosi sulla probabilità associata ad eventi più elementari}.\\
Non è, invece, compito della probabilità quello di attribuire i valori di probabilità agli eventi elementari (si pensi, banalmente, alla differenza tra un dado regolare e un dado truccato): infatti, tale compito è affidato alla statistica, in quanto molto più legato alla praticità e alla modalità dei assegnazione.\\
Una volta appresa l'assegnazione della probabilità agli eventi elemantari, interviene la probabilità: in particolare, la struttura matematica alla base del calcolo della probabilità prevede tre importanti elementi
\begin{enumerate}
  \item un insieme $\Omega$ (che per il momento si considera finito);
  \item una famiglia $\mathcal{A}$ (non vuota) di sottoinsiemi di $\Omega$ (spesso la famiglia di tutti i sottoinsieme); mentre gli elementi di $\Omega$ sono chiamati risultati elementari, gli elementi sottoinsiemi di $\Omega$ appartenenti a tale famiglia sono chiamati risultati complessi, ottenuti come aggregazione di risultati elementari;
  \item un'applicazione
  \[p : \mathcal{A} \longrightarrow \left[0,1\right]\]
  che ad ogni sottoinsieme appartenente alla famiglia $\mathcal{A}$ associa un valore compreso tra $0$ e $1$.
\end{enumerate}
Gli elementi di $\Omega$ sono detti \textbf{eventi elementari}, per cui $\Omega$ è detto \textbf{spazio degli eventi elementari}, mentre gli elementi della famiglia $\mathcal{A}$ prendono il nome di \textbf{risultati} (o eventi) \textbf{casuali} (o semplicemente eventi, configurazioni, traiettorie, campioni), per cui $\mathcal{A}$ prende il nome di \textbf{spazio degli eventi casuali}.\\
Se due eventi hanno un'intersezione nulla (come numeri pari e numeri dispari), si dice che essi sono \textbf{mutualmente esclusivi}.\\
L'applicazione $p$ è detta \textbf{probabilità}, mentre l'immagine attraverso $p$ di un evento $A$, ovvero $p(A)$ viene chiamata \textbf{probabilità dell'evento $A$}.

\vspace{1em}
\subsection{Regole della famiglia di eventi complessi}
La famiglia di eventi complessi $\mathcal{A}$, così come l'applicazione $p$, è sempre subordinata alla presenza di alcune importanti condizioni:
\begin{enumerate}
  \item tra gli elementi della famiglia degli eventi complessi $\mathcal{A}$ ci deve essere sempre l'\textbf{evento certo}:
  \[\Omega \in \mathcal{A}\]

  \item tra gli elementi della famiglia degli eventi complessi $\mathcal{A}$ ci deve essere sempre l'\textbf{evento impossibile}:
  \[\varnothing \in \mathcal{A}\]

  \item se tra gli elementi della famiglia degli eventi complessi $\mathcal{A}$ si considerano gli eventi $A$ e $B$, ad $\mathcal{A}$ deve appartenere anche la loro \textbf{unione} e la loro \textbf{intersezione}:
  \[A \cup B \in \mathcal{A} \hspace{0.5em} \text{e} \hspace{0.5em} A \cap B \in \mathcal{A}\]

  \item se tra gli elementi della famiglia degli eventi complessi $\mathcal{A}$ si considera l'evento $A$, ad $\mathcal{A}$ deve appartenere anche il suo opposto:
  \[A^c \in \mathcal{A}\]
\end{enumerate}
Nella pratica, se si lavora con uno spazio degli eventi che è finito, come famiglia dei risultati si considera l'insieme di tutti i risultati possibili, ovvero la famiglia costituita da tutti i sottoinsiemi di $\Omega$ (essendo $\Omega$ \textbf{finito}, l'insieme dei sottoinsiemi di $\Omega$ è ancora una famiglia finita con cui si può lavorare). Quando, invece, $\Omega$ è infinito, non si potrà lavorare con tutti i sottoinsiemi di $\Omega$, ma si dovrà procedere a considerare una sua restrizione (potrebbe, infatti, non essere possibile considerare l'insieme di tutti sottoinsiemi dello spazio degli eventi elementari).\\
Una famiglia $\mathcal{A}$ che soddisfa i quatto punti di cui sopra prende il nome di \textbf{algebra}: l'insieme delle parti è un esempio di algebra.

\vspace{1em}
\subsection{Regole dell'applicazione di probabilità}
L'applicazione $p$ tale per cui
\[p : \mathcal{A} \longrightarrow \left[0,1\right]\]
deve soddisfare, anch'essa, determinate regole:
\begin{enumerate}
  \item l'\textbf{evento certo} deve avere \textbf{probabilità massima}, ovvero
  \[p(\Omega) = 1\]
  \item l'\textbf{evento impossibile} deve avere \textbf{probabilità nulla}, ovvero
  \[p(\varnothing) = 0\]
  \item se due eventi $A$ e $B$ sono mutualmente esclusivi, ovvero tali che i sottoinsiemi di $\Omega$ associati siano disgiunti, ovvero $A \cap B = \varnothing$, allora si ha che
  \[p(A) + p(B) = p(A \cup B)\]
  tale proprietà prende il nome di \textbf{additività} (sempre, però, relativamente a eventi disgiunti).
\end{enumerate}
Un'applicazione $p$ definita come segue
\[p : \mathcal{A} \longrightarrow [0,1]\]
che soddisfa le tre proprietà di cui sopra prende il nome di \textbf{misura di probabilità}.\\


\vspace{1em}
\subsection{Spazio di probabilità}
Dopo aver introdotto il concetto di \textbf{algebra} e \textbf{probabilità} è possibile fornire la definizione di \textbf{spazio di probabilità finito}, (finito in quanto lo spazio degli eventi elementari $\Omega$ è finito):

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{SPAZIO DI PROBABILITÀ FINITO}}\\
    \parbox{\linewidth}{Per definizione si chiama \textbf{spazio di probabilità finito} una \textbf{terna} $\left(\Omega,\mathcal{A},p\right)$ dove
    \begin{itemize}
      \item $\Omega$ è un insieme \textbf{finito} che identifica tutti e soli gli eventi elementari;
      \item $\mathcal{A}$ è un'algebra di sottoinsiemi di $\Omega$ (che, in quanto algebra, soddisfa le $4$ regole precedentemente esposte), generalmente data da tutti i sottoinsiemi di $\
      Omega$;
      \item $p$ è una probabilità su $\mathcal{A}$ (che, essendo una probabilità, soddisfa le $3$ regole precedentemente esposte).
    \end{itemize}
    \vspace{1mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\subsubsection{Proprietà degli spazi di probabilità finiti}
Le proprietà degli spazi di probabilità finiti discendono dalle richieste, ossia dalle regole, definite in merito alla famiglia degli eventi complessi $\mathcal{A}$, la quale deve essere un'\textbf{algebra} e sulla funzione $p$, la quale deve essere una \textbf{probabilità}:

\begin{enumerate}
  \item \textbf{Proprietà additiva e subadditiva}: di seguito si espone la definizione di proprietà additiva e subadditiva della probabilità:

  % Tabella per le definizione di concetti, etc...
  \vspace{1em}
  \rowcolors{1}{black!5}{black!5}
  \setlength{\tabcolsep}{14pt}
  \renewcommand{\arraystretch}{2}
  \noindent
  \begin{tabularx}{0.94\textwidth}{@{}|P|@{}}
      \hline
      {\textbf{PROPRIETÀ ADDITIVA E SUBADDITIVA}}\\
      \parbox{\linewidth}{Se $A_1,...,A_n \in \mathcal{A}$ e sono a due a due \textbf{disgiunti} (ovvero mutualmente esclusivi), allora
      \[\sum_{k=1}^n p \left(A_k\right) = p \left(\bigcup_{k=1}^n A_k\right)\]
      ciò significa che  la probabilità è \textbf{additiva}.\\
      Se gli eventi non sono a due a due digiunti, allora è possibile solo affermare che
      \[\sum_{k=1}^n p \left(A_k\right) \geq p \left(\bigcup_{k=1}^n A_k\right)\]
      In particolare, è sempre verificato che
      \[p(A) + p(B) \geq p(A \cup B), \hspace{0.5em} \forall A,B \in \mathcal{A}\]
      ciò significa che  la probabilità è \textbf{subadditiva}.
      \vspace{3mm}}\\
      \hline
  \end{tabularx}

  \vspace{1em}
  \noindent
  \textbf{Dimostrazione $\boldsymbol{1}$}: La proprietà di additività e subadditività si dimostra per \textbf{induzione}: si chiami $B$ l'evento così ottenuto
  \[B = \bigcup_{k=1}^{n-1}A_k\]
  Dal momento che per ipotesi gli eventi $A_1,...,A_n \in \mathcal{A}$ sono disgiunti, deve essere che
  \[A \cap \bigcup_{k=1}^{n-1}A_k = A \cap B = \varnothing\]
  e quindi si ha che
  \[p\left(\bigcup_{k=1}^{n}A_k\right) = p(A_n) + p\left(\bigcup_{k=1}^{n-1}A_k\right)\]
  sfruttando la proprietà di \textbf{additività della probabilità rispetto ad eventi disgiunti} (ossia la proprietà $3$ della probabilità).\\
  Si procede analogamente, per induzione a scendere su $n$ fino a ottenere che
  \[p \left(\bigcup_{k=1}^n A_k\right) = \sum_{k=1}^n p \left(A_k\right)\]
  Per dimostrare anche la seconda implicazione, si deve ricorrere alla proprietà fondamentale dimostrata di seguito, la quale permette di affermare che, siccome $p(A \cap B) \geq 0$, allora
  \[p(A \cup B) + p(A \cap B) = p(A) + p(B) \longrightarrow p(A) + p(B) \geq p(A \cup B)\]
  Ancora una volta, per dimostrare la proprietà di cui sopra si procede per \textbf{induzione}: avendo dimostrato il passo base con $n=2$, si suppone che tale proprietà sia verificata per $n-1$ e la si dimostri per $n$; appare evidente che se si considerano $n$ eventi non a due a due disgiunti, tali per cui
  \[A_n \cap \bigcup_{k=1}^{n-1}A_k \neq \varnothing\]
  allora segue che
  \[p\left(\bigcup_{k=1}^{n}A_k\right) \leq p(A_n) + p\left(\bigcup_{k=1}^{n-1}A_k\right)\]
  ma usando l'ipotesi induttiva si perviene al risultato seguente
  \[\sum_{k=1}^n p \left(A_k\right) \geq p \left(\bigcup_{k=1}^n A_k\right)\]

  \vspace{2em}
  \noindent
  \item \textbf{Proprietà fondamentale}: di seguito si espone una relazione fondamentale che riguarda il calcolo della probabilità:

  % Tabella per le definizione di concetti, etc...
  \vspace{1em}
  \rowcolors{1}{black!5}{black!5}
  \setlength{\tabcolsep}{14pt}
  \renewcommand{\arraystretch}{2}
  \noindent
  \begin{tabularx}{0.94\textwidth}{@{}|P|@{}}
      \hline
      {\textbf{PROPRIETÀ FONDAMENTALE}}\\
      \parbox{\linewidth}{Si verifica che
      \[p(A \cup B) + p(A \cap B) = p(A) + p(B), \hspace{0.5em} \forall A,B \in \mathcal{A}\]
      \vspace{1mm}}\\
      \hline
  \end{tabularx}

  \vspace{1em}
  \noindent
  \textbf{Dimostrazione $\boldsymbol{2}$}: Per dimostrare la proprietà fondamentale è opportuno osservare che $A \cup B$ può essere vista come l'unione di tre \textbf{insiemi disgiunti}:
  \[A - (A \cap B) \hspace{1em} A \cap B \hspace{1em} B - (A \cap B)\]
  ovvero
  \[A \cup B = \left(A - (A \cap B)\right) \cup \left(A \cap B\right) \cup \left(B - (A \cap B)\right)\]
  sfruttando ancora la proprietà di \textbf{additività della probabilità rispetto ad eventi disgiunti} nel caso $n = 3$ e la proprietà di \textbf{monotonia} dimostrata di seguito, osservando che $A \cap B \subset A$ e $A \cap B \subset B$ si può concludere che
  \begin{flalign*}
    p(A \cup B) & = p\left(A - (A \cap B)\right) + p\left(A \cap B\right) + p\left(B - (A \cap B)\right)\\
    & = p(A) - p(A \cap B) + p(A \cap B) + p(B) - p(A \cap B) = p(A) + p(B) - p(A \cap B)
  \end{flalign*}

  \newpage
  \noindent
  \item \textbf{Proprietà di monotonia}: di seguito si espone la proprietà che giustifica la monotonia della probabilità:

  % Tabella per le definizione di concetti, etc...
  \vspace{1em}
  \rowcolors{1}{black!5}{black!5}
  \setlength{\tabcolsep}{14pt}
  \renewcommand{\arraystretch}{2}
  \noindent
  \begin{tabularx}{0.94\textwidth}{@{}|P|@{}}
      \hline
      {\textbf{PROPRIETÀ DI MONOTONIA}}\\
      \parbox{\linewidth}{Si verifica che
      \[p(A - B) = p(A) - p(B), \hspace{0.5em} \forall A,B \in \mathcal{A} : B \subset A\]
      In particolare, dal momento che $p(A - B) \geq 0$, allora deve essere che
      \[B \subset A \longrightarrow p(B) \leq p(A)\]
      ciò significa che la probabilità è \textbf{monotona} (\textbf{crescente}), come intuitivamente ci si poteva aspettare.
      \vspace{3mm}}\\
      \hline
  \end{tabularx}

  \vspace{1em}
  \noindent
  \textbf{Dimostrazione $\boldsymbol{3}$}: È facile osservare che gli eventi $A - B$ e l'evento $B$ sono, per costruzione, due eventi mutualmente esclusivi (e quindi disgiunti); inoltre deve essere $(A - B) \cup B = A$, dal momento che $B \subset A$. Ciò permette di concludere che
  \[p(A - B) + p(B) = p((A - B) \cup B) = p(A)\]
  sfruttando la proprietà di \textbf{additività della probabilità rispetto ad eventi disgiunti}.
\end{enumerate}

\vspace{1em}
\noindent
\begin{corollary}
  \textbf{Osservazione}: Se si considera un evento $A \in \mathcal{A}$, allora si ha che
  \[p(A^c) = 1 - p(A)\]
\end{corollary}

\vspace{1em}
\noindent
\textbf{Dimostrazione}: La dimostrazione è presto fatta e segue dai risultati precedenti. Infatti è ovvio che $A$ e $A^c$ sono due eventi disgiutni e che $A \cup A^c = \Omega$. Pertanto, sfruttando la \textbf{proprietà di additività della probabilità rispetto ad eventi digiunti} e la probabilità dell'\textbf{evento certo} si ottiene che
\[p(A \cup A^c) = p(\Omega) = p(A) + p(A^c) \longrightarrow p(A) = 1 - p(A^c)\]

\vspace{1em}
\subsubsection{Costruzione di spazi di probabilità finiti}
Si consideri un \textbf{insieme finito} $\Omega = \left\{\omega_1,...,\omega_n\right\}$ di eventi elementari (che prenderà il nome di \textbf{spazio campione}) e un insieme $\Delta = \left\{\alpha_1,...,\alpha_n\right\}$ di \textbf{numeri reali positivi} la cui somma deve produrre il valore $1$, ovvero
\[\sum_{k=1}^n \alpha_k = 1 \hspace{0.5em} \text{con} \hspace{0.5em} \alpha_k \in \mathbb{R}, \alpha_k \geq 0\]
Per la costruzione dello spazio di probabilità si considera come \textbf{algebra} $\mathcal{A}$ degli eventi complessi (o aggregati) l'\textbf{insieme delle parti} di $\Omega$ e si definisce una funzione
\[p : \mathcal{A} \longrightarrow [0,1]\]
considerando i valori $\alpha_1,...,\alpha_n$ come i valori di probabilità che verranno attribuiti a ciascun evento elementare di $\Omega$, ovverosia
\[p(\left\{\omega_k\right\}) = \alpha_k, \hspace{0.5em} \text{con} \hspace{0.5em} k=1,...,n\]
Tale concetto deve poi essere esteso a qualsiasi evento $A \in \mathcal{A}$ non vuoto, quale il seguente
\[A = \left\{\omega_{k,1},...,\omega_{k,m}\right\}\]
ovvero un sottoinsieme non vuoto di $\Omega$. Allora la probabilità dell'evento $A$ sarà definita come segue
\[p(A) = \sum_{j=1}^m p(\left\{\omega_{k,j}\right\}) = \sum_{j=1}^m \alpha_{k,j} = \sum_{\omega \in A} p(\left\{\omega\right\})\]
ponendo, per semplicità, $p(\varnothing)=0$. In altre parole, \textbf{la probabilità di $A$ è la somma delle probabilità degli eventi elemntari che costituiscono $A$}.\\
Mentre la famiglia $\mathcal{A}$ è necessariamente un'\textbf{algebra} (in quanto soddisfa le $4$ proprietà precedentemente esposte), in quanto l'insieme delle parti di $\Omega$, è opportuno verificare che la funzione $p$ presa in considerazione sia, effettivamente, una probabilità:
\begin{enumerate}
  \item La probabilità dell'evento certo è naturalmente $1$ per costruzione, in quanto
  \[p(\Omega) = \sum_{k=1}^n p \left(\left\{w_k\right\}\right) = \sum_{k=1}^n \alpha_k = 1\]
  \item Per costruzione, la probabilità dell'evento impossibile è nulla, ovvero:
  \[p(\varnothing)=0\]
  \item Si verifica immediatamente, infine, che la funzione $p$ è effettivamente additiva rispetto a eventi disgiunti, ovvero
  \[p(A \cup B) = \sum_{\omega \in A \cup B} p\left(\left\{w\right\}\right) = \sum_{\omega \in A} p\left(\left\{w\right\}\right) + \sum_{\omega \in B} p\left(\left\{w\right\}\right)\]
  essendo $A$ e $B$ disgiunti, ovvero $A \cup B = A + B$.
\end{enumerate}

\vspace{1em}
\noindent
\textbf{Esempio $\boldsymbol{1}$}: Nel caso di un dado regolare a sei facce, si è posto
\[\omega_k = k \hspace{0.5em} \text{e} \hspace{0.5em} \alpha_k = \frac{1}{6}\]
ovverosia
\[\Omega= \left\{1,...,6\right\} \hspace{0.5em} \text{e} \hspace{0.5em} \Delta=\left\{\frac{1}{6},...,\frac{1}{6}\right\}\]

\vspace{1em}
\noindent
\textbf{Esempio $\boldsymbol{2}$}: Si consideri il lancio di due dadi regolari, ambedue a sei facce. Lo spazio degli eventi elementari è
\[\Omega = \left\{(1,1),(1,2),...,(1,6),(2,1),(2,2),...,(6,1),(6,2),...,(6,6)\right\}\]
ovvero un insieme finito costituito da $36$ elementi. Assumendo che i dadi siano uguali e con facce uniformi, è naturale pensare che la probabilità che esca uno degli eventi elementari sia la stessa, ovvero
\[p\left(\left\{(1,1)\right\}\right) = p\left(\left\{(1,2)\right\}\right) = ... = p\left(\left\{(6,6)\right\}\right)\]
Il valore della probabilità di ciascuno degli eventi elementari è $\frac{1}{36}$: questo in quanto la somma delle probabilità di tutti gli eventi elementari deve essere $1$. In questo caso, si sta quindi ponendo
\[\alpha_k = \frac{1}{36} \hspace{0.5em} \text{per} \hspace{0.5em} k=1,...,36\]
Pertanto, considerando come algebra $\mathcal{A}$ degli eventi l'insieme delle parti di $\Omega$ e definendo una probabilità $p$ su $\mathcal{A}$ come esposto in precedenza, se $A \in \mathcal{A}$, allora

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{white}{white}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{>{\hsize=0.02\textwidth}P>{\hsize=0.01\textwidth}PP>{\hsize=0.01\textwidth}PP}
  $p(A)$ & $=$ & \parbox{\linewidth}{\vspace{3mm} somma delle probabilità degli eventi elementari che appartengono ad $\mathcal{A}$\vspace{3mm}} & $=$ & \parbox{\linewidth}{\vspace{3mm} numero degli elementi di $\mathcal{A}$ moltiplicato per $\frac{1}{36}$\vspace{3mm}}\\
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Esempio}: Si calcoli, ora, la probabilità dei seguenti eventi complessi:
\begin{enumerate}
  \item escono due numeri uguali
  \item la somma dei due numeri fa $8$
  \item almeno uno dei due numeri è pari
\end{enumerate}

\vspace{1em}
\noindent
\textbf{Esempio $\boldsymbol{1}$}: Al primo evento è associato il sottoinsieme
\[A = \left\{(1,1),(2,2),...,(6,6)\right\}\]
costituito da $6$ elementi. Quindi si evince che
\[p(A) = \frac{6}{36} = \frac{1}{6}\]
Infatti, dopo aver assegnato in maniera arbitraria i valori di probabilità agli eventi elementari, si adopera l'insieme delle regole del calcolo della probabilità al fine di determinare la probabilità degli eventi complessi (o aggregati).

\vspace{1em}
\noindent
\textbf{Esempio $\boldsymbol{2}$}: Al secondo evento è associato il sottoinsieme
\[A = \left\{(2,6),(3,5),(4,4),(5,3),(6,2)\right\}\]
costituito da $5$ elementi. Quindi si evince che
\[p(A) = \frac{5}{36}\]

\vspace{1em}
\noindent
\textbf{Esempio $\boldsymbol{1}$}: Al primo evento è associato il sottoinsieme
\[A = \left\{
  \begin{array}{l}
    (2,1),...,(2,6),(4,1),...,(4,6),(6,1),...,(6,6),\\
    (1,2),(1,4),(1,6),(3,2),(3,4),(3,6),(5,2),(5,4),(5,6)
  \end{array}
\right\}\]
costituito da $27$ elementi. Quindi si evince che
\[p(A) = \frac{27}{36} = \frac{3}{4}\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi, ancora una volta, che la scelta di porre
\[\alpha_k = \frac{1}{36} \hspace{0.5em} \text{per} \hspace{0.5em} k=1,...,36\]
è di \textbf{natura totalmente arbitraria} e basata su considerazioni empiriche (dadi uguali, facce uniformi, etc.). Se i dadi avessero delle anomalie (fossero, per esempio, truccati), sarebbe più ragionevole pesare in modo diverso le probabilità degli eventi elementari.\\
Per esempio, se ci fosse uno squilibrio di peso sulle facce $1$ dei dadi, si potrebbe decidere di porre
\begin{flalign*}
  p \left(\left\{(1,1)\right\}\right) & = \frac{1}{9}\\
  p \left(\left\{(1,2)\right\}\right) & = p \left(\left\{(1,6)\right\}\right) = p \left(\left\{(2,1)\right\}\right) = ... = p \left(\left\{(6,1)\right\}\right) = \frac{1}{18}\\
  \hspace{-2em} \text{e sui restanti } 25 \text{ eventi elementari porre}\\
  p \left(\left\{(...,...)\right\}\right) & = \left(1-\frac{1}{9}-\frac{10}{18}\right) \cdot \frac{1}{25} = \frac{1}{75}
\end{flalign*}

\newpage
\section{Serie}
Di seguito si espone la definizione di \textbf{serie numerica}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{SERIE NUMERICA}}\\
    \parbox{\linewidth}{Data una successione di numeri reali $\left\{a_n\right\}_{n \in \mathbb{N}}$, si chiama \textbf{serie numerica} la successione delle somme parziali
    \[\left\{s_n := \sum_{k=1}^n a_k\right\}_{n \in \mathbb{N}}\]
    Più esplicitamente
    \[\left\{
      \begin{array}{l}
        s_1 = a_1\\
        s_2 = a_1 + a_2\\
        ...\\
        s_n = a_1 + ... + a_n\\
        ...
      \end{array}
    \right.\]
    Pertanto, effettuare la sommatoria di infinito termini $a_n$ equivale ad effettuare
    \[\lim_{n \to \infty} s_n\]
    Tale successione si indica con il simbolo
    \[\sum_{k=1}^{\infty}a_k\]
    e si impiega lo stesso simbolo per indicare il limite per $n \to \infty$ (ammesso che esista).\vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{2em}
\noindent
\textbf{Osservazione $\boldsymbol{1}$}: Se la successione $\left\{a_n\right\}$ è una successione di numeri reali non negativi, allora, naturalmente, $\left\{s_n\right\}$ è crescente. Quindi, come ben noto, $\left\{s_n\right\}$ converge, oppure diverge a $+\infty$.

\vspace{2em}
\noindent
\textbf{Osservazione $\boldsymbol{2}$}: È chiaro che il simbolo
\[\sum_{k=1}^{\infty}a_k\]
viene utilizzato per indicare che la somma inzia a partire dal termine $a_1$. Il simbolo
\[\sum_{k=0}^{\infty}a_k\]
invece, è atto a indicare che la somma inzia a partire dal termine $a_0$. Similmente, si impiega il simbolo
\[\sum_{k=3}^{\infty}a_k\]
quando si inizia a sommare a partire dal termine $a_3$.

\vspace{2em}
\noindent
\textbf{Osservazione $\boldsymbol{3}$}: Si osservi che, naturalmente
\[\sum_{k=1}^{\infty}a_k\]
converge \textbf{se e solo se} converge
\[\sum_{k=3}^{\infty}a_k\]
Questo in quanto
\[\sum_{k=1}^{\infty}a_k = a_1 + a_2 + ... + a_{j-1} + \sum_{k=0}^{\infty}a_k\]
per cui il limite a destra esste \textbf{se e solo se} esiste quello di sinistra, in quanto la differenza tra le due successione è costituita soltanto un numero finito di elementi (dalla costante $a_1 + a_2 + ... + a_{j-1}$) che non influiscono sulla convergenza della successione stessa.

\vspace{2em}
\noindent
\textbf{Osservazione $\boldsymbol{4}$}: Si osservi che

\begin{lemma}
  \textbf{Non è vero} che ogni serie converge o diverge a $\pm \infty$.
\end{lemma}

\vspace{2em}
\noindent
\textbf{Esempio}: Si consideri la seguente serie
\[\sum_{k=1}^{\infty}(-1)^k\]
tale serie non converge e non diverge: infatti la somma parziale con $k$ pari converge a $0$, mentre la somma parziale con $k$ dispari converge a $-1$: pertanto la serie di partenza non converge e non diverge, in quanto non esiste il limite della somma di successione.\\
Si parla, in questo caso, di una \textbf{successione oscillante}:
\[s_1=-1,s_2=0,s_3=-1,...\]

\vspace{1em}
\subsection{Condizione necessaria per la convergenza di una serie}
In genere non è facile stabilire se una serie sia convergente o meno (e se anche lo fosse, non è sempre facile stabilire il limite della stessa). Si consideri, a tal proposito, il seguente lemma:

\begin{lemma}
  Si consideri la serie seguente
  \[\sum_{k=1}^\infty a_k\]
  Se essa converge, allora deve essere che
  \[\lim_{n \to \infty} a_n = 0\]
  cioé \textbf{condizione necessaria} affinché una serie converga è che i termini da sommare progressivvamente diventino indefinitivamente piccoli.
\end{lemma}

\vspace{1em}
\subsubsection{Serie armonica}
\textbf{Osservazione}: Si osservi che tale condizione è necessaria, ma \textbf{non sufficiente}. E ciò è facilmente verificabile con l'esempio seguente: si consideri la \textbf{serie armonica} seguente
\[\sum_{k=1}^\infty \frac{1}{k}\]
Tale serie diverge a $+\infty$, anche se
\[\lim_{k \to \infty} = 0\]
in quanto essa va a $0$ troppo lentamente e quindi non ha sufficienza per garantire la convergenza.

\vspace{1em}
\noindent
\textbf{Dimostrazione}: Si dimostri per assurdo che la \textbf{serie armonica} diverge a $+\infty$. Dal momento che taluna è una serie ottenuta come sommatoria di quantità positive o converge, oppure diverge. Si supponga per assurdo che non diverga: allora converge ad un certo $l$, ovvero dovrebbe essere che
\[\lim_{n \to \infty} s_n = l\]
Si può facilmente osservare che la differenza tra le due somme parziali $s_{2n}$ e $s_n$ si può scrivere come
\[s_{2n} - s_n = \sum_{k=n+1}^{2n} \frac{1}{k}\]
questo perché i primi $n$ termini vengono eliminati nella differenza. Inoltre si ha che
\[s_{2n} - s_n = \sum_{k=n+1}^{2n} \frac{1}{k} = \underbrace{\frac{1}{n+1} + \frac{1}{n+2} + ... + \frac{1}{2n}}_\text{$n$ \text{ termini}} \geq n \cdot \frac{1}{2n} = \frac{1}{2}\]
in quanto, ovviamente
\[\frac{1}{n+1} > \frac{1}{n+2} > ... > \frac{1}{2n}\]
ed essi sono proprio $n$ termini. Ciò permette di affermare che
\[\frac{1}{n+1} + \frac{1}{n+2} + ... + \frac{1}{2n} \geq n \cdot \frac{1}{2n} = \frac{1}{2}\]
Per la definizione di limite si ha che definitivamente, ossia per $n$ abbastanza grande, si ha che
\[\forall \epsilon > 0, \exists n_\epsilon \in \mathbb{N} : \forall n \geq n_\epsilon \longrightarrow \left \vert s_n - l \right \vert < \epsilon\]
Ponendo $\epsilon = \frac{1}{4}$ si ottiene che
\[\left \vert s_n - l \right \vert < \frac{1}{4}\]
Da ciò segue che, per la disuguaglianza triangolare e ricordando che $|w|=|-w|$
\[\frac{1}{2} \leq \left \vert s_{2n} - s_n \right \vert = \left \vert s_{2n} - l + l - s_n \right \vert \leq \left \vert s_{2n} - l \right \vert + \left \vert s_{n} - l \right \vert < \frac{1}{4} + \frac{1}{4} = \frac{1}{2}\]
ricordando che il limite delle due somme parziali è identico, dal momento che per $n \to \infty$ $s_{n} \to +\infty$, $s_n \leq s_{2n}$ e si verifica che
\[\lim_{k \to \infty} \frac{1}{k} = 0\]
Dal momento che una quantità non può essere minore di se stessa si ottiene l'assurdo.

\vspace{1em}
\subsection{Serie armonica generalizzata}
Di seguito si fornisce la definizione di \textbf{serie armonica generalizzata}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{SERIE ARMONICA GENERALIZZATA}}\\
    \parbox{\linewidth}{Dato $\alpha \in \mathbb{R}$, la serie
    \[\sum_{k=1}^\infty \frac{1}{k^\alpha}\]
    è detta \textbf{serie armonica generalizzata}.\vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Osservazione}: Anche se la serie armonica è divergente, la presenza di un esponente $\alpha > 1$ sul termine $\frac{1}{k}$ fa sì che le somme parziali crescano più lentamente e quindi ci sia convergenza. Se $\alpha < 1$, invece, la serie che non può che divergere ancora più velocemente.\\
Omettendo la dimostrazione, si può facilmente capire che
\[\sum_{k=1}^\infty \frac{1}{k^\alpha} \left\{
  \rowcolors{1}{white}{white}
  \begin{array}{l}
    \text{diverge a } +\infty \text{ se } \alpha \leq 1\\
    \text{converge se } \alpha > 1\\
  \end{array}
\right.\]

\vspace{1em}
\subsection{Serie geometrica}
Di seguito si fornisce la definizione di \textbf{serie geometrica}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{SERIE GEOMETRICA}}\\
    \parbox{\linewidth}{Dato $Q \in \mathbb{R}$, la serie
    \[\sum_{k=0}^\infty q^k\]
    è detta \textbf{serie geometrica} di ragione $q$ (e parte con $k=0$).\vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Osservazione}: Il comportamento della serie è il seguente:
\[\sum_{k=0}^\infty q^k \left\{
  \rowcolors{1}{white}{white}
  \begin{array}{l}
    \text{converge a } \frac{1}{1-q} \text{ se } q \in (-1,1)\\
    \text{diverge a } +\infty \text{ se } q \geq 1\\
    \text{indeterminata se } q \leq -1
  \end{array}
\right.\]
ove per \textbf{indeterminata} si intende che non converge, né diverge a $\pm \infty$.

\vspace{1em}
\noindent
\textbf{Dimostrazione}: Se $q=1$ il comportamento è ovvio, in quanto si somma indefinitamente il valore $1$, per cui la serie diverge a $+\infty$. Se $q \neq 1$, allora si deve osservare che è possibile scrivere
\[1 - q^{n+1} = (1 - q) \cdot (1 + q + q^2 + ... + q^n)\]
dividendo ambo i mebri per il termine $1 - q \neq 0$ in quanto per ipotesi si è assunto $q \neq 1$, si ottiene il seguente termine generico della serie geometrica:
\[s_n = 1 + q + q^2 + ... + q^n = \frac{1 - q^{n+1}}{1 - q}\]
e la tesi segue per quanto noto sul limite di $q^n$:
\begin{itemize}
  \item se $q \in (-1,1)$, allora ovviamente
  \[\lim_{n \to \infty} q^{n+1} = 0\]
  per cui
  \[\lim_{n \to \infty} \frac{1 - q^{n+1}}{1 - q} = \frac{1}{1-q}\]

  \item se $q > 1$, allora ovviamente
  \[\lim_{n \to \infty} q^{n+1} = +\infty\]
  per cui
  \[\lim_{n \to \infty} \frac{1 - q^{n+1}}{1 - q} = +\infty\]
  in quanto si può portare fuori il \quotes{$-$}, senza avere problemi di segno.

  \item se $q < 1$, allora ovviamente
  \[q^{n+1} > 0\]
  se $n+1$ è pari, mentre
  \[q^{n+1} < 0\]
  se $n+1$ è dispari, quindi la serie è oscillante con ampiezza a crescere.
\end{itemize}

\vspace{1em}
\noindent
\textbf{Esempio}: Si calcoli la seguente serie geometrica:
\[\sum_{k=1}^\infty \left(\frac{1}{3}\right)^k\]
ricordando sempre, però, che la serie geoemtrica parte con $k=0$. Ovviamente è noto che, se $k=0$
\[\left(\frac{1}{3}\right)^0 = 1\]
per cui si può scrivere
\[\sum_{k=1}^\infty \left(\frac{1}{3}\right)^k = -1 + \sum_{k=0}^\infty \left(\frac{1}{3}\right)^k\]
ma siccome $q = \frac{1}{3} \in (-1,1)$, allora la serie converge a
\[\frac{1}{1-q} = \frac{1}{1 - \frac{1}{3}}\]
e si può scrivere
\[\sum_{k=1}^\infty \left(\frac{1}{3}\right)^k = -1 + \sum_{k=0}^\infty \left(\frac{1}{3}\right)^k = -1 + \frac{1}{1 - \frac{1}{3}} = \frac{1}{2}\]

\vspace{1em}
\subsection{Criterio del confronto per serie a termini positivi}
Non è sempre facile capire se una serie converge o meno: anche se la serie è a termini positivi, non è facile determinare se essa converga o diverga a $\pm \infty$. Tuttavia, esistono diversi criteri, uno dei più basilari ed efficaci è il criterio del confronto:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{CRITERIO DEL CONFRONTO PER SERIE A TERMINI POSITIVI}}\\
    \parbox{\linewidth}{Siano date due successioni $a_n,b_n \geq 0$ e si supponga che esse siano tali che $a_n \leq b_n, \forall n$. Allora si ha che
    \begin{itemize}
      \item se \(\displaystyle{\sum_{k=1}^\infty a_n}\) diverge, diverge anche \(\displaystyle{\sum_{k=1}^\infty b_n}\)
      \item se \(\displaystyle{\sum_{k=1}^\infty b_n}\) converge, allora converge anche \(\displaystyle{\sum_{k=1}^\infty a_n}\)
    \end{itemize}
    Inoltre, detto $l_b$ il limite dela prima e $l_a$ il limite della seconda, risulta $l_a = l_b$.
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
Si propone una breve dimostrazione (che si basa sui teoremi del confronto di successioni monotone):
\begin{itemize}
  \item si indichi con $s_n$ la successione delle somme parziali relativa ai termini $a_n$, ovvero
  \[s_n = a_1 + ... + a_n\]
  \item si indichi con $r_n$ la successione delle somme parziali relativa ai termini $b_n$, ovvero
  \[r_n = b_1 + ... + b_n\]
\end{itemize}
Si supponga che la successione $r_n$ converga e si chiami ccon $l_b$ il suo limite, ovvero
\[\lim_{n \to \infty} r_n = l_b\]
sapendo, però, che $a_n \leq b_n, \forall n$, si evince che
\[s_n \leq r_n\]
ma siccome $r_n$ è una successione crescente e convergente, i suoi termini sono diminati dall'alto dal limite $l_b$, da cui
\[s_n \leq r_n \leq l_b\]
per il teorema di convergenza delle successioni monotone. Ma siccome anche la successione $s_n$ è crescente ed è limitata superiormente da $l_b$, per il teorema di esistenza del limite delle successioni monotone segue che
\[\exists \lim_{n \to \infty} a_n = l_a\]
per il teorema del confronto tra successioni, sapendo che $a_n \leq b_n, \forall n$, si ha che $l_a \leq l_b$.
Generalmente per il confronto vengono utilizzate la serie geometrica e la serie armonica generalizzata (visto che già se ne conosce il comportamento).

\vspace{1em}
\noindent
\textbf{Dimostrazione}: Si consideri la seguente serie
\[\sum_{k=0}^\infty \frac{1}{k!}\]
e si dimostri che essa è \textbf{convergente}. Ricordando che $0!=1$, per definizione, si ha che
\[\sum_{k=0}^n \frac{1}{k!} = 1 + 1 + \frac{1}{2} + ... + \frac{1}{n \cdot (n-1) \cdot ... \cdot 2}\]
se ora, in ciascun denominatore, si procede ad eliminare tutti i prodotti tranne i primi due, ovvero lasciando solamente $n \cdot (n-1)$, è naturale ottenere una sommatoria maggiorata, per cui
\[\sum_{k=0}^n \frac{1}{k!} = 1 + 1 + \frac{1}{2} + ... + \frac{1}{n \cdot (n-1) \cdot ... \cdot 2} \leq 1 + 1 + \frac{1}{2 \cdot 1} + ... + \frac{1}{n \cdot (n-1)} = 2 + \sum_{k=2}^n \frac{1}{k \cdot (k-1)}\]
La serie a destra può essere così riscritta
\[\sum_{k=2}^\infty \frac{1}{k \cdot (k-1)} = \sum_{k=2}^\infty \left[\frac{1}{k-1} - \frac{1}{k}\right]\]
e tale serie è \textbf{convergente} ad $1$, in quanto $s_n = 1 - \frac{1}{n}$. Per verificarlo basta provare a scrivere esplicitamente la successione delle somme parziali
\[s_n = \left(1 - \frac{1}{2}\right) + \left(\frac{1}{2} - \frac{1}{3}\right) + ... + \left(\frac{1}{n-1} - \frac{1}{n}\right) = 1 - \frac{1}{n}\]
in quanto tutti gli altri termini si semplificano. Applicando il criteriore del confronto, è facile osservare che
\[\sum_{k=0}^\infty \frac{1}{k!} \leq 2 + \sum_{k=2}^\infty \frac{1}{k \cdot (k-1)} = 2 + 1 = 3\]
per cui si ottiene che anche la successione
\[\sum_{k=0}^\infty \frac{1}{k!}\]
è convergente e il suo limite è minore di $3$. Tale limite prende il nome di \textbf{numero di Nepero} ed è indicato con $e$.

\newpage
\begin{center}
  7 Marzo 2022
\end{center}
\section{Spazi di probabilità generali}
Finora sono stati considerati degli spazi degli eventi elementari finiti. Tuttavia, non è sempre possibile sapere a priori quanti elementi devono essere contenuti nello spazio campione su cui si andrà a lavorare, per cui si rende necessario operare con spazi arbitrariamente grandi, ovvero \textbf{non finiti}.\\
Tuttavia, ciò introduce una complicazione aggiuntiva: non sarà più possibile sommare un numero finito di probabilità, ma un numero arbitrariamente grande e quindi infinito.

\vspace{1em}
\subsection{$\boldsymbol{\sigma}$-algebra}
Per estensione con quanto esposto in precedenza, di seguito si espone la definizione di $\sigma$-algebra, ovvero un'algebra nella quale non si pone un limite sul numero di elementi:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{$\boldsymbol{\sigma}$-ALGEBRA}}\\
    \parbox{\linewidth}{Una famiglia $\mathcal{A}$ di parti di un insieme $\Omega$ è detta \textbf{$\boldsymbol{\sigma}$-algebra} se
    \begin{enumerate}
      \item l'insieme vuoto e lo spazio campione stesso appartengono ad $\mathcal{A}$, ovvero
      \[\varnothing, \Omega \in \mathcal{A}\]
      \item se $A \in \mathcal{A}$, allora $A^c \in \mathcal{A}$
      \item mentre in un'algebra normale si chiedeva che dati $n$ sottoinsiemi appartenenti all'algebra, anche la loro unione e intersezione di devono appartenere, nel caso di una $\sigma$-algebra si chiede che se si considera una successione di sottoinsiemi $A_n$ all'interno della $\sigma$-algebra, ovvero $\left\{A_n, n \in \mathbb{A} \right\} \subset \mathcal{A}$, ossia una \textbf{quantità al più numerabile}, allora l'unione e l'intersezione di tali sottoinsiemi devono appartenere alla $\sigma$-algebra:
      \[\bigcup_{n=1}^\infty A_n \in \mathcal{A} \hspace{1em} \text{e} \hspace{1em} \bigcap_{n=1}^\infty A_n \in \mathcal{A}\]
    \end{enumerate}
    \vspace{1mm}}\\
    \hline
\end{tabularx}

\vspace{2em}
\noindent
\textbf{Osservazione}: Ovviamente, ogni \textbf{$\boldsymbol{\sigma}$-algebra} è anche un'algebra, e i due concetti coincidono se $\Omega$ ha un numero finito di elementi.

\newpage
\noindent
\subsection{Probabilità generale}
Così come su un'algebra è stato definito il concetto di probabilità, è opportuno estendere tale concetto anche ad una $\sigma$-algebra:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{PROBABILITÀ PER SPAZI DI PROBABILITÀ GENERALI}}\\
    \parbox{\linewidth}{Siano $\Omega$ un insieme e la famiglia $\mathcal{A}$ una \textbf{$\boldsymbol{\sigma}$-algebra} su $\Omega$. Una (misura di) \textbf{probabilità} è una funzione
    \[p : \mathcal{A} \longrightarrow [0,1]\]
    tale che
    \begin{enumerate}
      \item come per un'algebra normale, la probabilità dell'insieme vuoto sia nulla e quella dello spazio campione stesso sia massima, ovvero
      \[p(\varnothing) = 0 \hspace{1em} \text{e} \hspace{1em} p(\Omega) = 1\]
      \item se $\left\{A_n, n \in \mathbb{N}\right\} \subset \mathcal{A}$ è una successione di insiemi appartenenti alla $\sigma$-algebra \textbf{a due a due disgiunti}, ovvero $A_i \cap A_j \neq \varnothing, \forall i \neq j$, allora
      \[\sum_{n=1}^\infty p(A_n) = p \left(\bigcup_{n=1}^{\infty} A_n\right) \hspace{1em} \left[\boldsymbol{\sigma}-\textbf{additività}\right]\]
      ovvero la probabilità deve essere \textbf{$\boldsymbol{\sigma}$-additiva}. Da notare che
      \[\sum_{n=1}^\infty p(A_n)\]
      è una \textbf{serie numerica}, ovverosia una \textbf{somma infinita} delle probabilità di ogni singolo insieme $A_n$ considerato.
    \end{enumerate}
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\subsection{Spazio di probabilità generale}
Avendo esteso il concetto di alebra e probabilità al caso generale, è posibile parlare di \textbf{spazio di probabilità generale}, la cui definizione viene di seguito esposta:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{SPAZIO DI PROBABILITÀ GENERALE}}\\
    \parbox{\linewidth}{Si chiama \textbf{spazio di probabilità} una terna $\left(\Omega,\mathcal{A},p\right)$ dove
    \begin{itemize}
      \item $\Omega$ è un insieme, ovvero lo spazio degli eventi elementari (spazio campione)
      \item $\mathcal{A}$ è una $\sigma$-algebra
      \item $p$ è una probabilità definita su $\mathcal{A}$
    \end{itemize}
    \vspace{1mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
Da notare, ovviamente, che i risultati visti in precedenza, nell'ambito di uno spazio campione finito, sono ancora validi, anche in questo ambito generale.\\
Si consideri, a tal proposito, il seguente esempio:

\vspace{1em}
\noindent
\textbf{Esempio}: Presa una moneta e lanciandola ripetutatemente, si vuole determinare la proabilità che esca testa al lancio $n$-esimo, ma non prima.\\
Per la visualizzazione di tale problema dal punto di vista matematico, è possibile etichettare testa con il numero \quotes{$0$} e croce con il numero \quotes{$1$}. È possibile, quindi, identificare i risultati di una successione di lanci con una successione che prenda valori in $\{0,1\}$. Per esempio $(0,0,1,0,1,1,...)$ identifica una successione di lanci in cui al primo e al secondo lancio è uscita testa, al terzo croce, al quarto di nuovo testa, etc...\\
Con questa identificazione l'evento elementare è, fissato $n$, il seguente:

\begin{flalign*}
  \omega_n & = \text{ la prima volta che esce testa è al lancio } n\text{-esimo}\\
   & = \parbox{\linewidth}{\text{la famiglia delle successione che hanno \quotes{$1$} nei\\ primi $n-1$ elementi e \quotes{$0$} all'evento $n$-esimo.}}\\
\end{flalign*}

\noindent
Lo spazio degli eventi elementari è dunque $\Omega=\left\{\omega_n, n \in \mathbb{N}\right\}$, ovvero l'insimee delle fammiglie $\omega_1,\omega_2,$ etc., il quale, quindi, ha un numero infinito, ossia una quantità numerabile, di elementi.\\
Per rispondere alla domanda che è stata posta in principio, è necessario stabilire un criterio ragionebvole per assegnare la probabilità. È possibile assumere, in maniera puramente \textbf{euristica}, che
\begin{itemize}
  \item in ogni singolo lancio, la probabilità che esca testa o croce sia la stessa;
  \item il risultato di un lancio sia indipendente dai risultati dei lanci precedenti.
\end{itemize}
Queste ultime sono ipotesi ragionevoli, ma come per il lancio di un dado, sono assunzioni totalmente arbitrarie. Per esempio, la moneta potrebbe essere sbilanciata e quindi testa potrebbe tendere as usicre più volte rispetto a croce.\\
Per stabilire la probabilità di verificarsi dell'evento $\omega_1$ è necessario capire che cosa accade nel primo lancio: se esce testa la probabilità è presto calcolata $\frac{1}{2}$, ossia il $50\%$.\\
La probabilità che si verifichi $\omega_2$ prevede che non sia uscita testa al primo lancio e serve che al secono lancio esca proprio testa. Quindi la probabilità è $\frac{1}{2}$ di $\frac{1}{2}$, cioé $\frac{1}{4}$, ossia il $25\%$.\\
È così via per l'evento $\omega_n$:
\[p\left(\left\{\omega_n\right\}\right) = \left(\frac{1}{2}\right)^n\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Nonostante si abbia risposto alla domanda, non è stato definito completamente lo spazio di probabilità che si sta considerando.\\
È opportuno considerare come $\sigma$-algebra $\mathcal{A}$, come già visto, l'insieme di tutti i sottoinsiemi di $\Omega$: questo è possibile farlo nonostante $\Omega$ sia infinito, in quanto è costituita da una \textbf{quntità numerabile} di elementi.\\
Dopodiché la probabilità su $\mathcal{A}$ si definisce come in precedenza, ossia come somma delle probabilità degli eventi elementari costituenti $\mathcal{A}$; in particolare
\[p(A) = \left\{
  \rowcolors{1}{white}{white}
  \begin{array}{cl}
    \displaystyle{\sum_{\omega \in A} p\left(\left\{\omega\right\}\right)} & \forall A \subset \Omega \text{ non vuoto}\\
    0 & \text{se } A = \varnothing
  \end{array}
\right.\]
La funzione così definita è ben posta, poiché $\Omega$ è numerabile e quindi $\mathcal{A}$ è al più numerabile. Quindi
\[\sum_{\omega \in \mathcal{A}}\]
è una sommatoria finita o una serie (se il numero di elementi costituenti $\mathcal{A}$ è infinito). Si ha, inoltre, che tale funzione è utti gli effetti una probabilità, in quanto la somma delle probabilità di tutti gli eventi elementari è proprio $1$
\[p(\Omega) = \sum_{n=0}^\infty p \left(\left\{\omega\right\}\right) = \sum_{n=0}^\infty \left(\frac{1}{2}\right)^n = \sum_{n=1}^\infty \left(\frac{1}{2}\right)^n - 1 = \frac{1}{1 - \dfrac{1}{2}} - 1 = 2 - 1 = 1\]
essendo una serie geometrica di ragione $\frac{1}{2}$. Si può facilmente osservare che vale la proprietà di \textbf{$\boldsymbol{\sigma}$-additività}: si calcoli la probabilità dell'evento
\[A = \left\{\text{esce testa per la prima volta tra il terzo e il sesto lancio (compresi)}\right\} = \left\{\omega_1,\omega_4,\omega_5,\omega_6\right\}\]
Per calcolare la probabilità di tale evento complesso $\mathcal{A}$ sarà sufficiente provvedere alla somma delle probabilità dei singoli eventi che appartengono ad $\mathcal{A}$, secondo la definzione, ovvero:
\[p(A) = \sum_{n=3}^6 p\left(\left\{\omega_n\right\}\right) = \left(\frac{1}{2}\right)^3 + \left(\frac{1}{2}\right)^4 + \left(\frac{1}{2}\right)^5 + \left(\frac{1}{2}\right)^6\]
Si consideri un altro evento complesso:
\[A = \left\{\text{esce testa per la prima volta in un lancio pari}\right\} = \left\{\omega_n : n \text{ è pari}\right\} = \left\{\omega_{2m} : m \in \mathbb{N}\right\}\]
La probabilità di tale evento è, quindi:
\[p(\mathcal{A}) = \sum_{m=0}^\infty p \left(\left\{\omega_{2m}\right\}\right) = \sum_{m=0}^\infty \left(\frac{1}{2}\right)^{2m} = \sum_{m=0}^\infty \left(\frac{1}{4}\right)^{m} = \sum_{m=1}^\infty \left(\frac{1}{4}\right)^{m} - 1 = \frac{1}{1 - \dfrac{1}{4}} - 1 = \frac{4}{3} - 1 = \frac{1}{3}\]

\vspace{1em}
\noindent
\textbf{Osservazione}: L'esempio appena visto è molto simile a quelli visti nel caso finito. Il motivo per cui tale estensione al caso generale è stata così naturale è che $\Omega$ è numerabile, nonostante sia infinito, ma nulla di più. Esso merita, quindi, una definizione specifica:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{SPAZIO DI PROBABILITÀ DISCRETO}}\\
    \parbox{\linewidth}{Si dirà che uno spazio di probabilità $(\Omega,\mathcal{A},p)$ è \textbf{discreto} se $\Omega$ è al più numerabile (ovvero o finito o numberabile) e $\mathcal{A}$ è la famiglia di tutti i sottoinsieme di $\Omega$. Naturalmente, per quanto già visto, la probabilità sulla famiglia $\mathcal{A}$ viene definita come
    \[p(A) = \left\{
      \begin{array}{cl}
        \displaystyle{\sum_{\omega \in A} p\left(\left\{\omega\right\}\right)} & \forall A \subset \Omega \text{ non vuoto}\\
        0 & \text{se } A = \varnothing
      \end{array}
    \right.\]
    Quindi, in base a tale formula, si evince che il comportamento di $p$ è \textbf{completamente determinato dalle probabilità degli eventi elementari}.
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che l'espressione
\[\sum_{\omega \in A} p\left(\left\{\omega\right\}\right)\]
è da interpretarsi come una serie. Tuttavia, nel calcolo di tale sommatoria è totalmente \textbf{ininfluente l'ordine con cui si vanno a sommare le probabilità} degli eventi costituenti $\mathcal{A}$, ma solamente perché taluna è una \textbf{serie convergente a termini positivi}. Pertanto, in questo caso, si parla di \textbf{convergenza assoluta} e, quindi il limite non cambia se i termini vengono riarrangiati.

\vspace{1em}
\noindent
Si considerino due questioni:
\begin{enumerate}
  \item Si consideri l'alternativa di considerare nell'esempio appena trattato, lo spazio degli eventi elementi seguenti
  \[\Omega = \left\{\text{successioni costituite da \quotes{0} e da  \quotes{1}}\right\}\]
  e, per $n \in \mathbb{N}$, gli eventi
  \[A_n = \left\{\text{successioni che presentano \quotes{1} nei primi } n-1 \text{ elementi e \quotes{0} nell'} n \text{-esimo}\right\}\]
  Ovvero ci si sta chiedendo se sia più conveniente considerare gli eventi oggetto di interesse come eventi elementari $\omega_n$ invece che come eventi complessi $A_n$.

  \item Inoltre, ci si deve chidere per quale ragione non ci si limiti ad assegnare una probabilità esclusivamente sugli eventi elementari e si necessita, invece, di introdurre la famiglia $\mathcal{A}$ e definire $p$ su eventi complessi $A \in \mathcal{A}$.
\end{enumerate}

\vspace{1em}
\noindent
La risposta alla seconda questione è presto detta: se $\Omega$ non fosse un insieme finito o numerabile, i suoi sottoinsiemi potrebbero non essere finiti o numerabili, per cui non sarebbe possibile definire la probabilità dell'evento complesso semplicemente basandosi sulla sommatoria della probabilità degli eventi elementari, in quanto tale sommatoria potrebbe essere non finita, in quanto somma di quantità più che numerabili, perdendo di significato.

\vspace{1em}
\noindent
\textbf{Esempio}: Per rispondere alla prima questione, invece, si consideri un esempio pratico. Se si deve modellizzare la risposta elastica di un ponte di ferro costituito da delle travi di ferro; si compia il seguente parallelo
\begin{itemize}
  \item Le travi sono gli eventi elementari $\omega_n$;
  \item L'elastiticità delle travi corrisponde alla probabilità di eventi elementari $p \left(\left\{\omega_n\right\}\right)$;
  \item Le regole con cui le travi interagiscono sono gli assiomi dello spazio di probabilità (quale l'additività);
  \item Il ponte è l'evento complesso $\mathcal{A}$.
\end{itemize}
In questo caso, per la modellizzaione, si sarebbe potuto certamente prendere come elemento base del ponte gli atomi di ferro e considerare sia le travi che il ponte strutture complesse; tuttavia, il concetto di elasticità sarebbe stato definito comunque a partire dalle travi e non sugli atomi, dove tale applicazione non avrebbe alcun senso. Similmente, si sarebbero potuto considerare come eventi elementari le successioni, però il concetto di probabilità va comunque definito a livello di evento $A_n$ e non sulla singola successione, in cui non avrebbe avuto senso.\\
In effetti ogni successione avrebbe dovuto avere la stessa probabilità, ma ogni evento $A_n$ ne contiene infinite e quindi $A_n$ risulterebbe avere \textbf{probabilità infinita} (e ciò è impossibile).\\
In tale esempio, pertanto, dal punto di vista operativo, i due approcci non differiscono concettualmente; spesso, però, si usano spazi non discreti: il ponte potrebbe essere fatto da ben altro che semplici travi.

\vspace{1em}
\noindent
\textbf{Esercizio}: Si consideri un bersaglio con una macchia non omogenea al suo interno:

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \node[circle,draw=black,fill=white, inner sep=0pt,minimum size=4cm]{} (0,0);
    \node[circle,draw=black,fill=black, inner sep=0pt,minimum size=1cm](i) at (0,1) {};
    \node[circle,draw=black,fill=black, inner sep=0pt,minimum size=1cm](i1) at (0,0.7) {};
    \node[circle,draw=black,fill=black, inner sep=0pt,minimum size=1cm](i2) at (-0.5,0.8) {};
    \node[circle,draw=black,fill=black, inner sep=0pt,minimum size=1cm](i3) at (-0.8,0.5) {};
  \end{tikzpicture}
  \caption{Esempio 4}
  \label{fig:esempio_4}
\end{figure}

\noindent
Lanciando una freccetta, qual'è la probabilità di colpire la macchia scura?\\
In questo caso, ha senso considerare l'insieme degli eventi elementari $\Omega$ l'insieme di tutti i punti del cerchio
\[\Omega : = \left\{x \in \mathbb{R}^2 : x \in \text{cerchio}\right\}\]
Pertanto, sembra ragionevole assegnare ad una certa zona la probabilità di essere colpita in modo proporzionale alla sua area. In altre parole, se $A$ è un sottoinsieme del cerchio $\Omega$, si ha che
\[p(A) = c \cdot \left \vert A \right \vert\]
dove $\left \vert A \right \vert$ è l'area del sottoinsieme e $c>0$ è un opportuno fattore; questa è ovviamente un'\textbf{assunzione euristica}, totalmente arbitraria.\\
Affinché l'oggetto appena definito sia un'algebra (e $p$ una probabilità), deve risultare $p(\Omega)=1$, si può considerare come fattore rinormalizzante
\[c=\frac{1}{\left \vert \Omega \right \vert}\]
Nuovamente, la misura di probabilità così definita è una scelta arbitraria basata su considerazioni empiriche. Si sarebbe potuto ancora definirla in modo diverso, per esempio volendo tenere conto della gravità di zone poste in basso che, a paritià di area, potrebbero avere più probabilità di essere colpite rispetto a zone poste in alto.\\
Si osservi, poi, che benché sia stato considerato come spazio degli eventi elementari l'insieme del punti del bersaglio, ovvero uno spazio \textbf{né finito}, \textbf{né numerabile}, non ha senso definire prima la probabilità di colpire i singoli punti (che sarebbe sempre nulla) e poi la probabilità di colpire un'intera area del bersaglio, in quanto ad ogni area corrispondono infiniti punti e quindi la probabilità risultante sarebbe nulla.\\
Quando $\Omega$ è un insieme al più numerabile, è sempre possibile scegliere $\mathcal{A}$ come la famiglia di tutti i sottoinsiemi di $\Omega$; tuttavia, in generale questo non è possibile farlo, o non risulta conveniente farlo.\\
Infatti, in questo caso, lavorando con $\Omega$ non finito e non numerabile, la $\sigma$-algebra $\mathcal{A}$ non è
\[\mathcal{A} := \left\{\text{ogni sottoinsieme di }\Omega\right\}\]
in quanto poi dopo si avrebbe difficoltà a definire la probabilità $p$. In effetti, in questo caso, si è assunto
\[\mathcal{A} := \left\{\text{ogni sottoinsieme di }\Omega\text{ per cui abbia senso il concetto di area}\right\}\]
altrimenti non si sarebbe potuto scrivere $\left \vert A \right \vert$. In questo caso, la famiglia $\mathcal{A}$ assunta è a tutti gli effetti una $\sigma$-algebra $\mathcal{A}$, in quanto l'unione di due eventi disgiunti di cui si conosce la misura (l'area) è ancora un evento di cui è nota la misura (l'area).\\
Ciò che in questo caso è rilevante è che in $\mathcal{A}$ cadano tutti gli oggetti geometrici classici e le loro unioni ed intersezioni numerabili. Tale $\sigma$-algebra prende il nome di \textbf{$\boldsymbol{\sigma}$-algebra di Borel}, ovvero la \textbf{famiglia di tutti i sottoinsiemi misurabili di $\boldsymbol{\Omega}$}, o in termini tecnici, la più piccola $\sigma$-algebra che contiene gli aperti di $\Omega$.

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che, innanzitutto, una probabilità è una \textbf{misura}, una misura della facilità con cui un evento si verifica e come qualsiasi altra misura presenta la seguente proprietà: se di tale oggetto se ne misurano le parti distinte (senza sovrapposizioni) per conoscere la misura dell'oggetto complessivo, è sufficiente sommare fra loro le singole misure distinte.

\vspace{1em}
\noindent
Volendo determinare ulteriori proprietà generali degli spazi di probabilità:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{PROPRIETÀ DELLO SPAZIO DI PROBABILITÀ}}\\
    \parbox{\linewidth}{Sia $\left(\Omega,\mathcal{A},p\right)$ uno spazio di probabilità
    \begin{itemize}
      \item se $\left\{A_n\right\}$ è una successione crescente di eventi, cioé $A_n \subset A_{n+1}, \forall n \in \mathbb{N}$, allora
      \[p \left(\bigcup_{k=1}^\infty A_n\right) = \lim_{n \to \infty} p(A_n) \hspace{1em} \left[\textbf{continuità dal basso}\right]\]
      ovvero la probabilità dell'unione di tali eventi dipende unicamente dal comportamento asintotico dell'ultimo evento, che contiene tutti gli altri, ovvero l'evento $A_n$

      \item se $\left\{A_n\right\}$ è una successione decrescente di eventi, cioé $A_{n+1} \subset A_{n}, \forall n \in \mathbb{N}$, allora
      \[p \left(\bigcap_{k=1}^\infty A_n\right) = \lim_{n \to \infty} p(A_n) \hspace{1em} \left[\textbf{continuità dall'alto}\right]\]
    \end{itemize}
    \vspace{1mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Dimostrazione $\boldsymbol{1}$}: È possibile scrivere $\forall n \in \mathbb{N}$, grazie al fatto che si sta lavorando con successioni crescenti
\[\bigcup_{k=1}^n A_k = A_1 \cup \bigcup_{k=2}^n \left(A_k - A_{k-1}\right)\]
in modo tale da operare con insiemi disgiunti. Poiché
\[\bigcup_{k=1}^\infty A_k = A_1 \cup \bigcup_{k=2}^\infty \left(A_k - A_{k-1}\right)\]
ovvero si sta considerando un insieme infintio di insiemi a due a due disgiunti, usando la $\sigma$-additività si ottiene
\[p \left(\bigcup_{k=1}^\infty A_k\right) = p(A_1) + \sum_{k=2}^\infty p \left(A_k - A_{k-1} \right)\]
sfruttando il concetto di serie, una sommatoria infinita può essere considerata come il limite delle somme parziali, ovvero si ha che
\[p(A_1) + \sum_{k=2}^\infty p \left(A_k - A_{k-1}\right) = p(A_1) + \lim_{n \to +\infty} \sum_{k=2}^n p \left(A_k - A_{k-1}\right)\]
Dal momento che $p(A_1)$ è un numero reale, può essere tranquillamente portato dentro il limite, ottenendo
\[p(A_1) + \lim_{n \to +\infty} \sum_{k=2}^n p \left(A_k - A_{k-1} \right) = \lim_{n \to +\infty} \left[p(A_1) + \sum_{k=2}^n p \left(A_k - A_{k-1}\right)\right]\]
Sfruttando ancora l'additività si possono rimettere nuovamente insieme tutti gli insiemi e calcolare il limite della probabilità dell'unione, come mostrato di seguito:
\[\lim_{n \to +\infty} \left[p(A_1) + \sum_{k=2}^n p \left(A_k - A_{k-1}\right)\right] = \lim_{n \to +\infty} p\left(A_1 \cup \bigcup_{k=2}^n \left(A_k - A_{k-1}\right) \right) = \lim_{n \to +\infty} p(A_n)\]

\vspace{1em}
\noindent
\textbf{Dimostrazione $\boldsymbol{2}$}: Per la dimostrazione della seconda proprietà, si deve osservare che $\{A_1 - A_n\}$ è una successione necessariamente crescente. Dopo questa prima osservazione si può facilmente scrivere che
\[p(A_1) - p \left(\bigcap_{k=2}^{\infty} A_k\right) = p \left(A_1 - \bigcap_{k=2}^\infty A_k\right)\]
questo sfruttando il fatto che
\[\bigcap_{k=2}^\infty A_k \subset A_1\]
Inoltre, dal momento che l'intersezione degli $A_k$ è uguale all'unione dei complementari si ottiene
\[p \left(A_1 - \bigcap_{k=2}^\infty A_k\right) = p \left(A_1 \cap \bigcup_{k=2}^\infty A_k^c\right)\]
Ora, invece, sfruttando la proprietà distributiva, si ha che $A_1$ intersecato con l'unione è uguale all'unione delle intersezioni, per cui
\[p \left(A_1 \cap \bigcup_{k=2}^\infty A_k^c\right) = p \left( \bigcup_{k=2}^\infty \left(A_1 \cap A_k^c\right)\right)\]
Ma naturalmente si ha che $A_1 \cap A_k^c = A_1 - A_k$, ovvero l'intersezione tra $A_1$ e il complementare di $A_k$ è $A_1$ a cui viene tolto $A_k$, per cui
\[p \left( \bigcup_{k=2}^\infty \left(A_1 \cap A_k^c\right)\right) = p \left( \bigcup_{k=2}^\infty \left(A_1 - A_k\right)\right)\]
Ma per l'osservazione iniziale, si ha che $A_1 - A_k$ è una successione crescente, per cui per la \textbf{continuità dal basso} dimostrata in precedenza, segue che
\[p \left( \bigcup_{k=2}^\infty \left(A_1 - A_k\right)\right) = \lim_{n \to +\infty} p \left(A_1 - A_n\right) = p(A_1) - \lim_{n \to +\infty} p(A_n)\]
Per cui si è ottenuto, alla fine, che
\[p(A_1) - p \left(\bigcap_{k=2}^{\infty} A_k\right) = p(A_1) - \lim_{n \to +\infty} p(A_n) \longrightarrow p \left(\bigcap_{k=2}^{\infty} A_k\right) = \lim_{n \to +\infty} p(A_n)\]





























\end{document}
