\documentclass[a4paper]{extarticle}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\selectlanguage{italian}
\usepackage[table]{xcolor}
\usepackage{xcolor}
\usepackage{circuitikz}
\usetikzlibrary{positioning, circuits.logic.US}
\usetikzlibrary{shapes.geometric, arrows}
\usetikzlibrary {shapes.gates.logic.US, shapes.gates.logic.IEC, calc}
\tikzset {branch/.style={fill, shape = circle, minimum size = 3pt, inner sep = 0pt}}
\usetikzlibrary{matrix,calc}
\usepackage{multirow}
\usepackage{float}
\usepackage{geometry}
\usepackage{tabularx}
\usepackage{pgf-pie}
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color, soul}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{subfig}
\graphicspath{ {./img/} }
\newtheorem{theorem}{Teorema}[section]
\newtheorem{corollary}{Corollario}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

% Specifiche
\geometry{
 a4paper,
 top=20mm,
 left=30mm,
 right=30mm,
 bottom=30mm
}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LO]{\nouppercase{\leftmark}}
\fancyfoot[CE, CO]{\thepage}
\addtolength{\headheight}{1em}
\addtolength{\footskip}{-0.5em}

\newcommand{\quotes}[1]{``#1''}
\renewcommand\tabularxcolumn[1]{>{\vspace{\fill}}m{#1}<{\vspace{\fill}}}
\renewcommand\arraystretch{}
\newcolumntype{P}{>{\centering\arraybackslash}X}

\makeatletter
\DeclareRobustCommand{\iscircle}{\mathord{\mathpalette\is@circle\relax}}
\newcommand\is@circle[2]{%
  \begingroup
  \sbox\z@{\raisebox{\depth}{$\m@th#1\bigcirc$}}%
  \sbox\tw@{$#1\square$}%
  \resizebox{!}{\ht\tw@}{\usebox{\z@}}%
  \endgroup
}
\makeatother

\newcommand*\circled[2]{\tikz[baseline=(char.base)]{
            \node[shape=circle,fill=#1,draw,inner sep=2pt] (char) {#2};}}

\title{\textbf{Università di Trieste\\ \vspace{1em}
Laurea in ingegneria elettronica e informatica}}
\author{Enrico Piccin - Corso di Probabilità e Statistica - Prof. Marco Barchiesi}
\date{Anno Accademico 2021/2022 - 3 Marzo 2022}

\begin{document}

\vspace{-10mm}
\maketitle

\tableofcontents
\newpage

\noindent
\begin{center}
  3 Marzo 2022
\end{center}

\section{Introduzione}
Si supponga di stare in un \textbf{universo deterministico}, ovvero tale per cui tutto ciò che accadrà in futuro è determinato dalla situazione nel preciso istante in cui si sta vivendo.\\
Dal punto di vista fisico, si supponga di voler analizzare un certo fenomeno, a patto di conoscere
\begin{enumerate}
  \item la legge che regola tale fenomeno
  \item i dati iniziali (riferiti allo stato iniziale del fenomeno)
  \item le condizioni esterne al fenomeno oggetto di interesse
\end{enumerate}
è sempre possibile predire quello che accadrà nel futuro relativamente al fenomeno oggetto di studio.

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri il \textbf{lancio di un dado}. Taluno è un fenomeno oggetto di studio e, come tale, deve essere analizzato conoscendo
\begin{enumerate}
  \item la legge che regola il fenomeno: la legge di caduta dei gravi
  \item i dati iniziali del problema: peso del dado, altezza inziale, forza di attrazione gravitazionale, etc.
  \item le condizioni esterne: vento, umidità, stabilità dell'aria, etc.
\end{enumerate}
Naturalmente, attraverso queste informazioni, è possibile predire il comportamento del dado: quando esso viene lasciato, cade e si schianta al suolo.\\
Tuttavia, se ora si volesse anche sapere su che faccia il dado atterrerà, non si ha a disposizione un legge fisica che ne regola tale fenomeno, in quanto la legge di caduta dei gravi presuppone il corpo come puntiforme; inoltre il movimento dell'aria influenza significativamente la rotazione del corpo.\\
Pertanto, per la determinazione dell'esito di tale fenomeno, non si hanno a disposizione informazioni sufficienti: non si conosce la legge che regola il fenomeno, i dati iniziali sono scarsamente influenti e le condizioni esterne sono troppo variabili. Ciò fa sì che l'output finale di tale fenomeno sia completamente sconosciuto, in quanto l'evento oggetto d'analisi è totalmente \textbf{casuale}, o più propriamente \textbf{aleatorio}.\\
Si noti, ovviamente, che anche per fenomeni apparentemente facili da predire, le condizioni iniziali che vengono poste per lo studio degli stessi comportano sempre un margine di incertezza e, quindi, di aleatorietà: non si può sempre sapere con precisione assoluta lo stato iniziale del sistema oggetto di studio.\\
Per cercare di far fronte a tale incertezza si può
\begin{itemize}
  \item impiegare una legge molto più particolareggiata (più vicina alla perfezione) che regola il fenomeno interessato; misurare con maggiore precisione i dati iniziali e definire con più raffinatezza le conidizione esterne; tuttavia, tale procedimento comporterebbe un lavoro molto oneroso e scarsamente proficuo;
  \item cercare di capire quali sono i possibili output del fenomeno (ossia le $6$ facce del dado) e associare a ciascuno di tali output un valore che fornisca un'informazione di carattere quantitativo in riferimento alla possibilità che esso sia l'effettivo output del fenomeno interessato.
\end{itemize}
Da quest'ultima alternativa segue la definizione di \textbf{probabilità}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{PROBABILITÀ}}\\
    \parbox{\linewidth}{La \textbf{probabilità} è un modo per \textbf{quantificare} quanto un possibile risultato sia \textbf{facilmente ottenibile}.\vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri il ancio di un dado a $6$ facce e si prendano in considerazione dei possibili risultati
\begin{enumerate}
  \item esce il numero $6$
  \item esce un numero pari
  \item esce un numero $\leq 6$
  \item esce un numero $\leq 4$
  \item esce un numero $\geq 7$
\end{enumerate}
Si capisce facilmente come il primo risultato (o evento) sia molto elementare, in quanto prende in considerazione una sola faccia del dado, mentre i restanti sono dei risultati (o eventi) più complessi, che si ottengono tramite aggregazione dei risultati elementari.\\
Dal punto di vista matematica, per l'analisi di questo fenomeno, si definisce un insieme $\Omega$ dei possibili risultati elementari del lancio di un dado, ovvero
\[\Omega = \left\{1,2,3,4,5,6\right\}\]
Naturalmente, ora, i risultati che sono stati esposti in principio non sono altro che dei \textbf{sottoinsiemi} dell'insieme $\Omega$ appena definito, come mostrato di seguito:
\begin{enumerate}
  \item \(A = \left\{6\right\}\)
  \item \(A = \left\{2,4,6\right\}\)
  \item \(A = \left\{1,2,3,4,5,6\right\} = \Omega\)
  \item \(A = \left\{1,2,3,4\right\}\)
  \item \(A = \varnothing\)
\end{enumerate}
Per attribuire a ciascuno di tali risultati un valore quantitativo che ne descriva la possibilità di verificarsi, si definisce $p = p(A)$ come la \textbf{probabilità associata al risultato $A$}, ovverosia un numero all'interno di una scala che, per convenzione, viene indicata nell'intervallo $\left[0,1\right]$, che quantifica la facilità con cui il risultato si presenta.\\
Per esempio, la probabilità che esca un numero maggiore di $7$ nel lancio di un dado a $6$ facce è ovviamente nulla, in quanto a tale evento viene associato l'insieme vuoto. Questo significa che tale risultato (o evento) è \textbf{impossibile}, pertanto si assegna ad esso un valore di probabilità di fondo scala, ovvero
\[p(\varnothing) = 0\]
Analogamente, la probabilità che esca un numero minore o uguale a $6$ nel lancio di un dado è ovviamente massima, in quanto a tale evento viene associato l'insieme $\Omega$ stesso. Questo significa che tale risultato (o evento) è \textbf{certo}, pertanto si assegna ad esso un valore di probabilità di fine scala, ovvero
\[p(\Omega) = 1\]
È facile capire che se si considerano due eventi a cui sono associati due sottinsiemi $A$ e $B$ disgiunti, tali per cui $A \cap B = \varnothing$, allora si avrà che
\[p(A \cup B) = p(A) + p(B)\]
Inoltre, se il dado è regolare, ha senso ed è plausibile associare lo stesso valore di probabilità a ciascuno degli eventi elementari, ovvero
\[p \left(\left\{1\right\}\right) = p \left(\left\{2\right\}\right) = p \left(\left\{3\right\}\right) = p \left(\left\{4\right\}\right) = p \left(\left\{5\right\}\right) = p \left(\left\{6\right\}\right)\]
e se ora si sommano le probabilità di tutti gli eventi elementari, non si può non ottenere la probabilità dell'evento certo, ovvero
\[p \left(\left\{1\right\}\right) + p \left(\left\{2\right\}\right) + p \left(\left\{3\right\}\right) + p \left(\left\{4\right\}\right) + p \left(\left\{5\right\}\right) + p \left(\left\{6\right\}\right) = p(\Omega) = 1\]
Per implicazione logica, siccome la somma delle probabilità degli eventi elementari è pari a $1$ ed essi sono \textbf{equiprobabili}, deve essere necessariamente che
\[p \left(\left\{1\right\}\right) = p \left(\left\{2\right\}\right) = p \left(\left\{3\right\}\right) = p \left(\left\{4\right\}\right) = p \left(\left\{5\right\}\right) = p \left(\left\{6\right\}\right) = \frac{1}{6}\]
A partire da tale evidenza, è possibile ora andare ad associare agli eventi complessi, aggregati di eventi elementari, una probabilità, come di seguito esposto
\[p \left(\left\{2,4,6\right\}\right) = p \left(\left\{2\right\}\right) + p \left(\left\{4\right\}\right) + p \left(\left\{6\right\}\right) = \frac{3}{6} = \frac{1}{2}\]
e similmente
\[p \left(\left\{1,2,3,4\right\}\right) = p \left(\left\{1\right\}\right) + p \left(\left\{2\right\}\right) + p \left(\left\{3\right\}\right) + p \left(\left\{4\right\}\right) = \frac{4}{6} = \frac{2}{3}\]
Naturalmente, ora, se si dovesse definire la probabilità associata alla somma di due eventi non disgiunti, non si può ricorrere alla formula precedentemente esposta, in quanto bisogna anche tenere conto delle sovrapposizioni. Infatti
\[\frac{7}{6} = p \left(\left\{2,4,6\right\}\right) + p \left(\left\{1,2,3,4\right\}\right) \neq p \left(\left\{1,2,3,4,6\right\}\right) = \frac{5}{6}\]
questo perché, per quanto si è detto, i due sottoinsieme associati ai rispettivi risultati non sono disgiunti, in quanto \(\left\{2,4,6\right\} \cap \left\{1,2,3,4\right\} = \left\{2,4\right\}\)

\vspace{1em}
\subsection{Matematica della probabilità}
Il compito della probabilità è quello di fornire delle regole, a partire dalle quali riuscire ad attribuire una valutazione quantitativa della possibilità di verificarsi di eventi più complessi, \textbf{basandosi sulla probabilità associata ad eventi più elementari}.\\
Non è, invece, compito della probabilità quello di attribuire i valori di probabilità agli eventi elementari (si pensi, banalmente, alla differenza tra un dado regolare e un dado truccato): infatti, tale compito è affidato alla statistica, in quanto molto più legato alla praticità e alla modalità dei assegnazione.\\
Una volta appresa l'assegnazione della probabilità agli eventi elemantari, interviene la probabilità: in particolare, la struttura matematica alla base del calcolo della probabilità prevede tre importanti elementi
\begin{enumerate}
  \item un insieme $\Omega$ (che per il momento si considera finito);
  \item una famiglia $\mathcal{A}$ (non vuota) di sottoinsiemi di $\Omega$ (spesso la famiglia di tutti i sottoinsieme); mentre gli elementi di $\Omega$ sono chiamati risultati elementari, gli elementi sottoinsiemi di $\Omega$ appartenenti a tale famiglia sono chiamati risultati complessi, ottenuti come aggregazione di risultati elementari;
  \item un'applicazione
  \[p : \mathcal{A} \longrightarrow \left[0,1\right]\]
  che ad ogni sottoinsieme appartenente alla famiglia $\mathcal{A}$ associa un valore compreso tra $0$ e $1$.
\end{enumerate}
Gli elementi di $\Omega$ sono detti \textbf{eventi elementari}, per cui $\Omega$ è detto \textbf{spazio degli eventi elementari}, mentre gli elementi della famiglia $\mathcal{A}$ prendono il nome di \textbf{risultati} (o eventi) \textbf{casuali} (o semplicemente eventi, configurazioni, traiettorie, campioni), per cui $\mathcal{A}$ prende il nome di \textbf{spazio degli eventi casuali}.\\
Se due eventi hanno un'intersezione nulla (come numeri pari e numeri dispari), si dice che essi sono \textbf{mutualmente esclusivi}.\\
L'applicazione $p$ è detta \textbf{probabilità}, mentre l'immagine attraverso $p$ di un evento $A$, ovvero $p(A)$ viene chiamata \textbf{probabilità dell'evento $A$}.

\vspace{1em}
\subsection{Regole della famiglia di eventi complessi}
La famiglia di eventi complessi $\mathcal{A}$, così come l'applicazione $p$, è sempre subordinata alla presenza di alcune importanti condizioni:
\begin{enumerate}
  \item tra gli elementi della famiglia degli eventi complessi $\mathcal{A}$ ci deve essere sempre l'\textbf{evento certo}:
  \[\Omega \in \mathcal{A}\]

  \item tra gli elementi della famiglia degli eventi complessi $\mathcal{A}$ ci deve essere sempre l'\textbf{evento impossibile}:
  \[\varnothing \in \mathcal{A}\]

  \item se tra gli elementi della famiglia degli eventi complessi $\mathcal{A}$ si considerano gli eventi $A$ e $B$, ad $\mathcal{A}$ deve appartenere anche la loro \textbf{unione} e la loro \textbf{intersezione}:
  \[A \cup B \in \mathcal{A} \hspace{0.5em} \text{e} \hspace{0.5em} A \cap B \in \mathcal{A}\]

  \item se tra gli elementi della famiglia degli eventi complessi $\mathcal{A}$ si considera l'evento $A$, ad $\mathcal{A}$ deve appartenere anche il suo opposto:
  \[A^c \in \mathcal{A}\]
\end{enumerate}
Nella pratica, se si lavora con uno spazio degli eventi che è finito, come famiglia dei risultati si considera l'insieme di tutti i risultati possibili, ovvero la famiglia costituita da tutti i sottoinsiemi di $\Omega$ (essendo $\Omega$ \textbf{finito}, l'insieme dei sottoinsiemi di $\Omega$ è ancora una famiglia finita con cui si può lavorare). Quando, invece, $\Omega$ è infinito, non si potrà lavorare con tutti i sottoinsiemi di $\Omega$, ma si dovrà procedere a considerare una sua restrizione (potrebbe, infatti, non essere possibile considerare l'insieme di tutti sottoinsiemi dello spazio degli eventi elementari).\\
Una famiglia $\mathcal{A}$ che soddisfa i quatto punti di cui sopra prende il nome di \textbf{algebra}: l'insieme delle parti è un esempio di algebra.

\vspace{1em}
\subsection{Regole dell'applicazione di probabilità}
L'applicazione $p$ tale per cui
\[p : \mathcal{A} \longrightarrow \left[0,1\right]\]
deve soddisfare, anch'essa, determinate regole:
\begin{enumerate}
  \item l'\textbf{evento certo} deve avere \textbf{probabilità massima}, ovvero
  \[p(\Omega) = 1\]
  \item l'\textbf{evento impossibile} deve avere \textbf{probabilità nulla}, ovvero
  \[p(\varnothing) = 0\]
  \item se due eventi $A$ e $B$ sono mutualmente esclusivi, ovvero tali che i sottoinsiemi di $\Omega$ associati siano disgiunti, ovvero $A \cap B = \varnothing$, allora si ha che
  \[p(A) + p(B) = p(A \cup B)\]
  tale proprietà prende il nome di \textbf{additività} (sempre, però, relativamente a eventi disgiunti).
\end{enumerate}
Un'applicazione $p$ definita come segue
\[p : \mathcal{A} \longrightarrow [0,1]\]
che soddisfa le tre proprietà di cui sopra prende il nome di \textbf{misura di probabilità}.\\


\vspace{1em}
\subsection{Spazio di probabilità}
Dopo aver introdotto il concetto di \textbf{algebra} e \textbf{probabilità} è possibile fornire la definizione di \textbf{spazio di probabilità finito}, (finito in quanto lo spazio degli eventi elementari $\Omega$ è finito):

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{SPAZIO DI PROBABILITÀ FINITO}}\\
    \parbox{\linewidth}{Per definizione si chiama \textbf{spazio di probabilità finito} una \textbf{terna} $\left(\Omega,\mathcal{A},p\right)$ dove
    \begin{itemize}
      \item $\Omega$ è un insieme \textbf{finito} che identifica tutti e soli gli eventi elementari;
      \item $\mathcal{A}$ è un'algebra di sottoinsiemi di $\Omega$ (che, in quanto algebra, soddisfa le $4$ regole precedentemente esposte), generalmente data da tutti i sottoinsiemi di $\
      Omega$;
      \item $p$ è una probabilità su $\mathcal{A}$ (che, essendo una probabilità, soddisfa le $3$ regole precedentemente esposte).
    \end{itemize}
    \vspace{1mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\subsubsection{Proposizione 1 - Proprietà degli spazi di probabilità finiti}
\label{sec:proposizione_1}
Le proprietà degli spazi di probabilità finiti discendono dalle richieste, ossia dalle regole, definite in merito alla famiglia degli eventi complessi $\mathcal{A}$, la quale deve essere un'\textbf{algebra} e sulla funzione $p$, la quale deve essere una \textbf{probabilità}:

\begin{enumerate}
  \item \textbf{Proprietà additiva e subadditiva}: di seguito si espone la definizione di proprietà additiva e subadditiva della probabilità:

  % Tabella per le definizione di concetti, etc...
  \vspace{1em}
  \rowcolors{1}{black!5}{black!5}
  \setlength{\tabcolsep}{14pt}
  \renewcommand{\arraystretch}{2}
  \noindent
  \begin{tabularx}{\textwidth}{@{}|P|@{}}
      \hline
      {\textbf{PROPRIETÀ ADDITIVA E SUBADDITIVA}}\\
      \parbox{\linewidth}{Se $A_1,...,A_n \in \mathcal{A}$ e sono a due a due \textbf{disgiunti} (ovvero mutualmente esclusivi), allora
      \[\sum_{k=1}^n p \left(A_k\right) = p \left(\bigcup_{k=1}^n A_k\right)\]
      ciò significa che  la probabilità è \textbf{additiva}.\\
      Se gli eventi non sono a due a due digiunti, allora è possibile solo affermare che
      \[\sum_{k=1}^n p \left(A_k\right) \geq p \left(\bigcup_{k=1}^n A_k\right)\]
      In particolare, è sempre verificato che
      \[p(A) + p(B) \geq p(A \cup B), \hspace{0.5em} \forall A,B \in \mathcal{A}\]
      ciò significa che la probabilità è \textbf{subadditiva}.
      \vspace{3mm}}\\
      \hline
  \end{tabularx}

  \vspace{1em}
  \noindent
  \textbf{Dimostrazione $\boldsymbol{1}$}: La proprietà di additività e subadditività si dimostra per \textbf{induzione}: si chiami $B$ l'evento così ottenuto
  \[B = \bigcup_{k=1}^{n-1}A_k\]
  Dal momento che per ipotesi gli eventi $A_1,...,A_n \in \mathcal{A}$ sono disgiunti, deve essere che
  \[A \cap \bigcup_{k=1}^{n-1}A_k = A \cap B = \varnothing\]
  e quindi si ha che
  \[p\left(\bigcup_{k=1}^{n}A_k\right) = p(A_n) + p\left(\bigcup_{k=1}^{n-1}A_k\right)\]
  sfruttando la proprietà di \textbf{additività della probabilità rispetto ad eventi disgiunti} (ossia la proprietà $3$ della probabilità).\\
  Si procede analogamente, per induzione a scendere su $n$ fino a ottenere che
  \[p \left(\bigcup_{k=1}^n A_k\right) = \sum_{k=1}^n p \left(A_k\right)\]
  Per dimostrare anche la seconda implicazione, si deve ricorrere alla proprietà fondamentale dimostrata di seguito, la quale permette di affermare che, siccome $p(A \cap B) \geq 0$, allora
  \[p(A \cup B) + p(A \cap B) = p(A) + p(B) \longrightarrow p(A) + p(B) \geq p(A \cup B)\]
  Ancora una volta, per dimostrare la proprietà di cui sopra si procede per \textbf{induzione}: avendo dimostrato il passo base con $n=2$, si suppone che tale proprietà sia verificata per $n-1$ e la si dimostri per $n$; appare evidente che se si considerano $n$ eventi non a due a due disgiunti, tali per cui
  \[A_n \cap \bigcup_{k=1}^{n-1}A_k \neq \varnothing\]
  allora segue che
  \[p\left(\bigcup_{k=1}^{n}A_k\right) \leq p(A_n) + p\left(\bigcup_{k=1}^{n-1}A_k\right)\]
  ma usando l'ipotesi induttiva si perviene al risultato seguente
  \[\sum_{k=1}^n p \left(A_k\right) \geq p \left(\bigcup_{k=1}^n A_k\right)\]

  \vspace{2em}
  \noindent
  \item \textbf{Proprietà fondamentale}: di seguito si espone una relazione fondamentale che riguarda il calcolo della probabilità:

  % Tabella per le definizione di concetti, etc...
  \vspace{1em}
  \rowcolors{1}{black!5}{black!5}
  \setlength{\tabcolsep}{14pt}
  \renewcommand{\arraystretch}{2}
  \noindent
  \begin{tabularx}{\textwidth}{@{}|P|@{}}
      \hline
      {\textbf{PROPRIETÀ FONDAMENTALE}}\\
      \parbox{\linewidth}{Si verifica che
      \[p(A \cup B) + p(A \cap B) = p(A) + p(B), \hspace{0.5em} \forall A,B \in \mathcal{A}\]
      \vspace{-1mm}}\\
      \hline
  \end{tabularx}

  \vspace{1em}
  \noindent
  \textbf{Dimostrazione $\boldsymbol{2}$}: Per dimostrare la proprietà fondamentale è opportuno osservare che $A \cup B$ può essere vista come l'unione di tre \textbf{insiemi disgiunti}:
  \[A - (A \cap B) \hspace{1em} A \cap B \hspace{1em} B - (A \cap B)\]
  ovvero
  \[A \cup B = \left(A - (A \cap B)\right) \cup \left(A \cap B\right) \cup \left(B - (A \cap B)\right)\]
  sfruttando ancora la proprietà di \textbf{additività della probabilità rispetto ad eventi disgiunti} nel caso $n = 3$ e la proprietà di \textbf{monotonia} dimostrata di seguito, osservando che $A \cap B \subset A$ e $A \cap B \subset B$ si può concludere che
  \begin{flalign*}
    p(A \cup B) & = p\left(A - (A \cap B)\right) + p\left(A \cap B\right) + p\left(B - (A \cap B)\right)\\
    & = p(A) - p(A \cap B) + p(A \cap B) + p(B) - p(A \cap B) = p(A) + p(B) - p(A \cap B)
  \end{flalign*}

  \newpage
  \noindent
  \item \textbf{Proprietà di monotonia}: di seguito si espone la proprietà che giustifica la monotonia della probabilità:

  % Tabella per le definizione di concetti, etc...
  \vspace{1em}
  \rowcolors{1}{black!5}{black!5}
  \setlength{\tabcolsep}{14pt}
  \renewcommand{\arraystretch}{2}
  \noindent
  \begin{tabularx}{\textwidth}{@{}|P|@{}}
      \hline
      {\textbf{PROPRIETÀ DI MONOTONIA}}\\
      \parbox{\linewidth}{Si verifica che
      \[p(A - B) = p(A) - p(B), \hspace{0.5em} \forall A,B \in \mathcal{A} : B \subset A\]
      In particolare, dal momento che $p(A - B) \geq 0$, allora deve essere che
      \[B \subset A \longrightarrow p(B) \leq p(A)\]
      ciò significa che la probabilità è \textbf{monotona} (\textbf{crescente}), come intuitivamente ci si poteva aspettare.
      \vspace{3mm}}\\
      \hline
  \end{tabularx}

  \vspace{1em}
  \noindent
  \textbf{Dimostrazione $\boldsymbol{3}$}: È facile osservare che gli eventi $A - B$ e l'evento $B$ sono, per costruzione, due eventi mutualmente esclusivi (e quindi disgiunti); inoltre deve essere $(A - B) \cup B = A$, dal momento che $B \subset A$. Ciò permette di concludere che
  \[p(A - B) + p(B) = p((A - B) \cup B) = p(A)\]
  sfruttando la proprietà di \textbf{additività della probabilità rispetto ad eventi disgiunti}.
\end{enumerate}

\vspace{1em}
\noindent
\begin{corollary}
  \textbf{Osservazione}: Se si considera un evento $A \in \mathcal{A}$, allora si ha che
  \[p(A^c) = 1 - p(A)\]
\end{corollary}

\vspace{1em}
\noindent
\textbf{Dimostrazione}: La dimostrazione è presto fatta e segue dai risultati precedenti. Infatti è ovvio che $A$ e $A^c$ sono due eventi disgiutni e che $A \cup A^c = \Omega$. Pertanto, sfruttando la \textbf{proprietà di additività della probabilità rispetto ad eventi digiunti} e la probabilità dell'\textbf{evento certo} si ottiene che
\[p(A \cup A^c) = p(\Omega) = p(A) + p(A^c) \longrightarrow p(A) = 1 - p(A^c)\]

\vspace{1em}
\subsubsection{Costruzione di spazi di probabilità finiti}
Si consideri un \textbf{insieme finito} $\Omega = \left\{\omega_1,...,\omega_n\right\}$ di eventi elementari (che prenderà il nome di \textbf{spazio campione}) e un insieme $\Delta = \left\{\alpha_1,...,\alpha_n\right\}$ di \textbf{numeri reali positivi} la cui somma deve produrre il valore $1$, ovvero
\[\sum_{k=1}^n \alpha_k = 1 \hspace{0.5em} \text{con} \hspace{0.5em} \alpha_k \in \mathbb{R}, \alpha_k \geq 0\]
Per la costruzione dello spazio di probabilità si considera come \textbf{algebra} $\mathcal{A}$ degli eventi complessi (o aggregati) l'\textbf{insieme delle parti} di $\Omega$ e si definisce una funzione
\[p : \mathcal{A} \longrightarrow [0,1]\]
considerando i valori $\alpha_1,...,\alpha_n$ come i valori di probabilità che verranno attribuiti a ciascun evento elementare di $\Omega$, ovverosia
\[p(\left\{\omega_k\right\}) = \alpha_k, \hspace{0.5em} \text{con} \hspace{0.5em} k=1,...,n\]
Tale concetto deve poi essere esteso a qualsiasi evento $A \in \mathcal{A}$ non vuoto, quale il seguente
\[A = \left\{\omega_{k,1},...,\omega_{k,m}\right\}\]
ovvero un sottoinsieme non vuoto di $\Omega$. Allora la probabilità dell'evento $A$ sarà definita come segue
\[p(A) = \sum_{j=1}^m p(\left\{\omega_{k,j}\right\}) = \sum_{j=1}^m \alpha_{k,j} = \sum_{\omega \in A} p(\left\{\omega\right\})\]
ponendo, per semplicità, $p(\varnothing)=0$. In altre parole, \textbf{la probabilità di $A$ è la somma delle probabilità degli eventi elemntari che costituiscono $A$}.\\
Mentre la famiglia $\mathcal{A}$ è necessariamente un'\textbf{algebra} (in quanto soddisfa le $4$ proprietà precedentemente esposte), in quanto l'insieme delle parti di $\Omega$, è opportuno verificare che la funzione $p$ presa in considerazione sia, effettivamente, una probabilità:
\begin{enumerate}
  \item La probabilità dell'evento certo è naturalmente $1$ per costruzione, in quanto
  \[p(\Omega) = \sum_{k=1}^n p \left(\left\{w_k\right\}\right) = \sum_{k=1}^n \alpha_k = 1\]
  \item Per costruzione, la probabilità dell'evento impossibile è nulla, ovvero:
  \[p(\varnothing)=0\]
  \item Si verifica immediatamente, infine, che la funzione $p$ è effettivamente additiva rispetto a eventi disgiunti, ovvero
  \[p(A \cup B) = \sum_{\omega \in A \cup B} p\left(\left\{w\right\}\right) = \sum_{\omega \in A} p\left(\left\{w\right\}\right) + \sum_{\omega \in B} p\left(\left\{w\right\}\right)\]
  essendo $A$ e $B$ disgiunti, ovvero $A \cup B = A + B$.
\end{enumerate}

\vspace{1em}
\noindent
\textbf{Esempio $\boldsymbol{1}$}: Nel caso di un dado regolare a sei facce, si è posto
\[\omega_k = k \hspace{0.5em} \text{e} \hspace{0.5em} \alpha_k = \frac{1}{6}\]
ovverosia
\[\Omega= \left\{1,...,6\right\} \hspace{0.5em} \text{e} \hspace{0.5em} \Delta=\left\{\frac{1}{6},...,\frac{1}{6}\right\}\]

\vspace{1em}
\noindent
\textbf{Esempio $\boldsymbol{2}$}: Si consideri il lancio di due dadi regolari, ambedue a sei facce. Lo spazio degli eventi elementari è
\[\Omega = \left\{(1,1),(1,2),...,(1,6),(2,1),(2,2),...,(6,1),(6,2),...,(6,6)\right\}\]
ovvero un insieme finito costituito da $36$ elementi. Assumendo che i dadi siano uguali e con facce uniformi, è naturale pensare che la probabilità che esca uno degli eventi elementari sia la stessa, ovvero
\[p\left(\left\{(1,1)\right\}\right) = p\left(\left\{(1,2)\right\}\right) = ... = p\left(\left\{(6,6)\right\}\right)\]
Il valore della probabilità di ciascuno degli eventi elementari è $\frac{1}{36}$: questo in quanto la somma delle probabilità di tutti gli eventi elementari deve essere $1$. In questo caso, si sta quindi ponendo
\[\alpha_k = \frac{1}{36} \hspace{0.5em} \text{per} \hspace{0.5em} k=1,...,36\]
Pertanto, considerando come algebra $\mathcal{A}$ degli eventi l'insieme delle parti di $\Omega$ e definendo una probabilità $p$ su $\mathcal{A}$ come esposto in precedenza, se $A \in \mathcal{A}$, allora

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{white}{white}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{>{\hsize=0.02\textwidth}P>{\hsize=0.01\textwidth}PP>{\hsize=0.01\textwidth}PP}
  $p(A)$ & $=$ & \parbox{\linewidth}{\vspace{3mm} somma delle probabilità degli eventi elementari che appartengono ad $\mathcal{A}$\vspace{3mm}} & $=$ & \parbox{\linewidth}{\vspace{3mm} numero degli elementi di $\mathcal{A}$ moltiplicato per $\frac{1}{36}$\vspace{3mm}}\\
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Esempio}: Si calcoli, ora, la probabilità dei seguenti eventi complessi:
\begin{enumerate}
  \item escono due numeri uguali
  \item la somma dei due numeri fa $8$
  \item almeno uno dei due numeri è pari
\end{enumerate}

\vspace{1em}
\noindent
\textbf{Esempio $\boldsymbol{1}$}: Al primo evento è associato il sottoinsieme
\[A = \left\{(1,1),(2,2),...,(6,6)\right\}\]
costituito da $6$ elementi. Quindi si evince che
\[p(A) = \frac{6}{36} = \frac{1}{6}\]
Infatti, dopo aver assegnato in maniera arbitraria i valori di probabilità agli eventi elementari, si adopera l'insieme delle regole del calcolo della probabilità al fine di determinare la probabilità degli eventi complessi (o aggregati).

\vspace{1em}
\noindent
\textbf{Esempio $\boldsymbol{2}$}: Al secondo evento è associato il sottoinsieme
\[A = \left\{(2,6),(3,5),(4,4),(5,3),(6,2)\right\}\]
costituito da $5$ elementi. Quindi si evince che
\[p(A) = \frac{5}{36}\]

\vspace{1em}
\noindent
\textbf{Esempio $\boldsymbol{1}$}: Al primo evento è associato il sottoinsieme
\[A = \left\{
  \begin{array}{l}
    (2,1),...,(2,6),(4,1),...,(4,6),(6,1),...,(6,6),\\
    (1,2),(1,4),(1,6),(3,2),(3,4),(3,6),(5,2),(5,4),(5,6)
  \end{array}
\right\}\]
costituito da $27$ elementi. Quindi si evince che
\[p(A) = \frac{27}{36} = \frac{3}{4}\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi, ancora una volta, che la scelta di porre
\[\alpha_k = \frac{1}{36} \hspace{0.5em} \text{per} \hspace{0.5em} k=1,...,36\]
è di \textbf{natura totalmente arbitraria} e basata su considerazioni empiriche (dadi uguali, facce uniformi, etc.). Se i dadi avessero delle anomalie (fossero, per esempio, truccati), sarebbe più ragionevole pesare in modo diverso le probabilità degli eventi elementari.\\
Per esempio, se ci fosse uno squilibrio di peso sulle facce $1$ dei dadi, si potrebbe decidere di porre
\begin{flalign*}
  p \left(\left\{(1,1)\right\}\right) & = \frac{1}{9}\\
  p \left(\left\{(1,2)\right\}\right) & = p \left(\left\{(1,6)\right\}\right) = p \left(\left\{(2,1)\right\}\right) = ... = p \left(\left\{(6,1)\right\}\right) = \frac{1}{18}\\
  \hspace{-2em} \text{e sui restanti } 25 \text{ eventi elementari porre}\\
  p \left(\left\{(...,...)\right\}\right) & = \left(1-\frac{1}{9}-\frac{10}{18}\right) \cdot \frac{1}{25} = \frac{1}{75}
\end{flalign*}

\newpage
\section{Serie}
Di seguito si espone la definizione di \textbf{serie numerica}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{SERIE NUMERICA}}\\
    \parbox{\linewidth}{Data una successione di numeri reali $\left\{a_n\right\}_{n \in \mathbb{N}}$, si chiama \textbf{serie numerica} la successione delle somme parziali
    \[\left\{s_n := \sum_{k=1}^n a_k\right\}_{n \in \mathbb{N}}\]
    Più esplicitamente
    \[\left\{
      \begin{array}{l}
        s_1 = a_1\\
        s_2 = a_1 + a_2\\
        ...\\
        s_n = a_1 + ... + a_n\\
        ...
      \end{array}
    \right.\]
    Pertanto, effettuare la sommatoria di infinito termini $a_n$ equivale ad effettuare
    \[\lim_{n \to \infty} s_n\]
    Tale successione si indica con il simbolo
    \[\sum_{k=1}^{\infty}a_k\]
    e si impiega lo stesso simbolo per indicare il limite per $n \to \infty$ (ammesso che esista).\vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{2em}
\noindent
\textbf{Osservazione $\boldsymbol{1}$}: Se la successione $\left\{a_n\right\}$ è una successione di numeri reali non negativi, allora, naturalmente, $\left\{s_n\right\}$ è crescente. Quindi, come ben noto, $\left\{s_n\right\}$ converge, oppure diverge a $+\infty$.

\vspace{2em}
\noindent
\textbf{Osservazione $\boldsymbol{2}$}: È chiaro che il simbolo
\[\sum_{k=1}^{\infty}a_k\]
viene utilizzato per indicare che la somma inzia a partire dal termine $a_1$. Il simbolo
\[\sum_{k=0}^{\infty}a_k\]
invece, è atto a indicare che la somma inzia a partire dal termine $a_0$. Similmente, si impiega il simbolo
\[\sum_{k=3}^{\infty}a_k\]
quando si inizia a sommare a partire dal termine $a_3$.

\vspace{2em}
\noindent
\textbf{Osservazione $\boldsymbol{3}$}: Si osservi che, naturalmente
\[\sum_{k=1}^{\infty}a_k\]
converge \textbf{se e solo se} converge
\[\sum_{k=3}^{\infty}a_k\]
Questo in quanto
\[\sum_{k=1}^{\infty}a_k = a_1 + a_2 + ... + a_{j-1} + \sum_{k=0}^{\infty}a_k\]
per cui il limite a destra esste \textbf{se e solo se} esiste quello di sinistra, in quanto la differenza tra le due successione è costituita soltanto un numero finito di elementi (dalla costante $a_1 + a_2 + ... + a_{j-1}$) che non influiscono sulla convergenza della successione stessa.

\vspace{2em}
\noindent
\textbf{Osservazione $\boldsymbol{4}$}: Si osservi che

\begin{lemma}
  \textbf{Non è vero} che ogni serie converge o diverge a $\pm \infty$.
\end{lemma}

\vspace{2em}
\noindent
\textbf{Esempio}: Si consideri la seguente serie
\[\sum_{k=1}^{\infty}(-1)^k\]
tale serie non converge e non diverge: infatti la somma parziale con $k$ pari converge a $0$, mentre la somma parziale con $k$ dispari converge a $-1$: pertanto la serie di partenza non converge e non diverge, in quanto non esiste il limite della somma di successione.\\
Si parla, in questo caso, di una \textbf{successione oscillante}:
\[s_1=-1,s_2=0,s_3=-1,...\]

\vspace{1em}
\subsection{Condizione necessaria per la convergenza di una serie}
In genere non è facile stabilire se una serie sia convergente o meno (e se anche lo fosse, non è sempre facile stabilire il limite della stessa). Si consideri, a tal proposito, il seguente lemma:

\begin{lemma}
  Si consideri la serie seguente
  \[\sum_{k=1}^\infty a_k\]
  Se essa converge, allora deve essere che
  \[\lim_{n \to \infty} a_n = 0\]
  cioé \textbf{condizione necessaria} affinché una serie converga è che i termini da sommare progressivvamente diventino indefinitivamente piccoli.
\end{lemma}

\vspace{1em}
\subsubsection{Serie armonica}
\textbf{Osservazione}: Si osservi che tale condizione è necessaria, ma \textbf{non sufficiente}. E ciò è facilmente verificabile con l'esempio seguente: si consideri la \textbf{serie armonica} seguente
\[\sum_{k=1}^\infty \frac{1}{k}\]
Tale serie diverge a $+\infty$, anche se
\[\lim_{k \to \infty} = 0\]
in quanto essa va a $0$ troppo lentamente e quindi non ha sufficienza per garantire la convergenza.

\vspace{1em}
\noindent
\textbf{Dimostrazione}: Si dimostri per assurdo che la \textbf{serie armonica} diverge a $+\infty$. Dal momento che taluna è una serie ottenuta come sommatoria di quantità positive o converge, oppure diverge. Si supponga per assurdo che non diverga: allora converge ad un certo $l$, ovvero dovrebbe essere che
\[\lim_{n \to \infty} s_n = l\]
Si può facilmente osservare che la differenza tra le due somme parziali $s_{2n}$ e $s_n$ si può scrivere come
\[s_{2n} - s_n = \sum_{k=n+1}^{2n} \frac{1}{k}\]
questo perché i primi $n$ termini vengono eliminati nella differenza. Inoltre si ha che
\[s_{2n} - s_n = \sum_{k=n+1}^{2n} \frac{1}{k} = \underbrace{\frac{1}{n+1} + \frac{1}{n+2} + ... + \frac{1}{2n}}_\text{$n$ \text{ termini}} \geq n \cdot \frac{1}{2n} = \frac{1}{2}\]
in quanto, ovviamente
\[\frac{1}{n+1} > \frac{1}{n+2} > ... > \frac{1}{2n}\]
ed essi sono proprio $n$ termini. Ciò permette di affermare che
\[\frac{1}{n+1} + \frac{1}{n+2} + ... + \frac{1}{2n} \geq n \cdot \frac{1}{2n} = \frac{1}{2}\]
Per la definizione di limite si ha che definitivamente, ossia per $n$ abbastanza grande, si ha che
\[\forall \epsilon > 0, \exists n_\epsilon \in \mathbb{N} : \forall n \geq n_\epsilon \longrightarrow \left \vert s_n - l \right \vert < \epsilon\]
Ponendo $\epsilon = \frac{1}{4}$ si ottiene che
\[\left \vert s_n - l \right \vert < \frac{1}{4}\]
Da ciò segue che, per la disuguaglianza triangolare e ricordando che $|w|=|-w|$
\[\frac{1}{2} \leq \left \vert s_{2n} - s_n \right \vert = \left \vert s_{2n} - l + l - s_n \right \vert \leq \left \vert s_{2n} - l \right \vert + \left \vert s_{n} - l \right \vert < \frac{1}{4} + \frac{1}{4} = \frac{1}{2}\]
ricordando che il limite delle due somme parziali è identico, dal momento che per $n \to \infty$ $s_{n} \to +\infty$, $s_n \leq s_{2n}$ e si verifica che
\[\lim_{k \to \infty} \frac{1}{k} = 0\]
Dal momento che una quantità non può essere minore di se stessa si ottiene l'assurdo.

\vspace{1em}
\subsection{Serie armonica generalizzata}
Di seguito si fornisce la definizione di \textbf{serie armonica generalizzata}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{SERIE ARMONICA GENERALIZZATA}}\\
    \parbox{\linewidth}{Dato $\alpha \in \mathbb{R}$, la serie
    \[\sum_{k=1}^\infty \frac{1}{k^\alpha}\]
    è detta \textbf{serie armonica generalizzata}.\vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Osservazione}: Anche se la serie armonica è divergente, la presenza di un esponente $\alpha > 1$ sul termine $\frac{1}{k}$ fa sì che le somme parziali crescano più lentamente e quindi ci sia convergenza. Se $\alpha < 1$, invece, la serie che non può che divergere ancora più velocemente.\\
Omettendo la dimostrazione, si può facilmente capire che
\[\sum_{k=1}^\infty \frac{1}{k^\alpha} \left\{
  \rowcolors{1}{white}{white}
  \begin{array}{l}
    \text{diverge a } +\infty \text{ se } \alpha \leq 1\\
    \text{converge se } \alpha > 1\\
  \end{array}
\right.\]

\vspace{1em}
\subsection{Serie geometrica}
Di seguito si fornisce la definizione di \textbf{serie geometrica}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{SERIE GEOMETRICA}}\\
    \parbox{\linewidth}{Dato $Q \in \mathbb{R}$, la serie
    \[\sum_{k=0}^\infty q^k\]
    è detta \textbf{serie geometrica} di ragione $q$ (e parte con $k=0$).\vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Osservazione}: Il comportamento della serie è il seguente:
\[\sum_{k=0}^\infty q^k \left\{
  \rowcolors{1}{white}{white}
  \begin{array}{l}
    \text{converge a } \frac{1}{1-q} \text{ se } q \in (-1,1)\\
    \text{diverge a } +\infty \text{ se } q \geq 1\\
    \text{indeterminata se } q \leq -1
  \end{array}
\right.\]
ove per \textbf{indeterminata} si intende che non converge, né diverge a $\pm \infty$.

\vspace{1em}
\noindent
\textbf{Dimostrazione}: Se $q=1$ il comportamento è ovvio, in quanto si somma indefinitamente il valore $1$, per cui la serie diverge a $+\infty$. Se $q \neq 1$, allora si deve osservare che è possibile scrivere
\[1 - q^{n+1} = (1 - q) \cdot (1 + q + q^2 + ... + q^n)\]
dividendo ambo i mebri per il termine $1 - q \neq 0$ in quanto per ipotesi si è assunto $q \neq 1$, si ottiene il seguente termine generico della serie geometrica:
\[s_n = 1 + q + q^2 + ... + q^n = \frac{1 - q^{n+1}}{1 - q}\]
e la tesi segue per quanto noto sul limite di $q^n$:
\begin{itemize}
  \item se $q \in (-1,1)$, allora ovviamente
  \[\lim_{n \to \infty} q^{n+1} = 0\]
  per cui
  \[\lim_{n \to \infty} \frac{1 - q^{n+1}}{1 - q} = \frac{1}{1-q}\]

  \item se $q > 1$, allora ovviamente
  \[\lim_{n \to \infty} q^{n+1} = +\infty\]
  per cui
  \[\lim_{n \to \infty} \frac{1 - q^{n+1}}{1 - q} = +\infty\]
  in quanto si può portare fuori il \quotes{$-$}, senza avere problemi di segno.

  \item se $q < 1$, allora ovviamente
  \[q^{n+1} > 0\]
  se $n+1$ è pari, mentre
  \[q^{n+1} < 0\]
  se $n+1$ è dispari, quindi la serie è oscillante con ampiezza a crescere.
\end{itemize}

\vspace{1em}
\noindent
\textbf{Esempio}: Si calcoli la seguente serie geometrica:
\[\sum_{k=1}^\infty \left(\frac{1}{3}\right)^k\]
ricordando sempre, però, che la serie geoemtrica parte con $k=0$. Ovviamente è noto che, se $k=0$
\[\left(\frac{1}{3}\right)^0 = 1\]
per cui si può scrivere
\[\sum_{k=1}^\infty \left(\frac{1}{3}\right)^k = -1 + \sum_{k=0}^\infty \left(\frac{1}{3}\right)^k\]
ma siccome $q = \frac{1}{3} \in (-1,1)$, allora la serie converge a
\[\frac{1}{1-q} = \frac{1}{1 - \frac{1}{3}}\]
e si può scrivere
\[\sum_{k=1}^\infty \left(\frac{1}{3}\right)^k = -1 + \sum_{k=0}^\infty \left(\frac{1}{3}\right)^k = -1 + \frac{1}{1 - \frac{1}{3}} = \frac{1}{2}\]

\vspace{1em}
\subsection{Criterio del confronto per serie a termini positivi}
Non è sempre facile capire se una serie converge o meno: anche se la serie è a termini positivi, non è facile determinare se essa converga o diverga a $\pm \infty$. Tuttavia, esistono diversi criteri, uno dei più basilari ed efficaci è il criterio del confronto:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{CRITERIO DEL CONFRONTO PER SERIE A TERMINI POSITIVI}}\\
    \parbox{\linewidth}{Siano date due successioni $a_n,b_n \geq 0$ e si supponga che esse siano tali che $a_n \leq b_n, \forall n$. Allora si ha che
    \begin{itemize}
      \item se \(\displaystyle{\sum_{k=1}^\infty a_n}\) diverge, diverge anche \(\displaystyle{\sum_{k=1}^\infty b_n}\)
      \item se \(\displaystyle{\sum_{k=1}^\infty b_n}\) converge, allora converge anche \(\displaystyle{\sum_{k=1}^\infty a_n}\)
    \end{itemize}
    Inoltre, detto $l_b$ il limite dela prima e $l_a$ il limite della seconda, risulta $l_a = l_b$.
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
Si propone una breve dimostrazione (che si basa sui teoremi del confronto di successioni monotone):
\begin{itemize}
  \item si indichi con $s_n$ la successione delle somme parziali relativa ai termini $a_n$, ovvero
  \[s_n = a_1 + ... + a_n\]
  \item si indichi con $r_n$ la successione delle somme parziali relativa ai termini $b_n$, ovvero
  \[r_n = b_1 + ... + b_n\]
\end{itemize}
Si supponga che la successione $r_n$ converga e si chiami ccon $l_b$ il suo limite, ovvero
\[\lim_{n \to \infty} r_n = l_b\]
sapendo, però, che $a_n \leq b_n, \forall n$, si evince che
\[s_n \leq r_n\]
ma siccome $r_n$ è una successione crescente e convergente, i suoi termini sono diminati dall'alto dal limite $l_b$, da cui
\[s_n \leq r_n \leq l_b\]
per il teorema di convergenza delle successioni monotone. Ma siccome anche la successione $s_n$ è crescente ed è limitata superiormente da $l_b$, per il teorema di esistenza del limite delle successioni monotone segue che
\[\exists \lim_{n \to \infty} a_n = l_a\]
per il teorema del confronto tra successioni, sapendo che $a_n \leq b_n, \forall n$, si ha che $l_a \leq l_b$.
Generalmente per il confronto vengono utilizzate la serie geometrica e la serie armonica generalizzata (visto che già se ne conosce il comportamento).

\vspace{1em}
\noindent
\textbf{Dimostrazione}: Si consideri la seguente serie
\[\sum_{k=0}^\infty \frac{1}{k!}\]
e si dimostri che essa è \textbf{convergente}. Ricordando che $0!=1$, per definizione, si ha che
\[\sum_{k=0}^n \frac{1}{k!} = 1 + 1 + \frac{1}{2} + ... + \frac{1}{n \cdot (n-1) \cdot ... \cdot 2}\]
se ora, in ciascun denominatore, si procede ad eliminare tutti i prodotti tranne i primi due, ovvero lasciando solamente $n \cdot (n-1)$, è naturale ottenere una sommatoria maggiorata, per cui
\[\sum_{k=0}^n \frac{1}{k!} = 1 + 1 + \frac{1}{2} + ... + \frac{1}{n \cdot (n-1) \cdot ... \cdot 2} \leq 1 + 1 + \frac{1}{2 \cdot 1} + ... + \frac{1}{n \cdot (n-1)} = 2 + \sum_{k=2}^n \frac{1}{k \cdot (k-1)}\]
La serie a destra può essere così riscritta
\[\sum_{k=2}^\infty \frac{1}{k \cdot (k-1)} = \sum_{k=2}^\infty \left[\frac{1}{k-1} - \frac{1}{k}\right]\]
e tale serie è \textbf{convergente} ad $1$, in quanto $s_n = 1 - \frac{1}{n}$. Per verificarlo basta provare a scrivere esplicitamente la successione delle somme parziali
\[s_n = \left(1 - \frac{1}{2}\right) + \left(\frac{1}{2} - \frac{1}{3}\right) + ... + \left(\frac{1}{n-1} - \frac{1}{n}\right) = 1 - \frac{1}{n}\]
in quanto tutti gli altri termini si semplificano. Applicando il criteriore del confronto, è facile osservare che
\[\sum_{k=0}^\infty \frac{1}{k!} \leq 2 + \sum_{k=2}^\infty \frac{1}{k \cdot (k-1)} = 2 + 1 = 3\]
per cui si ottiene che anche la successione
\[\sum_{k=0}^\infty \frac{1}{k!}\]
è convergente e il suo limite è minore di $3$. Tale limite prende il nome di \textbf{numero di Nepero} ed è indicato con $e$.

\newpage
\begin{center}
  7 Marzo 2022
\end{center}
\section{Spazi di probabilità generali}
Finora sono stati considerati degli spazi degli eventi elementari finiti. Tuttavia, non è sempre possibile sapere a priori quanti elementi devono essere contenuti nello spazio campione su cui si andrà a lavorare, per cui si rende necessario operare con spazi arbitrariamente grandi, ovvero \textbf{non finiti}.\\
Tuttavia, ciò introduce una complicazione aggiuntiva: non sarà più possibile sommare un numero finito di probabilità, ma un numero arbitrariamente grande e quindi infinito.

\vspace{1em}
\subsection{$\boldsymbol{\sigma}$-algebra}
Per estensione con quanto esposto in precedenza, di seguito si espone la definizione di $\sigma$-algebra, ovvero un'algebra nella quale non si pone un limite sul numero di elementi:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{$\boldsymbol{\sigma}$-ALGEBRA}}\\
    \parbox{\linewidth}{Una famiglia $\mathcal{A}$ di parti di un insieme $\Omega$ è detta \textbf{$\boldsymbol{\sigma}$-algebra} se
    \begin{enumerate}
      \item l'insieme vuoto e lo spazio campione stesso appartengono ad $\mathcal{A}$, ovvero
      \[\varnothing, \Omega \in \mathcal{A}\]
      \item se $A \in \mathcal{A}$, allora $A^c \in \mathcal{A}$
      \item mentre in un'algebra normale si chiedeva che dati $n$ sottoinsiemi appartenenti all'algebra, anche la loro unione e intersezione di devono appartenere, nel caso di una $\sigma$-algebra si chiede che se si considera una successione di sottoinsiemi $A_n$ all'interno della $\sigma$-algebra, ovvero $\left\{A_n, n \in \mathbb{A} \right\} \subset \mathcal{A}$, ossia una \textbf{quantità al più numerabile}, allora l'unione e l'intersezione di tali sottoinsiemi devono appartenere alla $\sigma$-algebra:
      \[\bigcup_{n=1}^\infty A_n \in \mathcal{A} \hspace{1em} \text{e} \hspace{1em} \bigcap_{n=1}^\infty A_n \in \mathcal{A}\]
    \end{enumerate}
    \vspace{1mm}}\\
    \hline
\end{tabularx}

\vspace{2em}
\noindent
\textbf{Osservazione}: Ovviamente, ogni \textbf{$\boldsymbol{\sigma}$-algebra} è anche un'algebra, e i due concetti coincidono se $\Omega$ ha un numero finito di elementi.

\newpage
\noindent
\subsection{Probabilità generale}
Così come su un'algebra è stato definito il concetto di probabilità, è opportuno estendere tale concetto anche ad una $\sigma$-algebra:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{PROBABILITÀ PER SPAZI DI PROBABILITÀ GENERALI}}\\
    \parbox{\linewidth}{Siano $\Omega$ un insieme e la famiglia $\mathcal{A}$ una \textbf{$\boldsymbol{\sigma}$-algebra} su $\Omega$. Una (misura di) \textbf{probabilità} è una funzione
    \[p : \mathcal{A} \longrightarrow [0,1]\]
    tale che
    \begin{enumerate}
      \item come per un'algebra normale, la probabilità dell'insieme vuoto sia nulla e quella dello spazio campione stesso sia massima, ovvero
      \[p(\varnothing) = 0 \hspace{1em} \text{e} \hspace{1em} p(\Omega) = 1\]
      \item se $\left\{A_n, n \in \mathbb{N}\right\} \subset \mathcal{A}$ è una successione di insiemi appartenenti alla $\sigma$-algebra \textbf{a due a due disgiunti}, ovvero $A_i \cap A_j \neq \varnothing, \forall i \neq j$, allora
      \[\sum_{n=1}^\infty p(A_n) = p \left(\bigcup_{n=1}^{\infty} A_n\right) \hspace{1em} \left[\boldsymbol{\sigma}-\textbf{additività}\right]\]
      ovvero la probabilità deve essere \textbf{$\boldsymbol{\sigma}$-additiva}. Da notare che
      \[\sum_{n=1}^\infty p(A_n)\]
      è una \textbf{serie numerica}, ovverosia una \textbf{somma infinita} delle probabilità di ogni singolo insieme $A_n$ considerato.
    \end{enumerate}
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\subsection{Spazio di probabilità generale}
Avendo esteso il concetto di alebra e probabilità al caso generale, è posibile parlare di \textbf{spazio di probabilità generale}, la cui definizione viene di seguito esposta:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{SPAZIO DI PROBABILITÀ GENERALE}}\\
    \parbox{\linewidth}{Si chiama \textbf{spazio di probabilità} una terna $\left(\Omega,\mathcal{A},p\right)$ dove
    \begin{itemize}
      \item $\Omega$ è un insieme, ovvero lo spazio degli eventi elementari (spazio campione)
      \item $\mathcal{A}$ è una $\sigma$-algebra
      \item $p$ è una probabilità definita su $\mathcal{A}$
    \end{itemize}
    \vspace{1mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
Da notare, ovviamente, che i risultati visti in precedenza, nell'ambito di uno spazio campione finito, sono ancora validi, anche in questo ambito generale.\\
Si consideri, a tal proposito, il seguente esempio:

\vspace{1em}
\noindent
\textbf{Esempio}: Presa una moneta e lanciandola ripetutatemente, si vuole determinare la proabilità che esca testa al lancio $n$-esimo, ma non prima.\\
Per la visualizzazione di tale problema dal punto di vista matematico, è possibile etichettare testa con il numero \quotes{$0$} e croce con il numero \quotes{$1$}. È possibile, quindi, identificare i risultati di una successione di lanci con una successione che prenda valori in $\{0,1\}$. Per esempio $(0,0,1,0,1,1,...)$ identifica una successione di lanci in cui al primo e al secondo lancio è uscita testa, al terzo croce, al quarto di nuovo testa, etc...\\
Con questa identificazione l'evento elementare è, fissato $n$, il seguente:

\begin{flalign*}
  \omega_n & = \text{ la prima volta che esce testa è al lancio } n\text{-esimo}\\
   & = \parbox{\linewidth}{\text{la famiglia delle successione che hanno \quotes{$1$} nei\\ primi $n-1$ elementi e \quotes{$0$} all'evento $n$-esimo.}}\\
\end{flalign*}

\noindent
Lo spazio degli eventi elementari è dunque $\Omega=\left\{\omega_n, n \in \mathbb{N}\right\}$, ovvero l'insimee delle fammiglie $\omega_1,\omega_2,$ etc., il quale, quindi, ha un numero infinito, ossia una quantità numerabile, di elementi.\\
Per rispondere alla domanda che è stata posta in principio, è necessario stabilire un criterio ragionebvole per assegnare la probabilità. È possibile assumere, in maniera puramente \textbf{euristica}, che
\begin{itemize}
  \item in ogni singolo lancio, la probabilità che esca testa o croce sia la stessa;
  \item il risultato di un lancio sia indipendente dai risultati dei lanci precedenti.
\end{itemize}
Queste ultime sono ipotesi ragionevoli, ma come per il lancio di un dado, sono assunzioni totalmente arbitrarie. Per esempio, la moneta potrebbe essere sbilanciata e quindi testa potrebbe tendere as usicre più volte rispetto a croce.\\
Per stabilire la probabilità di verificarsi dell'evento $\omega_1$ è necessario capire che cosa accade nel primo lancio: se esce testa la probabilità è presto calcolata $\frac{1}{2}$, ossia il $50\%$.\\
La probabilità che si verifichi $\omega_2$ prevede che non sia uscita testa al primo lancio e serve che al secono lancio esca proprio testa. Quindi la probabilità è $\frac{1}{2}$ di $\frac{1}{2}$, cioé $\frac{1}{4}$, ossia il $25\%$.\\
È così via per l'evento $\omega_n$:
\[p\left(\left\{\omega_n\right\}\right) = \left(\frac{1}{2}\right)^n\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Nonostante si abbia risposto alla domanda, non è stato definito completamente lo spazio di probabilità che si sta considerando.\\
È opportuno considerare come $\sigma$-algebra $\mathcal{A}$, come già visto, l'insieme di tutti i sottoinsiemi di $\Omega$: questo è possibile farlo nonostante $\Omega$ sia infinito, in quanto è costituita da una \textbf{quntità numerabile} di elementi.\\
Dopodiché la probabilità su $\mathcal{A}$ si definisce come in precedenza, ossia come somma delle probabilità degli eventi elementari costituenti $\mathcal{A}$; in particolare
\[p(A) = \left\{
  \rowcolors{1}{white}{white}
  \begin{array}{cl}
    \displaystyle{\sum_{\omega \in A} p\left(\left\{\omega\right\}\right)} & \forall A \subset \Omega \text{ non vuoto}\\
    0 & \text{se } A = \varnothing
  \end{array}
\right.\]
La funzione così definita è ben posta, poiché $\Omega$ è numerabile e quindi $\mathcal{A}$ è al più numerabile. Quindi
\[\sum_{\omega \in \mathcal{A}}\]
è una sommatoria finita o una serie (se il numero di elementi costituenti $\mathcal{A}$ è infinito). Si ha, inoltre, che tale funzione è utti gli effetti una probabilità, in quanto la somma delle probabilità di tutti gli eventi elementari è proprio $1$
\[p(\Omega) = \sum_{n=0}^\infty p \left(\left\{\omega\right\}\right) = \sum_{n=0}^\infty \left(\frac{1}{2}\right)^n = \sum_{n=1}^\infty \left(\frac{1}{2}\right)^n - 1 = \frac{1}{1 - \dfrac{1}{2}} - 1 = 2 - 1 = 1\]
essendo una serie geometrica di ragione $\frac{1}{2}$. Si può facilmente osservare che vale la proprietà di \textbf{$\boldsymbol{\sigma}$-additività}: si calcoli la probabilità dell'evento
\[A = \left\{\text{esce testa per la prima volta tra il terzo e il sesto lancio (compresi)}\right\} = \left\{\omega_1,\omega_4,\omega_5,\omega_6\right\}\]
Per calcolare la probabilità di tale evento complesso $\mathcal{A}$ sarà sufficiente provvedere alla somma delle probabilità dei singoli eventi che appartengono ad $\mathcal{A}$, secondo la definzione, ovvero:
\[p(A) = \sum_{n=3}^6 p\left(\left\{\omega_n\right\}\right) = \left(\frac{1}{2}\right)^3 + \left(\frac{1}{2}\right)^4 + \left(\frac{1}{2}\right)^5 + \left(\frac{1}{2}\right)^6\]
Si consideri un altro evento complesso:
\[A = \left\{\text{esce testa per la prima volta in un lancio pari}\right\} = \left\{\omega_n : n \text{ è pari}\right\} = \left\{\omega_{2m} : m \in \mathbb{N}\right\}\]
La probabilità di tale evento è, quindi:
\[p(\mathcal{A}) = \sum_{m=0}^\infty p \left(\left\{\omega_{2m}\right\}\right) = \sum_{m=0}^\infty \left(\frac{1}{2}\right)^{2m} = \sum_{m=0}^\infty \left(\frac{1}{4}\right)^{m} = \sum_{m=1}^\infty \left(\frac{1}{4}\right)^{m} - 1 = \frac{1}{1 - \dfrac{1}{4}} - 1 = \frac{4}{3} - 1 = \frac{1}{3}\]

\vspace{1em}
\noindent
\textbf{Osservazione}: L'esempio appena visto è molto simile a quelli visti nel caso finito. Il motivo per cui tale estensione al caso generale è stata così naturale è che $\Omega$ è numerabile, nonostante sia infinito, ma nulla di più. Esso merita, quindi, una definizione specifica:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{SPAZIO DI PROBABILITÀ DISCRETO}}\\
    \parbox{\linewidth}{Si dirà che uno spazio di probabilità $(\Omega,\mathcal{A},p)$ è \textbf{discreto} se $\Omega$ è al più numerabile (ovvero o finito o numberabile) e $\mathcal{A}$ è la famiglia di tutti i sottoinsieme di $\Omega$. Naturalmente, per quanto già visto, la probabilità sulla famiglia $\mathcal{A}$ viene definita come
    \[p(A) = \left\{
      \begin{array}{cl}
        \displaystyle{\sum_{\omega \in A} p\left(\left\{\omega\right\}\right)} & \forall A \subset \Omega \text{ non vuoto}\\
        0 & \text{se } A = \varnothing
      \end{array}
    \right.\]
    Quindi, in base a tale formula, si evince che il comportamento di $p$ è \textbf{completamente determinato dalle probabilità degli eventi elementari}.
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che l'espressione
\[\sum_{\omega \in A} p\left(\left\{\omega\right\}\right)\]
è da interpretarsi come una serie. Tuttavia, nel calcolo di tale sommatoria è totalmente \textbf{ininfluente l'ordine con cui si vanno a sommare le probabilità} degli eventi costituenti $\mathcal{A}$, ma solamente perché taluna è una \textbf{serie convergente a termini positivi}. Pertanto, in questo caso, si parla di \textbf{convergenza assoluta} e, quindi il limite non cambia se i termini vengono riarrangiati.

\vspace{1em}
\noindent
Si considerino due questioni:
\begin{enumerate}
  \item Si consideri l'alternativa di considerare nell'esempio appena trattato, lo spazio degli eventi elementi seguenti
  \[\Omega = \left\{\text{successioni costituite da \quotes{0} e da  \quotes{1}}\right\}\]
  e, per $n \in \mathbb{N}$, gli eventi
  \[A_n = \left\{\text{successioni che presentano \quotes{1} nei primi } n-1 \text{ elementi e \quotes{0} nell'} n \text{-esimo}\right\}\]
  Ovvero ci si sta chiedendo se sia più conveniente considerare gli eventi oggetto di interesse come eventi elementari $\omega_n$ invece che come eventi complessi $A_n$.

  \item Inoltre, ci si deve chidere per quale ragione non ci si limiti ad assegnare una probabilità esclusivamente sugli eventi elementari e si necessita, invece, di introdurre la famiglia $\mathcal{A}$ e definire $p$ su eventi complessi $A \in \mathcal{A}$.
\end{enumerate}

\vspace{1em}
\noindent
La risposta alla seconda questione è presto detta: se $\Omega$ non fosse un insieme finito o numerabile, i suoi sottoinsiemi potrebbero non essere finiti o numerabili, per cui non sarebbe possibile definire la probabilità dell'evento complesso semplicemente basandosi sulla sommatoria della probabilità degli eventi elementari, in quanto tale sommatoria potrebbe essere non finita, in quanto somma di quantità più che numerabili, perdendo di significato.

\vspace{1em}
\noindent
\textbf{Esempio}: Per rispondere alla prima questione, invece, si consideri un esempio pratico. Se si deve modellizzare la risposta elastica di un ponte di ferro costituito da delle travi di ferro; si compia il seguente parallelo
\begin{itemize}
  \item Le travi sono gli eventi elementari $\omega_n$;
  \item L'elastiticità delle travi corrisponde alla probabilità di eventi elementari $p \left(\left\{\omega_n\right\}\right)$;
  \item Le regole con cui le travi interagiscono sono gli assiomi dello spazio di probabilità (quale l'additività);
  \item Il ponte è l'evento complesso $\mathcal{A}$.
\end{itemize}
In questo caso, per la modellizzaione, si sarebbe potuto certamente prendere come elemento base del ponte gli atomi di ferro e considerare sia le travi che il ponte strutture complesse; tuttavia, il concetto di elasticità sarebbe stato definito comunque a partire dalle travi e non sugli atomi, dove tale applicazione non avrebbe alcun senso. Similmente, si sarebbero potuto considerare come eventi elementari le successioni, però il concetto di probabilità va comunque definito a livello di evento $A_n$ e non sulla singola successione, in cui non avrebbe avuto senso.\\
In effetti ogni successione avrebbe dovuto avere la stessa probabilità, ma ogni evento $A_n$ ne contiene infinite e quindi $A_n$ risulterebbe avere \textbf{probabilità infinita} (e ciò è impossibile).\\
In tale esempio, pertanto, dal punto di vista operativo, i due approcci non differiscono concettualmente; spesso, però, si usano spazi non discreti: il ponte potrebbe essere fatto da ben altro che semplici travi.

\vspace{1em}
\noindent
\textbf{Esercizio}: Si consideri un bersaglio con una macchia non omogenea al suo interno:

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \node[circle,draw=black,fill=white, inner sep=0pt,minimum size=4cm]{} (0,0);
    \node[circle,draw=black,fill=black, inner sep=0pt,minimum size=1cm](i) at (0,1) {};
    \node[circle,draw=black,fill=black, inner sep=0pt,minimum size=1cm](i1) at (0,0.7) {};
    \node[circle,draw=black,fill=black, inner sep=0pt,minimum size=1cm](i2) at (-0.5,0.8) {};
    \node[circle,draw=black,fill=black, inner sep=0pt,minimum size=1cm](i3) at (-0.8,0.5) {};
  \end{tikzpicture}
  \caption{Esempio 4}
  \label{fig:esempio_4}
\end{figure}

\noindent
Lanciando una freccetta, qual'è la probabilità di colpire la macchia scura?\\
In questo caso, ha senso considerare l'insieme degli eventi elementari $\Omega$ l'insieme di tutti i punti del cerchio
\[\Omega : = \left\{x \in \mathbb{R}^2 : x \in \text{cerchio}\right\}\]
Pertanto, sembra ragionevole assegnare ad una certa zona la probabilità di essere colpita in modo proporzionale alla sua area. In altre parole, se $A$ è un sottoinsieme del cerchio $\Omega$, si ha che
\[p(A) = c \cdot \left \vert A \right \vert\]
dove $\left \vert A \right \vert$ è l'area del sottoinsieme e $c>0$ è un opportuno fattore; questa è ovviamente un'\textbf{assunzione euristica}, totalmente arbitraria.\\
Affinché l'oggetto appena definito sia un'algebra (e $p$ una probabilità), deve risultare $p(\Omega)=1$, si può considerare come fattore rinormalizzante
\[c=\frac{1}{\left \vert \Omega \right \vert}\]
Nuovamente, la misura di probabilità così definita è una scelta arbitraria basata su considerazioni empiriche. Si sarebbe potuto ancora definirla in modo diverso, per esempio volendo tenere conto della gravità di zone poste in basso che, a paritià di area, potrebbero avere più probabilità di essere colpite rispetto a zone poste in alto.\\
Si osservi, poi, che benché sia stato considerato come spazio degli eventi elementari l'insieme del punti del bersaglio, ovvero uno spazio \textbf{né finito}, \textbf{né numerabile}, non ha senso definire prima la probabilità di colpire i singoli punti (che sarebbe sempre nulla) e poi la probabilità di colpire un'intera area del bersaglio, in quanto ad ogni area corrispondono infiniti punti e quindi la probabilità risultante sarebbe nulla.\\
Quando $\Omega$ è un insieme al più numerabile, è sempre possibile scegliere $\mathcal{A}$ come la famiglia di tutti i sottoinsiemi di $\Omega$; tuttavia, in generale questo non è possibile farlo, o non risulta conveniente farlo.\\
Infatti, in questo caso, lavorando con $\Omega$ non finito e non numerabile, la $\sigma$-algebra $\mathcal{A}$ non è
\[\mathcal{A} := \left\{\text{ogni sottoinsieme di }\Omega\right\}\]
in quanto poi dopo si avrebbe difficoltà a definire la probabilità $p$. In effetti, in questo caso, si è assunto
\[\mathcal{A} := \left\{\text{ogni sottoinsieme di }\Omega\text{ per cui abbia senso il concetto di area}\right\}\]
altrimenti non si sarebbe potuto scrivere $\left \vert A \right \vert$. In questo caso, la famiglia $\mathcal{A}$ assunta è a tutti gli effetti una $\sigma$-algebra $\mathcal{A}$, in quanto l'unione di due eventi disgiunti di cui si conosce la misura (l'area) è ancora un evento di cui è nota la misura (l'area).\\
Ciò che in questo caso è rilevante è che in $\mathcal{A}$ cadano tutti gli oggetti geometrici classici e le loro unioni ed intersezioni numerabili. Tale $\sigma$-algebra prende il nome di \textbf{$\boldsymbol{\sigma}$-algebra di Borel}, ovvero la \textbf{famiglia di tutti i sottoinsiemi misurabili di $\boldsymbol{\Omega}$}, o in termini tecnici, la più piccola $\sigma$-algebra che contiene gli aperti di $\Omega$.

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che, innanzitutto, una probabilità è una \textbf{misura}, una misura della facilità con cui un evento si verifica e come qualsiasi altra misura presenta la seguente proprietà: se di tale oggetto se ne misurano le parti distinte (senza sovrapposizioni) per conoscere la misura dell'oggetto complessivo, è sufficiente sommare fra loro le singole misure distinte.

\vspace{1em}
\subsection{Proposizione 2 - Proprietà degli spazi di probabilità generali}
\label{sec:proposizione_2}
Volendo determinare ulteriori proprietà generali degli spazi di probabilità:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{PROPRIETÀ DELLO SPAZIO DI PROBABILITÀ}}\\
    \parbox{\linewidth}{Sia $\left(\Omega,\mathcal{A},p\right)$ uno spazio di probabilità
    \begin{itemize}
      \item se $\left\{A_n\right\}$ è una successione crescente di eventi, cioé $A_n \subset A_{n+1}, \forall n \in \mathbb{N}$, allora
      \[p \left(\bigcup_{k=1}^\infty A_n\right) = \lim_{n \to \infty} p(A_n) \hspace{1em} \left[\textbf{continuità dal basso}\right]\]
      ovvero la probabilità dell'unione di tali eventi dipende unicamente dal comportamento asintotico dell'ultimo evento, che contiene tutti gli altri, ovvero l'evento $A_n$

      \item se $\left\{A_n\right\}$ è una successione decrescente di eventi, cioé $A_{n+1} \subset A_{n}, \forall n \in \mathbb{N}$, allora
      \[p \left(\bigcap_{k=1}^\infty A_n\right) = \lim_{n \to \infty} p(A_n) \hspace{1em} \left[\textbf{continuità dall'alto}\right]\]
    \end{itemize}
    \vspace{1mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Dimostrazione $\boldsymbol{1}$}: È possibile scrivere $\forall n \in \mathbb{N}$, grazie al fatto che si sta lavorando con successioni crescenti
\[\bigcup_{k=1}^n A_k = A_1 \cup \bigcup_{k=2}^n \left(A_k - A_{k-1}\right)\]
in modo tale da operare con insiemi disgiunti. Poiché
\[\bigcup_{k=1}^\infty A_k = A_1 \cup \bigcup_{k=2}^\infty \left(A_k - A_{k-1}\right)\]
ovvero si sta considerando un insieme infintio di insiemi a due a due disgiunti, usando la $\sigma$-additività si ottiene
\[p \left(\bigcup_{k=1}^\infty A_k\right) = p(A_1) + \sum_{k=2}^\infty p \left(A_k - A_{k-1} \right)\]
sfruttando il concetto di serie, una sommatoria infinita può essere considerata come il limite delle somme parziali, ovvero si ha che
\[p(A_1) + \sum_{k=2}^\infty p \left(A_k - A_{k-1}\right) = p(A_1) + \lim_{n \to +\infty} \sum_{k=2}^n p \left(A_k - A_{k-1}\right)\]
Dal momento che $p(A_1)$ è un numero reale, può essere tranquillamente portato dentro il limite, ottenendo
\[p(A_1) + \lim_{n \to +\infty} \sum_{k=2}^n p \left(A_k - A_{k-1} \right) = \lim_{n \to +\infty} \left[p(A_1) + \sum_{k=2}^n p \left(A_k - A_{k-1}\right)\right]\]
Sfruttando ancora l'additività si possono rimettere nuovamente insieme tutti gli insiemi e calcolare il limite della probabilità dell'unione, come mostrato di seguito:
\[\lim_{n \to +\infty} \left[p(A_1) + \sum_{k=2}^n p \left(A_k - A_{k-1}\right)\right] = \lim_{n \to +\infty} p\left(A_1 \cup \bigcup_{k=2}^n \left(A_k - A_{k-1}\right) \right) = \lim_{n \to +\infty} p(A_n)\]

\vspace{1em}
\noindent
\textbf{Dimostrazione $\boldsymbol{2}$}: Per la dimostrazione della seconda proprietà, si deve osservare che $\{A_1 - A_n\}$ è una successione necessariamente crescente. Dopo questa prima osservazione si può facilmente scrivere che
\[p(A_1) - p \left(\bigcap_{k=2}^{\infty} A_k\right) = p \left(A_1 - \bigcap_{k=2}^\infty A_k\right)\]
questo sfruttando il fatto che
\[\bigcap_{k=2}^\infty A_k \subset A_1\]
Inoltre, dal momento che l'intersezione degli $A_k$ è uguale all'unione dei complementari si ottiene
\[p \left(A_1 - \bigcap_{k=2}^\infty A_k\right) = p \left(A_1 \cap \bigcup_{k=2}^\infty A_k^c\right)\]
Ora, invece, sfruttando la proprietà distributiva, si ha che $A_1$ intersecato con l'unione è uguale all'unione delle intersezioni, per cui
\[p \left(A_1 \cap \bigcup_{k=2}^\infty A_k^c\right) = p \left( \bigcup_{k=2}^\infty \left(A_1 \cap A_k^c\right)\right)\]
Ma naturalmente si ha che $A_1 \cap A_k^c = A_1 - A_k$, ovvero l'intersezione tra $A_1$ e il complementare di $A_k$ è $A_1$ a cui viene tolto $A_k$, per cui
\[p \left( \bigcup_{k=2}^\infty \left(A_1 \cap A_k^c\right)\right) = p \left( \bigcup_{k=2}^\infty \left(A_1 - A_k\right)\right)\]
Ma per l'osservazione iniziale, si ha che $A_1 - A_k$ è una successione crescente, per cui per la \textbf{continuità dal basso} dimostrata in precedenza, segue che
\[p \left( \bigcup_{k=2}^\infty \left(A_1 - A_k\right)\right) = \lim_{n \to +\infty} p \left(A_1 - A_n\right) = p(A_1) - \lim_{n \to +\infty} p(A_n)\]
Per cui si è ottenuto, alla fine, che
\[p(A_1) - p \left(\bigcap_{k=2}^{\infty} A_k\right) = p(A_1) - \lim_{n \to +\infty} p(A_n) \longrightarrow p \left(\bigcap_{k=2}^{\infty} A_k\right) = \lim_{n \to +\infty} p(A_n)\]

\newpage
\begin{center}
  11 marzo 2022
\end{center}
È noto, come dimostrato nella \textbf{Proposizione 1} (§ \ref{sec:proposizione_1}), che la probabilità è \textbf{subadditiva}; più un generale, se $A_1, ..., A_n$ sono eventi (non necessariamente disgiunti), allora
\[p \left( \bigcup_{k=1}^n A_k \right) \leq \sum_{k=1}^n p(A_k)\]
E la \textbf{Proposizione 2} (§ \ref{sec:proposizione_2} precedentemente esposta permette di generalizzare la \emph{subadditività} alle successioni di eventi.

\vspace{1em}
\noindent
\begin{corollary}
  Sia $\left\{A_n\right\}_{n \in \mathbb{N}}$ una successione di eventi in uno spazio di probabilità $(\Omega, \mathcal{A}, p)$. Allora
  \[p \left( \bigcup_{k=1}^\infty A_k\right) \leq \sum_{k=1}^\infty p(A_k)  \hspace{1em} \left[\boldsymbol{\sigma}\textbf{-subadditività}\right]\]
  Tale proprietà prende il nome di $\sigma$-subadditività.
\end{corollary}

\vspace{1em}
\noindent
\textbf{Dimostrazione}: Si consideri
\[B_n := \bigcup_{k=1}^n A_k\]
ovvero $B_n$ sotituisce un aggregato di $n$ successioni. Naturalmente, appare evidente come
\[B_{n+1} = B_n + A_{n+1} \geq B_n\]
per cui $\left\{B_n\right\}_{n \in \mathbb{N}}$ è una successione crescente di eventi e quindi $B_n \subset B_{n+1}$: ciò permettera di impiegare la \textbf{continuità dall'alto} dimostrata nella \textbf{Proposizione 2} (§ \ref{sec:proposizione_2}); inoltre, appare evidente come
\[\bigcup_{k=1}^\infty B_k = \bigcup_{k=1}^\infty A_k\]
per come è stato costruito l'oggetto $B_k$. Per la \textbf{continuità dall'alto} si ottiene che
\[p \left( \bigcup_{k=1}^\infty A_k\right) = p \left( \bigcup_{k=1}^\infty B_k\right) = \lim_{n \to +\infty} p \left(B_n\right)\]
ovvero la probabilità dell'aggregato, in una successione crescente, è stimata dal comportamento asintotico dell'elemento $B_n$. Riscrivendo $B_n$ secondo la sua definizione si ha che
\[ \lim_{n \to +\infty} p \left(B_n\right) = \lim_{n \to +\infty} p \left(\bigcup_{k=1}^n A_k\right)\]
sfruttando, ora, quanto è noto per il caso finito, ovvero che la probabilità dell'unione è minore della somma delle probabilità dei singoli eventi, si ha che
\[\lim_{n \to +\infty} p \left(\bigcup_{k=1}^n A_k\right) \leq \lim_{n \to +\infty} \sum_{k=1}^n p \left(A_k\right)\]
sfrutando, ora, il concetto di serie, si ha che il limite della serie è uguale al limite delle somme parziali, per cui
\[\lim_{n \to +\infty} \sum_{k=1}^n p \left(A_k\right) = \sum_{k=1}^\infty p \left(A_k\right)\]
in cui tale limite esiste sempre in quanto si sta considerando una serie a termini positivi. Pertanto tale limite può essere finito o $+\infty$, a seconda che la serie sia convergente o divergente.

\vspace{1em}
\noindent
\textbf{Osservazione}: È noto che, in generale, la proprietà
\[p \left( \bigcup_{k=1}^n A_k \right) \leq \sum_{k=1}^n p(A_k)\]
se gli eventi $A_1,...,A_n$ non sono digunti, non è un'uguaglianza. È noto, però, nel caso di due eventi $A$ e $B$ (così chiamati in luogo di $A_1$ e $A_2$) disgiunti, che
\[p(A \cup B) + p (A \cap B) = p(A) + p(B)\]
in cui è facile osservare che affinché la disuguaglianza
\[p(A \cup B) \leq p(A) + p(B)\]
sia una uguaglianza, deve essere considerato il termine $p (A \cap B)$. Ciò è ravvisabile ancora meglio se tale configurazione si analizza dal punto di vista geometrico:

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \tikzset{venn circle/.style={draw,circle,minimum
     width=3.5cm}}

    \node [venn circle, label={[fill=yellow!50,xshift=-1em]center:$A$}] (A) at (0,0) {};
    \node [venn circle, label={[fill=green!50,xshift=1em]center:$B$}] (B) at (0:2cm) {};
    \node[fill=red!50] at (barycentric cs:A=1/2,B=1/2 ) {$A \cap B$};
  \end{tikzpicture}
  \caption{Intersezione tra due insiemi}
  \label{fig:intersezione_due_insiemi}
\end{figure}

\vspace{1em}
\noindent
Considerando la probabilità una \textbf{misura} (in questo caso dell'area dei due insiemi), quando viene eseguita la somma $p(A) + p(B)$, si sta considerando due volte la probabilità della loro intersezione, ovvero $p(A \cap B)$; pertanto, al fine di ottenere $p(A \cup B)$, è necessario sottrarre a $p(A) + p(B)$ proprio la probabilità dell'intersezione $p(A \cap B)$, ottenendo l'identità
\[p(A \cup B) = p(A) + p(B) - p(A \cap B)\]

\vspace{1em}
\noindent
Nel caso di $n=3$ insiemi, si considerino $A$,$B$ e $C$ tre eventi

\begin{figure}[H]
\centering
\begin{tikzpicture}
  \tikzset{venn circle/.style={draw,circle,minimum
   width=3.5cm}}

  \node [venn circle, label={[fill=yellow!50,xshift=-1em]center:$A$}] (A) at (0,0) {};
  \node [venn circle, label={[fill=blue!50,yshift=1em]center:$C$}] (C) at (60:2cm) {};
  \node [venn circle, label={[fill=green!50,xshift=1em]center:$B$}] (B) at (0:2cm) {};
  \node[fill=orange!50,yshift=-1.5em] at (barycentric cs:A=1/2,B=1/2 ) {$1$};
  \node[fill=orange!50,xshift=-1.5em,yshift=1em] at (barycentric cs:A=1/2,C=1/2 ) {$2$};
  \node[fill=orange!50,xshift=1.5em,yshift=1em] at (barycentric cs:B=1/2,C=1/2 ) {$3$};
  \node[fill=violet!50] at (barycentric cs:A=1/3,B=1/3,C=1/3 ){$4$};
\end{tikzpicture}
\caption{Intersezione tra tre insiemi}
\label{fig:intersezione_tre_insiemi}
\end{figure}

\vspace{1em}
\noindent
In questo secondo caso, quando si sommano $p(A) + p(B) + p(C)$ vengono misurate \textbf{due volte} le intersezioni a due a due degli insiemi (ovvero $1$, $2$, $3$), mentre l'intersezione dei tre insiemi ($4$) viene misurata \textbf{tre volte}. Pertanto, se si vuole ottenere $p(A \cup B \cup C)$, alla somma delle tre probabilità $p(A) + p(B) + p(C)$ bisogna sottrarre $p(A \cap B) + p(A \cap C) + p(B \cap C)$. Tuttavia, in questo modo, è stata rimossa completamente l'intersezione tra i tre insiemi, che quindi deve essere riaggiunta, ottenendo:
\[p(A) + p(B) + p(C) - p(A \cap B) - p(A \cap C) - p(B \cap C) + p(A \cap B \cap C) = p(A \cup B \cup C) \hspace{1em} \forall A, B, C \in \mathcal{A}\]

\vspace{1em}
\noindent
\textbf{Dimostrazione}: Per la dimostrazione di tale proprietà, nel caso di $3$ eventi, si impiegano le nozioni già note per $2$ eventi, come mostrato di seguito:
\[p(A \cup B \cup C) = p((A \cup B) \cup C)\]
Ora, l'unione degli eventi $A \cup B$ e $C$ può essere scritta come somma delle probabilità degli eventi distinti meno la probabilità dell'intersezione, ovvero
\[p((A \cup B) \cup C) = p(A \cup B) + p(C) - p((A \cup B) \cap C)\]
Tuttavia, ora, $A \cup B$ è ancora l'unione di due eventi, per cui, secondo la formula, si ha che
\[p(A \cup B) + p(C) - p((A \cup B) \cap C) = p(A) + p(B) - p(A \cap B) + p(C) - p((A \cap B) \cup (B \cap C))\]
in cui, semplicemente, per la proprietà distributiva degli insiemi, si osserva che $(A \cup B) \cap C = (A \cap C) \cup (B \cap C)$. Pertanto, ora, sfruttando ancora una volta la proprietà di unione di due insiemi si può scrivere che
\[p((A \cap C) \cup (B \cap C)) = P(A \cap C) + p(B \cap C) - p((A \cap C) \cap (B \cap C))\]
da cui si ottiene la seguente formula
\[= p(A) + p(B) + p(C) - p(A \cap B) - p(A \cap C) - p(B \cap C) + p(A \cap B \cap C)\]
tenuto conto che $(A \cap C) \cap (B \cap C) = A \cap B \cap C$.

\vspace{1em}
\noindent
\textbf{Osservazione}: Tale formula può essere riscritta in modo più compatto: se si indicano i tre insiemi con $A_1, A_2, A_3$ è possibile scrivere
\[p \left(\bigcup_{k=1}^3 A_k\right) = \sum_{k=1}^3 \hspace{1em} \sum_{j \subset \left\{1,2,3\right\} \text{ tale che } \vert j \vert = k} \hspace{1em} (-1)^{k+1} \cdot p \left( \bigcap_{i \in j} A_i\right)\]
in cui la prima sommatoria serve solo per fissare la lunghezza dell'indice, mentre la seconda sommatoria considera tutte le famiglie costituite dal numero di elementi indicati dall'indice. Infatti
\begin{itemize}
  \item i sottoinsiemi $j \subset \{1,2,3\}$ per i quali $\vert j \vert = 1$ (ovvero che hanno cardinalità $1$) sono $\{1\}, \{2\}, \{3\}$, quindi
  \[\sum_{j \subset \left\{1,2,3\right\} \text{ tale che } \vert j \vert = 1} \hspace{1em} (-1)^{2} \cdot p \left( \bigcap_{i \in j} A_i\right) = p(A_1) + p(A_2) + p(A_3)\]

  \item i sottoinsiemi $I \subset \{1,2,3\}$ per i quali $\vert I \vert = 2$ sono $\{1,2\}, \{1,3\}, \{1,3\}$, quindi
  \[\sum_{j \subset \left\{1,2,3\right\} \text{ tale che } \vert j \vert = 2} \hspace{1em} (-1)^{3} \cdot p \left( \bigcap_{i \in j} A_i\right) = - p(A_1 \cap A_2) - p(A_1 \cap A_3) - p(A_2 \cap A_3)\]

  \item I sottoinsiemi $I \subset \{1,2,3\}$ per i quali $\vert I \vert = 3$ sono $\{1,2,3\}$, quindi
  \[\sum_{j \subset \left\{1,2,3\right\} \text{ tale che } \vert j \vert = 3} \hspace{1em} (-1)^{4} \cdot p \left( \bigcap_{i \in j} A_i\right) = p(A_1 \cap A_2 \cap A_3)\]
\end{itemize}
Eseguendo, ora, la somma, di ciascuno di tali casi si ottiene proprio la formula di partenza.

\newpage
\noindent
\subsection{Formula di inclusione-esclusione}
Procedendo, ora, per induzione, si può generalizzare tale formula al caso $n$, grazie al fatto che essa è stato scritta per mezzo di sommatorie, come illustrato di seguito:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{FORMULA DI INCLUSIONE-ESCLUSIONE}}\\
    \parbox{\linewidth}{Sia $(\omega, \mathcal{A}, p)$ uno spazio di probabilità. Presi $n$ eventi $A_1, A_2, ..., A_n \in \mathcal{A}$ si ha che
    \[p \left(\bigcup_{k=1}^n A_k\right) = \sum_{k=1}^n \hspace{1em} \sum_{j \subset \left\{1,...,n\right\} \text{ tale che } \vert j \vert = k} \hspace{1em} (-1)^{k+1} \cdot p \left( \bigcap_{i \in j} A_i\right)\]
    Si chiama formula di inclusione-esclusione in quanto per i termini pari si aggiunge, mentre per quelli dispari si toglie, a causa delle sovrapposizioni.
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\newpage
\section{Calcolo combinatorio}
Volendo procedere al calcolo probabilistico, risulta fondamentale conoscere il numero di eventi elementari che vanno a costituire lo spazio campione $\Omega$. Si espongono di seguito, per tale ragione, alcune fondamentali nozioni di calcolo combinatorio:

\vspace{1em}
\subsection{Disposizione con ripetizione}
Si espone di seguito la definizione di \textbf{dispozione con ripetizione}, in cui si considera una scelta che non condiziona quelle successive:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{DISPOSIZIONE CON RIPETIZIONE}}\\
    \parbox{\linewidth}{Dato $k \in \mathbb{N}$ e un insieme finito $A$, si chiama \textbf{disposizione con ripetizione} di $k$ elementi estratti da $A$ (o anche di \textbf{classe} $k$) una funzione
    \[f : \{1, ..., k\} \longrightarrow A\]
    \vspace{-1mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
In altre parole, considerando un insieme $A$, una disposizione con ripetizione di $k$ elementi estratti da $A$ non è altro che una $k$-upla di elementi dell'insieme $A$.\\
Ciò che è importante osservare, in tal senso, è che è \textbf{possibile scegliere uno stesso elemento più volte}. Si descriva, quindi, tale scelta, con una funzione
\[f : \{1, ..., k\} \longrightarrow A\]
ponendo

\begin{flalign*}
  f(1) & \text{ il primo elemento scelto}\\
  f(2) & \text{ il secondo elemento scelto}\\
  f(3) & \text{ il terzo elemento scelto}\\
  ... & \text{ ...}\\
  f(k) & \text{ il } k \text{-esimo elemento scelto}\\
\end{flalign*}

\noindent
In cui vi è una corrispondenza biunivoca tra la famiglia delle possibili disposizioni e l'insieme prodotto $A^k$ (ossia l'insieme delle $k$-uple con coordinate nell'insieme $A$): ad ogni disposizione $f$ è possibile associare la $k$-upla $(f(1),...,f(k))$, mentre ad ogni $k$-upla $(a_1,...,a_k)$ è possibile associare la disposizione
\[f(j) := a_j \hspace{1em} j= 1,...,k\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Si definisca quante disposizioni con ripetizione esistono di $k$ elementi su un insieme $A$ con $n$ elementi; ovviamente, vista la corrispondenza biunivoca ve ne sono
\[\boxed{\left \vert A^k \right \vert = n^k}\]
in quanto si hanno $n$ alternative per la scelta del primo elemento, $n$ alternative per la scelta del secondo elemento e così via fino al $k$-esimo elemento.

\vspace{1em}
\noindent
\textbf{Esempio}: Per compilare la colonna di una schedina del totocalcio occorre scegliere, per ciascuna delle $13$ partite considerate, un numero $A = \left\{1,\times,2\right\}$ ($1$ vittoria interna, $\times$ pareggio, $2$ vittoria esterna). Cioé bisogna effettuare una disposizione con ripetizione di $k=13$ elementi dall'insieme $A$. Quindi ci sono $3^{13} \cong 1,6$ milioni di modi per compilare la schedina.

\vspace{1em}
\subsection{Disposizione senza ripetizione}
Si espone di seguito la definizione di \textbf{dispozione senza ripetizione}, in cui si considera una scelta che condiziona quelle successive:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{DISPOSIZIONE SENZA RIPETIZIONE}}\\
    \parbox{\linewidth}{Dato $k \in \mathbb{N}$ e un insieme finito $A$, si chiama \textbf{disposizione senza ripetizione} di $k$ elementi estratti da $A$ una funzione \textbf{iniettiva}
    \[f : \{1, ..., k\} \longrightarrow A\]
    \vspace{-1mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
Le disposizioni senza ripetizione sono anche chiamate \textbf{disposizioni semplici}. Nel caso delle disposizioni con ripetizione, è assolutamente ininfluente la relazione tra $k$ ed $n$, con $n = \vert A \vert$ numero di elementi dell'insieme $A$; nel caso di disposizioni semplici, deve essere che $k \leq n$, in quanto altrimenti la funzione non potrebbe essere iniettiva, visto che a valori distinti di $k$ dovrebbe corrispondere uno stesso elemento.

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{PERMUTAZIONE}}\\
    \parbox{\linewidth}{Data una disposizione senza ripetizione di $k$ elementi estratti da $A$, se $k = \vert A \vert$, si parla di una \textbf{permutazione} dell'insieme $A$.
    \vspace{3mm}}\\
    \hline
\end{tabularx}
\vspace{1em}

\noindent
Dal punto di vista operativo, una disposizione senza ripetizione è una scelta di $k$ elementi all'interno di un insieme $A$, con il vincolo che
\begin{itemize}
  \item nello scegliere il secondo elemento, bisogna che esso sia diverso dal primo, cioé
  \[f(2) \neq f(1)\]
  \item nello scegliere il terzo elemento bisogna fare in modo che esso sia diverso dal primo e dal secondo, ovvero
  \[f(3) \neq f(1) \hspace{0.5em} \wedge \hspace{0.5em} f(3) \neq f(2)\]
  \item e così via.
\end{itemize}

\vspace{1em}
\noindent
Si determini quante disposizioni semplici esistono di $k$ elementi su un insieme $A$ con $n$ elementi; naturalmente si hanno $n$ possibilità per la prima scelta, $n-1$ per la seconda scelta (ovvero tutti gli elementi di $A$, escluso quello scelto precedentemente), e così via. Quindi il valore cercato è
\[\boxed{\underbrace{n \cdot (n-1) \cdot ... \cdot (n-k+1)}_\text{$k$ scelte} = \frac{n!}{(n-k)!}}\]
in cui l'uguaglianza si ottiene moltiplicando il lato sinistro per $(n-k)!$.

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri un mazzo di carte regolare, con $n=52$ carte. Naturalmente vi sono
\[52 \cdot 51 \cdot 50 \cdot 49 \cdot 48 \cong 312 \cdot 10^6\]
possibili modi per servire $k=5$ carte.

\vspace{1em}
\noindent
\textbf{Esercizio}: Si determini la probabilità $p_k$ che in un gruppo di $k$ persone selezionate casualmente (nessuna delle quali sia però nata il $29$ febbraio), almeno due di esse \textbf{compiono gli anni lo stesso giorno}.\\
Naturalmente, lo spazio degli eventi elementari $\Omega$ è costituito dalle possibili disposizioni con ripetizioni fi $k$ elementi dall'insieme degli $n=365$ giorni dell'anno (il $29/02$ è escluso per ipotesi). Infatti per ognuna delle $k$ persone viene selezionato un giorno di nascita. Si ha, quindi
\[\left \vert \Omega \right \vert = n^k = 365^k\]
La probabilità che una persona nasca in un dato giorno può essere assunta uniforme, e quindi può essere assunta uniforme anche la probabilità sulle disposizioni: ogni disposizione
\[f : \left\{1,...,k\right\} \longrightarrow \left\{1,...,365\right\}\]
ha probabilità
\[\frac{1}{\vert \Omega \vert} = \frac{1}{365^k}\]
Per risolvere la domanda del problema bisogna provvedere ad effettuarne la traduzione dal punto di vista matematico; l'evento di cui si deve effettuare il calcolo della probabilità $p_k$ è
\[A := \left\{f \in \Omega : f \text{ non è iniettiva}\right\}\]
Quindi
\[p_k = p(A) = 1 - p(A^c) = 1 - \frac{\vert A^c \vert}{\vert \Omega \vert}\]
ma siccome $A^c$ è costituito dalle disposizioni semplici, si ha
\[\vert A^c \vert = \frac{365!}{(365 - k)!} = \prod_{j=0}^{n-1} (365 - j)\]
per cui, finalmente, si ottiene
\[p_k = 1 - \frac{\displaystyle{\prod_{j=0}^{k-1}} (365 - j)}{365^k} = 1 - \prod_{j=0}^{k-1} \frac{365 - j}{365} = 1 - \prod_{j=0}^{k-1} \left(1 - \frac{j}{365}\right)\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Non appena $k \geq 23$, $p_k > \frac{1}{2}$. Cioé, in una classe di liceo vi è una probabilità superiore al $50\%$ che due persone compiano il compleanno lo stesso giorno.

\newpage
\begin{center}
  14 marzo 2022
\end{center}
\subsection{Combinazione}
Dopo aver esposto i concetti di disposizione con ripetizione e disposizione semplice, si espone di seguito il concetto di \textbf{combinazione}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{COMBINAZIONE}}\\
    \parbox{\linewidth}{Dato $k \in \mathbb{N}$ e un insieme finito $A$, si chiama \textbf{combinazione} di $k$ elementi estratti da $A$ i sottoinsiemi di $A$ di cardinalità $k$.
    \vspace{3mm}}\\
    \hline
\end{tabularx}
\vspace{1em}

\noindent
\textbf{Osservazione}: Si osservi che la differenza tra una disposizione e una combinazione è la rilevanza, nel primo, dell'ordine della disposizione degli elementi, fattore che nel secondo caso è ininfluente.\\
Infatti, ad una disposizione con ripetizione di $k$ elementi è possibile associare una $k$-upla, e quindi ad una disposizione semplice una $k$-upla senza ripetizione. Pertanto, è possibile considerare una disposizione semplice come una \textbf{collezione ordinata}, mentre una combinazione è una \textbf{collezione non ordinata}.

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri l'insieme $A = \left\{\iscircle,\square,\triangle\right\}$. Le disposizioni semplici di classe $k=2$ elementi possono essere identificate con le coppie ordinate
\[\left(\iscircle,\triangle\right) \hspace{0.5em} \left(\iscircle,\square\right) \hspace{0.5em} \left(\triangle,\square\right) \hspace{0.5em} \left(\triangle,\iscircle\right) \hspace{0.5em} \left(\square,\iscircle\right) \hspace{0.5em} \left(\square,\triangle\right)\]
Mentre le combinazioni, invece, sono
\[\left\{\iscircle,\triangle\right\} \hspace{0.5em} \left\{\iscircle,\square\right\} \hspace{0.5em} \left\{\triangle,\square\right\}\]
in quanto per le combinazioni non è rilevante l'ordine degli elementi dell'insieme, ma solamente gli elementi stessi.\\
Si determini, allora, il numero di combinazioni di $k$ lementi relative ad un insieme con $n$ elementi; al fine di rispondere a tale domanda, è sufficiente considerare una disposizione semplice di $k$ elementi (collezione ordinata) e procedere, poi, con la permutazione di tutti i $k$ elementi che la compongono, ottenendo una combinazione (collezione non ordinata). Da notare, infatti, che due collezioni ordinate (composte dagli stessi $k$ elementi) restituiscono la stessa collezione non ordinata; viceversa, da una collezione non ordinata, procedendo al suo ordinamento tramite permutazione dei suoi $k$ elementi si otterranno diverse collezioni ordinate, \textbf{tante quante sono le possibili permuazioni dei $\boldsymbol{k}$ elementi}.\\
Pertanto si ha

\vspace{1em}
\begin{table}[H]
  \rowcolors{1}{white}{white}
  \setlength{\tabcolsep}{14pt}
  \renewcommand{\arraystretch}{2}
  \noindent
  \begin{tabularx}{\textwidth}{P>{\hsize=0.005 \textwidth}PP>{\hsize=0.005 \textwidth}PP}
    \parbox{\linewidth}{Numero di combinazioni di $k$ elementi su $n$ elementi} & \multirow{2}{0.01em}{$\cdot$} & \parbox{\linewidth}{Numero di permutazioni di $k$ elementi} & \multirow{2}{0.01em}{$=$} & \parbox{\linewidth}{Numero di disposizioni semplici di $k$ elementi su $n$ elementi}\\
    $C_{n,k}$ & & $k!$ & & $\dfrac{n!}{(n-k)!}$\\
  \end{tabularx}
\end{table}

\vspace{1em}
\subsection{Coefficiente binomiale}
Peranto si è ottenuto che il numero di combinazioni di $k$ elementi su $n$ elementi è proprio
\[\boxed{C_{n,k} = \frac{n!}{k! \cdot (n-k)!}}\]
Tale quantità prende il nome di \textbf{coefficiente binomiale}, il quale viene indicato con il simbolo
\[\binom{n}{k}\]
Tenendo conto che, naturalmente, $k>0$ (in quanto non avrebbe senso una collezione di $0$ elementi), dal punto di visto matematico, visto che per $k=0$ si ha $k!=1$, si pone anche
\[\binom{n}{0}=1\]
Anche nel caso delle combinazioni, naturalmente, ha senso supporre $k \leq n$, in quanto per $k>n$ non ci sono disposizioni semplici di $k$ elementi, ovviamente. In generale, non esistono nemmeno combinazioni possibili con $k>n$, quindi si pone, per convenzione
\[\binom{n}{k} = 0 \hspace{1em} \text{se} \hspace{1em} k>n\]

\vspace{1em}
\noindent
\textbf{Esempio}: È noto che il numero dei possibili modi di servire $k=5$ carte da un mazzo da $n=52$ carte sono
\[\frac{52!}{(52-5)!} = \frac{52!}{47!}\]
ossia il numero di disposizioni semplici di $5$ elementi su $52$. Una volta, però, che le carte sono state distribuite, l'ordine con cui esse vengono disposte è ininfluente, pertanto vi sono
\[\binom{52}{5} = \frac{52!}{5! \cdot 47!}\]
possibili mani servite (ossia il numero di combinazioni di $5$ elementi su $52$).

\vspace{1em}
\subsubsection{Proprietà del coefficiente binomiale}
\begin{enumerate}
  \item La \textbf{prima proprietà} del coefficiente binomiale è di \textbf{simmetria}, ovvero
  \[\binom{n}{k} = \frac{n!}{k| \cdot (n-k)!} = \binom{n}{n-k} = \frac{n!}{(n-k)! \cdot (n - (n-k))!} \hspace{1em} \forall n \in \mathbb{N}, \forall k \in \{0,...,n\}\]

  \item La \textbf{seconda proprietà} prende il nome di \textbf{Formula di Stifel} e permette di esprimere la somma tra due coefficienti binomiali, come mostrato di seguito, scrivendo esplicitamente i due coefficienti binomiali
  \[\binom{n-1}{k-1} + \binom{n-1}{k} = \frac{(n-1)!}{(k-1)! \cdot (n-k)!} + \frac{(n-1)!}{k! \cdot (n-k-1)!}\]
  Ora, semplicemente, al fine di sommarli, è sufficiente impiegare le proprietà del fattoriale e scrivere
  \[\frac{1}{(k-1)!} = \frac{k}{k!} \hspace{1em} \text{e} \hspace{1em} \frac{1}{(n-k-1)!} = \frac{(n-k)}{(n-k)!}\]
  da cui si evince l'uguaglianza seguente
  \[\frac{(n-1)!}{(k-1)! \cdot (n-k)!} + \frac{(n-1)!}{k! \cdot (n-k-1)!} = \frac{(n-1)! \cdot k}{k! \cdot (n-k)!} + \frac{(n-1)! \cdot (n-k)}{k! \cdot (n-k)!}\]
  Ora che entrambi gli addendi presentano lo stesso denominatore, è possibile sommarli, ottenendo:
  \[\frac{(n-1)! \cdot k}{k! \cdot (n-k)!} + \frac{(n-1)! \cdot (n-k)}{k! \cdot (n-k)!} = \frac{n!}{k! \cdot (n-k)!} = \binom{n}{k} \hspace{1em} \forall n \in \mathbb{n}, \forall k \in \{0,...,n\}\]

  \item Infine, come \textbf{terza proprietà}, si espone la \textbf{formula del binomio di Newton}: siano $a,b \in \mathbb{R}$ e $n \in \mathbb{N}$, allora
  \[\boxed{(a+b)^n = \sum_{k=0}^n \binom{n}{k} a^k b^{n-k}}\]
  In particolare è noto che il numero di tutti i possibili raggruppamenti di oggetti estratti da un insieme, ovvero il numero di tutti i sottoinsiemi di un insieme è
  \[\boxed{\sum_{k=0}^n \binom{n}{k} = 2^n}\]
  ponendo $a=b=1$ nella formula del binomio di Newton.
\end{enumerate}

\vspace{1em}
\subsection{Permutazione con ripetizione}
Dopo aver introdotto il concetto di combinazione e di disposizione semplice e con ripetizione, é opportuno, ora, introdurre il significato della \textbf{permutazione con ripetizione}. Si consideri, a tal proposito, il seguente esempio: si supponga di disporre di $10$ palline numerate e anche colorate ($3$ blue, $4$ verdi e $3$ rosse):
\[\circled{blue!25}{1} \hspace{0.5em} \circled{blue!25}{2} \hspace{0.5em} \circled{blue!25}{3} \hspace{0.5em} \circled{green!25}{4} \hspace{0.5em} \circled{green!25}{5} \hspace{0.5em} \circled{green!25}{6} \hspace{0.5em} \circled{green!25}{7} \hspace{0.5em} \circled{red!25}{8} \hspace{0.5em} \circled{red!25}{9} \hspace{0.5em} \circled{red!25}{\small 10}\]
È possibile, ora, procedere all'ordinamento di tali oggetti, semplicemente provvedendo a permutarli, come mostrato di seguito
\[\circled{blue!25}{2} \hspace{0.5em} \circled{red!25}{8} \hspace{0.5em} \circled{green!25}{4} \hspace{0.5em} \circled{blue!25}{3} \hspace{0.5em} \circled{red!25}{\small 10} \hspace{0.5em} \circled{blue!25}{1} \hspace{0.5em} \circled{green!25}{5} \hspace{0.5em} \circled{green!25}{7} \hspace{0.5em} \circled{red!25}{9} \hspace{0.5em} \circled{green!25}{6}\]
Questo cirrisponde alla permutazione
\[f : \left\{1,...,10\right\} \longrightarrow A\]
con $A$ insieme delle palline, definita da
\[f(1)=2 \hspace{0.5em} f(2)=8 \hspace{0.5em} f(3)=4 \hspace{0.5em} \text{e così via}\]
Oppure ancora
\[\circled{blue!25}{3} \hspace{0.5em} \circled{red!25}{9} \hspace{0.5em} \circled{green!25}{6} \hspace{0.5em} \circled{blue!25}{1} \hspace{0.5em} \circled{red!25}{8} \hspace{0.5em} \circled{blue!25}{2} \hspace{0.5em} \circled{green!25}{7} \hspace{0.5em} \circled{green!25}{4} \hspace{0.5em} \circled{red!25}{\small 10} \hspace{0.5em} \circled{green!25}{5}\]
che corrisponde alla permutazione
\[g(1)=3 \hspace{0.5em} g(2)=9 \hspace{0.5em} g(3)=6 \hspace{0.5em} \text{e così via}\]
In cui il numero delle permutazioni è, naturalmente, $10!$, essendo una permutazione una disposizione semplice in cui $k=n$. Si osservi, però, che se nell'osservare le permutazioni si prende in considerazione esclusivamente il colore delle palline e non il loro valore, allora le due permutazioni precedenti sono perfettamente \textbf{equivalenti}. Formalmente, quindi, se l'insieme $A$ viene diviso in $3$ parti
\[\underbrace{A_1 = \{1,2,3\}}_\text{\textcolor{blue}{BLU}} \hspace{1em} \underbrace{A_2 = \{4,5,6,7\}}_\text{\textcolor{green}{VERDE}} \hspace{1em} \underbrace{A_3 = \{8,9,10\}}_\text{\textcolor{red}{ROSSO}}\]
e si osserva la controimmagine di ognuno di tali insimei attraverso $f$ è $g$ si ottiene
\begin{flalign*}
  f^{-1} (A_1) & = \{1,3,6\} = g^{-1}(A_1)\\
  f^{-1} (A_2) & = \{3,7,8,10\} = g^{-1}(A_2)\\
  f^{-1} (A_3) & = \{2,5,9\} = g^{-1}(A_3)\\
\end{flalign*}
cioé $f$ e $g$ spostano le palline di ogni colore sullo stesso blocco di posizioni.\\
Considerado, quindi, equivalenti due permutazioni che spostano i colori nello stesso modo, il numero di tali permutazioni non sarà più $10!$, ma tale quantità dovrà essere divisa per tutte le permutazioni che si reputano identiche: quindi $3!$ nel caso del \textcolor{blue}{blu}, $4!$ nel caso del \textcolor{green}{verde} e ancora $3!$ nel caso del \textcolor{red}{rosso}. Pertanto il numero di permutazioni che portano colori uguali in colori uguali, senza tenere conto dei è numeri è proprio
\[\frac{10!}{3! \cdot 4! \cdot 5!}\]

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{PERMUTAZIONE CON RIPETIZIONE}}\\
    \parbox{\linewidth}{Dato un insieme finito $A$, sia $\{A_1,...,A_q\}$ una sua partizione, cioé
    \[\bigcup_{j=1}^q A_j = A\]
    e gli $A_j$ sono a due a due disgiunti. Si chiama \textbf{permutazione con ripetizione} una permutazione in cui si considerano uguali gli elementi di uno stesso sottoinsieme $A_j$. Ciò significa che si considerano equivalenti due permutazioni $f$ e $g$ su $A$ quando
    \[f^{-1}(A_j) = g^{-1}(A_j) \hspace{1em} \forall j = 1,...,q\]
    ovvero le controimmagini di ciascuna permutazione coincidono.
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
Generalizzando, è possibile affermare che il numero di permutazioni con ripetuzione è
\[\boxed{\dfrac{n!}{\displaystyle{\prod_{j=1}^q n_j!}} \hspace{1em} \text{dove} \hspace{1em} \prod_{j=1}^q n_j! = (n_1)! \cdot ... \cdot (n_q)!}\]
in cui $n = \vert A \vert$, ossia il numero degli elementi dell'insieme $A$ e $n_j = \vert A_j \vert$, ossia il numero degli elementi della partizione $A_j$. Questo è dovuto al fatto che permutando internamente gli elementi di uno stesso sottoinsieme $A_j$ si ottiene una nuova permutazione, ma equivalente alla precedente.

\vspace{1em}
\noindent
\textbf{Esempio}: Sia $A = \{a,b,c,d\}$. Le possibili permutazioni di $A$ sono $4!=24$. Si considerino, ora, le permutazioni con ripetuzione relative alla partizione
\[A_1 = \{a\} \hspace{1em} A_2 = \{b\} \hspace{1em} A_3 = \{c,d\}\]
che, in pratica, equivale a non distinguere la lettera \quotes{$c$} dalla lettera \quotes{$d$}; pertanto
\[abcd \hspace{1em} abdc \hspace{1em} \text{sono equivalenti}\]
\[adbc \hspace{1em} acbd \hspace{1em} \text{sono equivalenti}\]
e così via. Il numero totale di permutazioni con ripetizione è, quindi
\[\frac{4!}{1! \cdot 1! \cdot 2!} = \frac{24}{2} = 12\]

\vspace{1em}
\subsection{Principio fondamentale del calcolo combinatorio}
Si espone di seguito il \textbf{principio fondamentale del calcolo combinatorio}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{PRINICIPIO FONDAMENTALE DEL CALCOLO COMBINATORIO}}\\
    \parbox{\linewidth}{Si supponga che gli elementi di una configurazione possano essere determinati mediante $q$ scelte \textbf{successive} ed \textbf{indipendenti} (ovvero totalmente ininfluenti una sull'altra), in cui ogni scelta abbia un numero fissato di opzioni: la prima scelta ha $n_1$ opzioni, la seconda $n_2$ opzioni, ..., la $q$-esima scelta ha $n_q$ opzioni.\\
    Se sequenze distinte di opzioni nelle scelte determinano configurazioni distinte, allora il numero totale di configurazioni cche è possibile ottenere è pari a
    \[\boxed{\prod_{j=1}^q n_q}\]
    ossia dal prodotto delle possibili opzioni che si hanno a disposizione ad ogni scelta.
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Esempio}: Si supponga di entrare in una gelateria, in cui vi sono solamente tre gusti: cioccolato/crema/puffo. Considerando che è possibile scegliere anche tra cono e coppetta, si determinino quante configurazioni esistono per il proprio gelato se è possibile scegliere due palline.\\
Naturalmente si hanno $n_1=2$ opzioni per la base (cono/coppetta) e $n_2=6$ opzioni per i gusti ($3$ nel caso di palline uguali e $3$ nel caso di palline diverse). Tenuto conto cche ad opzioni distinte corrispondono configurazioni finali distinte, si hanno $6 \cdot 2 = 12$ possibili assemblaggi.

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che il principio fondamentale del calcolo combinatorio prevede che le scelte da effettuare siano \textbf{indipendenti}, pertanto non è applicabile nel caso in cui da una scelta dipenda la scelta successiva.\\
Inoltre vi è il vincolo che \textbf{a scelte distinte corrispondano configurazioni finali distinte}: se, infatti, fosse sta individuata una prima scelta e una seconda scelta di gusto di gelato, si sarebbe potuto scegliere puffo e crema o crema e puffo ottenendo sempre la stessa configurazione finale, ma avendo prediletto opzioni distinte in principio.

\vspace{1em}
\noindent
\textbf{Esercizio}: Si impieghi, ora, il principio fondamentale del calcolo combinatorio per determinare il numero di possibili permutazioni con ripetizione, designato con $c$.\\
Si esamini, a tal proposito, il caso specifico delle palline colorate
\[\circled{blue!25}{2} \hspace{0.5em} \circled{red!25}{8} \hspace{0.5em} \circled{green!25}{4} \hspace{0.5em} \circled{blue!25}{3} \hspace{0.5em} \circled{red!25}{\small 10} \hspace{0.5em} \circled{blue!25}{1} \hspace{0.5em} \circled{green!25}{5} \hspace{0.5em} \circled{green!25}{7} \hspace{0.5em} \circled{red!25}{9} \hspace{0.5em} \circled{green!25}{6}\]
e si supponga di voler \quotes{assemblare} una permutazione: è possibile decidere dapprima dove posizionare i colori e per farlo si dispone di $c$ opzioni. Poi si deve decidere dove posizionare i numeri sulle palline blu, per cui si hanno $3!$ opzioni, sulle palline verdi, per cui si hanno $4!$ opzioni e sulle palline rosse, per cui si hanno $3!$ opzioni. Per il principio fondamentale del calcolo combinatorio, il numero di possibili permutazioni è adato da:
\[10! = c \cdot 3! \cdot 4! \cdot 3! \hspace{1em} \text{e quindi} \hspace{1em} c = \frac{10!}{3! \cdot 4! \cdot 3!}\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Nel caso generale, per ottenere una permutazione dell'insieme $A$ bisogna prima scegliere
\[
  \left\{
  \rowcolors{1}{white}{white}
  \renewcommand{\arraystretch}{1}
  \begin{array}{l}
    \text{le } n_1 \text{ posizioni su cui mettere gli elementi di } A_1\\
    ...\\
    \text{le } n_q \text{ posizioni su cui mettere gli elementi di } A_q\\
  \end{array}
  \right.
\]
cioé si fissa una specifica permutazione con ripetizione; si dispone, poi
\[
  \left\{
  \rowcolors{1}{white}{white}
  \renewcommand{\arraystretch}{1}
  \begin{array}{l}
    \text{gli } n_1 \text{ elementi di } A_1 \text{ nelle posizioni prescelte}\\
    ...\\
    \text{gli } n_q \text{ elementi di } A_q \text{ nelle posizioni prescelte}\\
  \end{array}
  \right.
\]
Pertanto, nella prima scelta si hanno $c$ possibili opzioni (ossia le permutazioni con ripetizione) e poi si hanno $n_1!$ opzioni nella seconda scelta (ossia le permutazioni su $A_1$), ..., ed infine si hanno $n_q!$ nell'ultima scelta (ossia le permutazioni su $A_q$). Pertanto si ha, per il principio fondamentale:
\[n! = c! \cdot n_1! \cdot ... \cdot n_q! = c \cdot \prod_{j=1}^q n_j!\]
che restituisce il risultato già ottenuto
\[\boxed{\dfrac{n!}{\displaystyle{\prod_{j=1}^q n_j!}} \hspace{1em} \text{dove} \hspace{1em} \prod_{j=1}^q n_j! = (n_1)! \cdot ... \cdot (n_q)!}\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che finora il concetto di disposizione con ripetizione, disposizione semplice e combinazione in modo matematico e preciso, mentre il concetto di permutazione con ripetizione è stato fornito in maniera intuitiva ed impirica.\\
Per essere più precisi, si rammenti che dato un insieme $E$, una \textbf{relazione} su $E$ è detta di \textbf{equivalenza} se è
\begin{itemize}
  \item \textbf{riflessiva}: $x \sim x$ $\forall x \in E$
  \item \textbf{simmetrica}: $x \sim y$ allora $y \sim x$ $\forall x,y \in E$
  \item \textbf{transitiva}: $x \sim y$ e $y \sim z$ allora $x \sim z$ $\forall x,y,z \in E$
\end{itemize}
Due elementi $x,y$ sono detti \textbf{equivalenti} se sono in relazione attraverso una relazione di equivalenza. La \textbf{classe di equivalenza} di un elemnto $x$ è definita come
\[[x] := \{y \in E : x \sim y\}\]
Per la riflessività, $x \in [x]$; per la simmetria, se $y \in [x]$ allora anche $x \in [y]$, mentre per la transitività, se $y \in [x]$ allora $x \sim y$ e se $z \in [x]$ allora $z \sim x$ e quindi $z \sim y$, quindi $z \in [y]$, per ogni scelta di $z$ (la stessa cosa vale se si parte considerando $z \in [y]$).\\
Dal primo risultato ($x \in [x]$), segue che ogni elementi di $E$ apartiene alla propria classe di equivalenza, la famiglia delle classi di equivalenza copre completamente l'insieme $E$; non solo, ma se si considerano due classi di equivalenza, o queste coincidono o queste sono disgiunte, per cui le classi di equivalenza costituiscono una partizione di $E$.

\vspace{1em}
\noindent
\textbf{Esempio $\boldsymbol{1}$}: Sia $\mathbb{R} - \{0\}$ e si consideri la seguente relazione di equivalenza: $x \sim y$ se e solo se $x \cdot y > 0$ (cioé se $x$ e $y$ presentano lo stesso segno). È facile verificare che si tratta di una relazione di equivalenza, in quanto le classi di equivalenza sono due:
\[\{x \in \mathbb{R} : x > 0\} \hspace{1em} \text{e} \hspace{1em} \{x \in \mathbb{R} : x < 0\}\]

\vspace{1em}
\noindent
\textbf{Esempio $\boldsymbol{2}$}: Sia
\[A := \{f : [0,1] \longrightarrow \mathbb{R}\}\]
e si ponga $f \sim g$ se e solo se $\exists c \in \mathbb{R} : f-g=c$ (cioé $f$ e $g$ sono una la traslata dell'altra in verticale). Anche in questo caso è facile verificare ce si tratta di una relazione di equivalenza.

\vspace{1em}
\noindent
\textbf{Osservazione}: Nella definzione di permutazione con ripetizione sono state considerate equivalenti due permutazioni $f$ e $g$ su $A$ quando
\[f^{-1}(A_J) = g^{-1}(A_j) \hspace{1em} \forall j=1,...,q\]
anche in questo caso si tratta di una relazione di equivalenza. Formalmente, dunque, \textbf{una permutazione con ripetizione è una classe di equivalenza} rispetto alla relazione
\[f^{-1}(A_J) = g^{-1}(A_j) \hspace{1em} \forall j=1,...,q\]
nella famiglia delle permutazioni.

\newpage
\noindent
\begin{center}
  17 Marzo 2022
\end{center}
Dopo aver definito il concetto di permutazione con ripetizione rispetto ad una partizione, è necessario procedere ad osservare un'applicazione di tal concetto:

\vspace{1em}
\noindent
\textbf{Esempio}: Si supponga di disporre di $10$ libri e di volerli disporre su una libreria avente $5$ ripiani. Si vuole sapere in quanti modi è possibile farlo, senza tenere conto di quali siano i libri, ma solo di quanti ne si pone su ogni scaffale.\\
Per esempio, dati i $5$ scaffali, vi si riporta quanti libri è stato deciso di porvisi, come mostrato di seguito
\[\boxed{3}\boxed{3}\boxed{0}\boxed{2}\boxed{2}\]
in cui, decidere di porre $3$ manga al primo piano e i $3$ libri di probabilità sul secondo o viceversa conta come una stessa configurazione.\\
Similmente, si sarebbe voluto sapere come suddividere $7$ paia di calzini in $3$ cassetti; se vengono disposti come segue
\[\boxed{2}\boxed{2}\boxed{3}\]
non è facile determinare il numero totale delle disposizioni. Più in generale, dati $n$ oggetti e $k$ contenitori, si calcoli il numero di possibili disposizioni.\\
Nel caso in cui $n=10$ e $k=5$, si considerino $10$ tessere bianche (corrispondenti ai $10$ libri) e $4=k-1$ tessere nere (corrispondenti ai divisori dei $5$ scaffali) e si dispongano in fila come segue:
\[\underbrace{\square\square}_\text{$2$}\blacksquare\underbrace{}_\text{$0$}\blacksquare\underbrace{\square\square\square}_\text{$3$}\blacksquare\underbrace{\square\square}_\text{$2$}\blacksquare\underbrace{\square\square\square}_\text{$3$}\]
Naturalmente questa è una possibile configurazione: $2$ tessere bianche prima della prima nera, $0$ bianche tra la prima e la seconda nera, $3$ bianche tra la seconda e la terza nera, $2$ bianche tra la terza e la quarta nera e $3$ bianche dopo la quarta nera. Si può associare, quindi, a questa configurazione di tessere la seguente configurazione di libri:
\[\boxed{2}\boxed{0}\boxed{3}\boxed{2}\boxed{3}\]
È ovvio che sussista una corrispondenza biunivoca tra le configurazioni delle tessere e le configurazioni dei libri. La configurazione di libri iniziale, per esempio, restituisce per le tessere la seguente:
\[\underbrace{\square\square\square}_\text{$3$}\blacksquare\underbrace{\square\square\square}_\text{$3$}\blacksquare\underbrace{}_\text{$0$}\blacksquare\underbrace{\square\square}_\text{$2$}\blacksquare\underbrace{\square\square}_\text{$2$}\]
Pertanto vi sono tante configurazioni di libri quante sono quelle per le tessere. Le configurazioni per le tessere sono permutazioni con ripetizione (rispetto alla partizione bianco/nero) e sono in numero di
\[\frac{14!}{10! \cdot 4!} = 1001\]
ovverosia $14$ tessere, partizionate in $10$ e $4$. Più in generale, ripetendo lo stesso ragionamento con $n$ oggetti e $k$ contenitori, le configurazioni sono in numero uguale a quelle delle permutazione con ripetizione di $n+k-1$ tessere partizionate in $n$ e $k-1$. Quindi
\[\boxed{\frac{(n+k-1)!}{n! \cdot (k-1)!} = \binom{n+k-1}{n}}\]
così facendo, nell'esempio dei calzini, con $n=7$ e $k=3$ si hanno
\[\frac{9!}{7! \cdot 2!} = 36\]
configurazioni. Da notare che se si considera un solo oggetto ($n=1$), allora vi sono solo $k$ configurazioni possibili, ovviamente.

\newpage
\noindent
\textbf{Osservazione}: Si osservi che i rudimenti di calcolo combinatorio fin ad ora analizzati (disposizioni semplici e con ripetizione, combinazioni, permutazioni con ripetzione rispetto ad una partizione) non sono semplici strumenti per risolvere problemi probabilistici, ma modi estremamente eficaci di contare possibili configurazioni.\\
Tale aspetto è essenziale quando si opera con probabilità finita, dal momento che è indispensabile per sapere quanti sono \textbf{tutti} i casi possibili e quanti sono quelli \textbf{favorevoli} (cioé quelli di interesse nell'evento considerato).

\vspace{1em}
\subsection{Combinazione con ripetizione}
Si espone di seguito la definizione di \textbf{combinazione con ripetizione}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{COMBINAZIONE CON RIPETIZIONE}}\\
    \parbox{\linewidth}{Dato $k \in \mathbb{N}$ e un insieme finito $A$, si chiama \textbf{combinazione con ripetizione} di classe $k$ su $A$ tutti i possibili raggruppamente di cardinalità $k$ che si possono formare con gli elementi di $A$, includendo eventuali ripetizioni.\\
    Da notare che due raggruppamenti vengono considerati differenti quando differiscono
    \begin{itemize}
      \item per qualche elemento;
      \item per il numero di volte in cui un dato elemento viene ripetuto.
    \end{itemize}
    \vspace{1mm}}\\
    \hline
\end{tabularx}

\vspace{2em}
\noindent
\textbf{Esempio}: Sia $A=\{1,2,3,4,5\}$ e si determinino le combinazioni con $2$ elementi e quali quelle con ripetizione. Naturalmente le combinazioni con $2$ elementi sono:
\[\{1,2\} \hspace{0.25em},\hspace{0.25em} \{1,3\} \hspace{0.25em},\hspace{0.25em} \{1,4\} \hspace{0.25em},\hspace{0.25em} \{1,5\} \hspace{0.25em},\hspace{0.25em} \{2,3\} \hspace{0.25em},\hspace{0.25em} \{2,4\} \hspace{0.25em},\hspace{0.25em} \{2,5\} \hspace{0.25em},\hspace{0.25em} \{3,4\} \hspace{0.25em},\hspace{0.25em} \{3,5\} \hspace{0.25em},\hspace{0.25em} \{4,5\}\]
ovvero sono
\[C_{5,2} = \binom{5}{2} = \frac{5!}{2! \cdot 3!} = 10\]
Se, invece, si possono ripetere qualche elemento, allora vanno anche considerate, oltre a quelle già esposte, le seguenti:
\[\{1,1\} \hspace{0.25em},\hspace{0.25em} \{2,2\} \hspace{0.25em},\hspace{0.25em} \{3,3\} \hspace{0.25em},\hspace{0.25em} \{4,4\} \hspace{0.25em},\hspace{0.25em} \{5,5\}\]
Allora, per determinare il numero di combinazioni con ripetizione di classe $k$ su un insieme finito $A$ di cardinalità $n$ si consideri che gli elementi di $A = \{a_1,...,a_n\}$ siano delle scatole, come mostrato di seguito:
\[\boxed{a_1}\boxed{a_2}\boxed{a_3}\boxed{a_4}\boxed{a_5}\boxed{a_6}\boxed{a_7}\boxed{a_8}\boxed{a_9}\boxed{a_{10}}\boxed{a_{11}}\boxed{a_{12}}\boxed{...}\boxed{a_n}\]
Si considerino, ora, $k$ oggetti e si pongano questi ultimi all'interno delle scatole. Infine si formi una combinazione con ripetizione con gli elementi $a_j$ che come scatola contengono almeno un ogetto, e si ripetano tante volte quanti sono gli oggetti che stanno nella scatola.\\
Per esempio, con $k=5$ si possono porre $2$ oggetti nella scatola $a_3$, $1$ nella scatola $a_5$ e due nalla scatola $a_8$. La combinazione relativa sarà
\[\{a_3,a_3,a_5,a_8,a_8\}\]
Si è così creata una corrispondenza biunivoca tra le combinazioni con ripetizione di classe $k$ su $n$ elementi e i modi di mettere $k$ oggetti in $n$ contenitori. Detto $C_{n,k}^r$ il numero delle combinazioni con ripetizione, per quanto visto sui contenitori, è possibile affermare che
\[\boxed{C_{n,k}^r = \binom{n+k-1}{k}}\]
e si noti che sono $k$ oggetti in $n$ contenitori e non viceversa.

\newpage
\noindent
\textbf{Esempio}: Si scrivano tutte le combinazioni con ripetizione di classe $3$ sull'insieme $A=\{a,b,c\}$. Allora si hanno:
\[\{a,a,a\} \hspace{0.25em},\hspace{0.25em} \{a,a,b\} \hspace{0.25em},\hspace{0.25em} \{a,a,c\} \hspace{0.25em},\hspace{0.25em} \{a,b,b\} \hspace{0.25em},\hspace{0.25em} \{a,b,c\} \hspace{0.25em},\hspace{0.25em} \{a,c,c\} \hspace{0.25em},\hspace{0.25em} \{b,b,b\} \hspace{0.25em},\hspace{0.25em} \{b,b,c\} \hspace{0.25em},\hspace{0.25em} \{b,c,c\} \hspace{0.25em},\hspace{0.25em} \{c,c,c\}\]
Nello scrivere aiuta sapere in anticipo che sono
\[C_{5,3}^r = \binom{5}{3} = \frac{5!}{3! \cdot 2!} = 10\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Pertanto, si hanno le seguenti formule per calcolare il numero di configurazione di classe $k$ di $n$ oggetti:

\vspace{1em}
\rowcolors{1}{white}{white}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{3}
\noindent
\begin{tabularx}{\textwidth}{@{}P|P|P@{}}
    \multicolumn{3}{c}{\textbf{CONFIGURAZIONI DI CLASSE $\boldsymbol{k}$ SU $\boldsymbol{n}$ OGGETTI}}\\
    \hline
    & \parbox{\linewidth}{\centering SEMPLICI} & \parbox{\linewidth}{\centering CON RIPETIZIONE}\\
    \hline
    \parbox{\linewidth}{DISPOSIZIONI (configurazioni ordinate)} & {$\dfrac{n!}{(n-k)!}$} & {$n^k$}\\
    \hline
    \parbox{\linewidth}{COMBINAZIONI (configurazioni non ordinate)} & {$\displaystyle{\binom{n}{k}}$} & {$\displaystyle{\binom{n+k-1}{k}}$}\\
    \hline
\end{tabularx}

\vspace{1em}
\subsection{Estrazione}
Si supponga di disporre di un'urna contenente $N$ palline di due colori: si considerino $M$ palline bianche e $N-M$ palline nere (con $M \leq N$). Si supponga di eseguire $n$ estrazioni successive. Naturalmente si hanno due cateogorie
\begin{itemize}
  \item \textbf{Estrazione senza reimmissione}, cioé le palline estratte non vengono reinserite. In questo caso deve essere $n \leq N$;
  \item \textbf{Estrazione con reimmissione}, cioé ad ogni estrazione la pallina estratta viene reinserita nell'urna.
\end{itemize}
Per ciascuna delle due cateogorie bisogna calcolare la probabilità che $k$ delle $n$ palline estratte siano bianche.\\
Numerando da $1$ ad $M$ le palline bianche e da $M+1$ a $N$ le palline nere si consideri la prima cateogoria: l'evento \quotes{il numero di palline bianche estratte è $k$} non dipende dall'ordine di estrazione, quindi è possibile prendere
\[\Omega := \{\text{combinazioni di classe } n \text{ sull'insieme delle } N \text{ palline}\}\]
Da questo è immediato capire che
\[\left \vert \Omega \right \vert = \binom{N}{n}\]
L'evento favorevole è
\[A := \{\omega \in \Omega : \left \vert \omega \cap \{1,...,M\} \right \vert = k\} = \{\omega \in \Omega : \left \vert \omega \cap \{\omega \cap \{M+1,...,N\} \right \vert = n-k\}\]
cioé le combinazioni che hanno $k$ elementi bianchi sono uguali alle combinazioni che hanno $n-k$ elementi neri.\\
È possibile determinare una configurazione $\omega \in A$ attraverso due scelte:
\begin{itemize}
  \item scegliere la parte di $\omega$ in $\{1,...,M\}$, cioé una combinazione di classe $k$. Naturalmente in questo caso si hanno
  \[\binom{M}{k}\]
  opzioni.
  \item Scegliere la parte di $\omega$ in $\{M+1,...,N\}$, cioè una combinazione di classe $n-k$. Pertanto si hanno
  \[\binom{N-M}{n-k}\]
  opzioni.
\end{itemize}

\[\overbrace{\circled{white}{1} \hspace{0.5em} \circled{white}{2} \hspace{0.5em} \circled{white}{3} \hspace{0.5em} \circled{white}{1} \hspace{0.5em} ... \hspace{0.5em} \circled{white}{M}}^\text{M}_\text{si scelgono k palline} \hspace{0.5em} \overbrace{\circled{black!25}{\tiny M+1} \hspace{0.5em} \circled{black!25}{\tiny M+2} \hspace{0.5em} \circled{black!25}{\tiny M+3} \hspace{0.5em} ... \hspace{0.5em} \circled{black!25}{N}}^\text{N-M}_\text{si scelgono n-k palline}\]
In questo modo si ottengono tutte le possibili configurazioni. Per il \textbf{teorema fondamentale del calcolo combinatorio}, il loro numero totale è dato da
\[\left \vert A \right \vert = \binom{M}{k} \cdot \binom{N-M}{n-k}\]
Una volta che è nota la cardinalità di $\Omega$ e di $A$, si può procedere ad assegnare le probabilità elementari: ancora una volta, si osserva che tale compito è affidato alla statistica, in quanto di natura prettamente euristica. Tuttavia, una configurazione significa infilare una mano nell'urna e tirare fuori $n$ palline: è quindi naturale assumere che le configurazioni abbiano tutte la stessa probabilità.\\
La probabilità elementare sulla singola configurazione è data, ovviamente, da
\[\frac{1}{\vert \Omega \vert}\]
in quanto la probabilità totale dello spazio $\Omega$ deve essere pari a $1$. La probabilità dell'evento $A$ è data, invece, da
\[p(A) = \frac{\vert A \vert}{\vert \Omega \vert} = \frac{\displaystyle{\binom{M}{k} \cdot \binom{N-M}{n-k}}}{\displaystyle{\binom{N}{n}}}\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che non sarebbe cambiato nulla se invece di considerare le combinazioni fossero state considerate delle disposizioni semplici. In altre parole, se invece di estrare dall'urna un mucchio di $n$ palline se ne fosse estratta una per volta e messa in ordine in fila il risultato sarebbe stato identico. Tuttavia, il problema è che ad ogni combinazione di classe $n$ corrispondono $n!$ disposizioni semplici di classe $n$, per cui il problema si sarebbe inutilmente complicato.\\
Quindi prendendo come spazio degli eventi elementari
\[\hat{\Omega} = \{\text{disposizioni semplici di classe } n \text{ sull'insieme delle } N \text{ palline}\}\]
ed indicato con $\hat{A}$ l'evento favorevole, si hanno $\vert \hat{\Omega} \vert = n! \cdot \vert \Omega \vert$ e $\hat{A} = n! \cdot \vert A \vert$, cossicché
\[p(\hat{A}) = \frac{\vert \hat{A} \vert}{\vert \hat{\Omega} \vert} = \frac{\vert A \vert}{\vert \Omega \vert} = p(A)\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Si proceda, ora, all'analisi dell'estrazione con reimmissione di $3$ palline di un'urna con $3$ palline. È possibile estrarre in modo ordinato, per cui vi sono $3^3=27$ disposizioni con ripetizione (di classe $3$ su $3$ oggetti):
\begin{align*}
  (1,1,1) \hspace{0.25em} , \hspace{0.25em} (2,2,2) \hspace{0.25em} , \hspace{0.25em} (3,3,3)\\\\
  (1,1,2) \hspace{0.25em} , \hspace{0.25em} (1,2,1) \hspace{0.25em} , \hspace{0.25em} (2,1,1) \hspace{0.25em} , \hspace{0.25em} (1,1,3) \hspace{0.25em} , \hspace{0.25em} (1,3,1) \hspace{0.25em} , \hspace{0.25em} (3,1,1)\\
  (2,2,1) \hspace{0.25em} , \hspace{0.25em} (2,1,2) \hspace{0.25em} , \hspace{0.25em} (1,2,2) \hspace{0.25em} , \hspace{0.25em} (2,2,3) \hspace{0.25em} , \hspace{0.25em} (2,3,2) \hspace{0.25em} , \hspace{0.25em} (3,2,2)\\
  (3,3,1) \hspace{0.25em} , \hspace{0.25em} (3,1,3) \hspace{0.25em} , \hspace{0.25em} (1,3,3) \hspace{0.25em} , \hspace{0.25em} (3,3,2) \hspace{0.25em} , \hspace{0.25em} (3,2,3) \hspace{0.25em} , \hspace{0.25em} (2,3,3)\\\\
  (1,2,3) \hspace{0.25em} , \hspace{0.25em} (1,3,2) \hspace{0.25em} , \hspace{0.25em} (2,1,3) \hspace{0.25em} , \hspace{0.25em} (2,3,1) \hspace{0.25em} , \hspace{0.25em} (3,1,2) \hspace{0.25em} , \hspace{0.25em} (3,2,1)
\end{align*}
che sono state opportunamente suddivise in classi: il primo gruppo sono le disposizioni con $3$ ripetizioni, a ciascuna delle quali corrisponde una combinazione, il secondo gruppo sono disposizioni con $2$ ripetizioni che, a tre a tre, corrispondono ad una sola combinazione, mentre il terzo gruppo contiene sei disposizioni con $3$ ripetizioni, corrispondenti ad una sola combinazione.\\
Alternativamente è possibile solamente segnare i risultati senza tenere conto dell'ordine di estrazione. In questo secondo caso si avrebbero
\[\binom{5}{3}=10\]
combinazioni con ripetizione (di classe $3$ su $3$ oggetti):
\begin{align*}
  \{1,1,1\} \hspace{0.25em} , \hspace{0.25em} \{2,2,2\} \hspace{0.25em} , \hspace{0.25em} \{3,3,3\}\\\\
  \{1,1,2\} \hspace{0.25em} \hspace{0.25em} , \hspace{0.25em} \{1,1,3\} \hspace{0.25em} , \hspace{0.25em} \{2,2,1\} \hspace{0.25em} , \hspace{0.25em} \{2,2,3\} \hspace{0.25em} , \hspace{0.25em} \{3,3,1\} \hspace{0.25em} , \hspace{0.25em} \{3,3,2\}\\\\
  \{1,2,3\}
\end{align*}
Come si osserva, nel caso di estrazioni con reimmissione, la cardinalità della corrispondenza tra disposizioni e combinazioni varia: $1$ a $1$, $3$ a $1$ e $6$ a $1$ (mentre nel caso di estrazioni senza reimmissione, la corrispondenza era costante: a $1$ combinazione corrispondevano $n!$ disposizioni). Poichè sull'estrazione singola le tre palline sono equiprobabili, ammesso che siano palline uguali, appare ragionevole assegnare a tutte le disposizioni con ripetizione la stessa probabilità, mentre alle combinazioni con ripetizione l'assegnazione va, invece, pesata opportunamente.\\
Si esamini in senso generale la seconda categoria di estrazioni: estrazione con reimmissione. Sulla base di quanto appena detto, è meglio considerare anche l'ordine di estrazione e prendere
\[\Omega := \{\text{disposizioni con ripetizione di classe } n \text{ sull'insieme delle } N \text{ palline}\}\]
Naturalmene si considerano disposizioni con ripetizione perché le palline una volta estratte vengono reinserite. Per cui si ha che
\[\vert \Omega \vert = N^n\]
L'evento favorevole è
\[A := \{f : \{1,...,n\} \longrightarrow \{1,...,N\} \text{ tale che } \left \vert f^{-1} \left(\{1,...,M\}\right) \right \vert = k\}\]
cioé le disposizioni con ripetizione che pescano $k$ elementi bianchi. Per determinare $\vert A \vert$ si utilizza il principio fondamentale in maniera simile a come è stato usato per le permutazioni con ripetizione con ripetizione rispetto ad una partizione.\\
Per ottenere una disposizione $f$ in $A$
\begin{itemize}
  \item si scelgono le $k$ posizioni, su $n$ possibili, in cui mettere le palline bianche. Naturalmente si hanno
  \[\binom{n}{k}\]
  opzioni, essendo la scelta una combinazione di classe $k$ su $n$ elementi.

  \item si dispongono $k$ palline bianche (eventualmente con ripetizione) nelle posizioni prescelte. Naturalmente si hanno $M^k$ opzioni, essendo la scelta una disposizione.

  \item si dispongono $n-k$ palline nere (eventualmente con ripetizione) nelle restanti $n-k$ posizioni. Naturalmente si hanno $(N-M)^{n-k}$ opzioni, essendo la scelta una disposizione.
\end{itemize}
In questo modo si ottengono tutte le possibile configurazioni. Per il principio fondamentale il loro numero totale è dato da
\[\vert A \vert = \binom{n}{k} \cdot M^k \cdot (N-M)^{n-k}\]
È possibile, quindi, concludere che
\[\boxed{p(A) = \frac{\vert A \vert}{\vert \Omega \vert} = \binom{n}{k} \cdot \frac{M^k \cdot (N-M)^{n-k}}{N^n} = \binom{n}{k} \cdot S^k \cdot (1-S)^{n-k}}\]
ponendo
\[S=\frac{M}{N}\]

\newpage
\noindent
\begin{center}
  24 Marzo 2022
\end{center}
\section{Probabilità condizionale}
Per l'introduzione del concetto di \textbf{probabilità condizionale} si espone di seguito un caso pratico: si consideri un'urna contenente $10$ palline numerate da $1$ a $10$; si effettui un'estrazione e si determini la probabilità che la pallina estratta abbia un numero $\leq 5$. Naturalmente come spazio degli eventi elementari si considera
\[\Omega := \{1,2,...,10\}\]
e, supponendo che le palline siano tutte uguali fra di loro, si consideri la probabilità uniforme
\[p(\{\omega\}) = \frac{1}{\vert \Omega \vert} = \frac{1}{10} \hspace{1em} \forall \omega \in \Omega\]
che si estende ad ogni sottoinsieme $A \subset \Omega$ al solito modo:
\[p(A) = \frac{\vert A \vert}{\vert \Omega \vert} = \frac{\vert A \vert}{10}\]
L'evento favorevole a cui si è interessati è
\[A := \{\omega \in \Omega : \omega \leq 5\}\]
E quindi la probabilità cercata è proprio
\[p(A)=\frac{1}{2}\]
Si supponga, ora, di sapere a priori che il numero uscito sia pari. Ciò porta a \textbf{modificare lo spazio campione} considerato nell'insieme dei numeri pari
\[B := \{2,4,6,8,10\}\]
con una probabilità uniforme
\[\widetilde{p}(\{\omega\}) = \frac{1}{\vert \Omega \vert} = \frac{1}{5} \hspace{1em} \forall \omega \in B\]
Ora, naturalmente, l'evento a cui si è interessati dovrà essere trasferito sullo spazio campione $B$ (e non più $\Omega$), ed è
\[C:=\{\omega \in B : \omega \leq 5\} = \{2,4\}\]
Si ha, quindi:
\[\widetilde{p}(C) = \frac{\vert C \vert}{\vert B \vert} = \frac{2}{5}\]
Cioé, sapendo a priori che il numero estratto è pari (informazione aggiuntiva), la probabilità che esca un numero $\leq 5$ sale a $\frac{2}{5}$. Si noti che $C = A \cap B$ e che
\[\widetilde{p}(C) = \frac{\vert A \cap B \vert}{\vert B \vert} = \frac{p(A \cap B)}{p(B)}\]
in cui, naturalmente, il rapporto delle probabilità deve essere sempre riferito allo spazio campione di partenza.\\
Ciò permette di fornire la seguente definizione:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{PROBABILITÀ CONDIZIONALE}}\\
    \parbox{\linewidth}{Siano $A$ e $B$ due eventi in uno spazio di probabilità ($\Omega$, $\mathcal{A}$, $p$), con $p(B)>0$. Si chiama, allora, \textbf{probabilità condizionale} di $A$ dato $B$ (cioé sapendo che si è verificato $B$) la quantità:
    \[\boxed{p(A \vert B) := \frac{p(A \cap B)}{p(B)}}\]
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Proposizione}: Si osservi che la funzione $p(\cdot \vert B)$, cioé
\[A \longrightarrow p(A \vert B) \hspace{1em} \forall A \in \mathcal{A}\]
è una probabilità su $\mathcal{A}$.

\vspace{1em}
\noindent
\textbf{Dimostrazione}: Per dimostrare che
\[A \longrightarrow p(A \vert B) \hspace{1em} \forall A \in \mathcal{A}\]
è una probabilità su $\mathcal{A}$ si deve dimostrare che
\begin{enumerate}
  \item Se si considera l'insieme vuoto $\varnothing$, allora $p(\varnothing \vert B) = 0$, che è immediato da osservare in quanto:
  \[p(\varnothing \vert B) = \frac{p(\varnothing \cap B)}{p(B)} = \frac{p(\varnothing)}{p(B)} = 0\]

  \item Se si considera l'insieme stesso $\Omega$, allora $p(\Omega \vert B) = 1$, che è immediato da osservare, sapendo che $B \subset \Omega$ in quanto:
  \[p(\Omega \vert B) = \frac{p(\Omega \cap B)}{p(B)} = \frac{p(B)}{p(B)} = 1\]

  \item Se si considerano due eventi disgiunti $A$ e $C$, allora $p((A \cup C) \vert B) = p(A \vert B) + p(C \vert B)$, che è immediato da osservare sfruttando la proprietà distributiva dell'intersezione sull'unione, in quanto
  \[p((A \cup C) \vert B) = \frac{p((A \cup C) \cap B)}{p(B)} = \frac{p((A \cap B) \cup (C \cap B))}{p(B)}\]
  Ma siccome $A$ e $C$ sono disgiunti, ovviamente anche $A \cap B$ e $C \cap B$ saranno disgiunti, per cui sfruttando la proprietà additiva della probabilità di eventi disgiunti si ottiene che
  \[\frac{p((A \cap B) \cup (C \cap B))}{p(B)} = \frac{p(A \cap B)}{p(B)} + \frac{p(C \cap B)}{p(B)} = p(A \vert B) + p(C \vert B)\]
\end{enumerate}

\vspace{1em}
\noindent
\textbf{Esercizio}: Vengono estratte $5$ palline da un'urna che ne contiene $90$ (numerate da $1$ a $90$). Si determini, allora, la probabilità che escano $1$ e $7$, anche sapendo che dei $5$ numeri estratti $3$ sono dispari.\\
Si assuma, per impotesi, che non ci sia reimmissione; lo spazio degli eventi elementari è costituito dalle estrazioni di cinque numeri tra $1$ e $90$, quindi
\[\Omega := \{\text{combinazioni i classe } 5 \text{ in } \{1,...,90\}\} = \{\omega \in \{1,...,90\} : \vert \omega \vert = 5\}\]
Sapendo, quindi, che
\[\vert \Omega \vert = \binom{90}{5}\]
su $\Omega$ si introduce la probabilità uniforme precedentemente considerata. Gli eventi a cui si è interessati sono
\[A:=\text{\quotes{\text{i numeri estratti contengono }1\text{ e }7}} = \{\omega \in \Omega : \{1,7\} \subset \omega\}\]
\[B:=\text{\quotes{i numeri estratti sono dispari}} = \{\omega \in \Omega : \vert \omega \cap \mathbb{N}_D \vert = 3\}\]
dove con $\mathbb{N}_D$ si indicano i numeri naturali dispari.\\
Naturalmente, le possibili configurazioni si ottengono aggiungendo a $\{1,7\}$ ogni possibile combinazione di classe $3$ sui restanti $\{1,...,90\} - \{1,7\}$ numeri. Quindi
\[\vert A \vert = \binom{88}{3}\]
da cui
\[p(A) = \frac{\vert A \vert}{\vert \Omega \vert} = \frac{\displaystyle{\binom{88}{3}}}{\displaystyle{\binom{90}{5}}} = \frac{88!}{3!} \cdot \frac{5!}{90!} = \frac{2}{801} \cong 0.0025\]
Per conoscere, ora, il numero di elementi che si trovano in $B$ e $A \cap B$ si procede nel modo seguente: gli elementi di $A \cap B$ sono cinquine che contengono $1$ e $7$, più un altro numero dispari diverso da $1$ e $7$ (che sono altri $43$ tra $1$ e $90$), e due numeri pari (ce ne sono $45$ tra $1$ e $90$, quindi $\binom{45}{2}$ combinazioni).\\
Per il principio fondamentale si ha che
\[\vert A \cap B \vert = \binom{43}{1} \cdot \binom{45}{2}\]
Similmente, dato che $B$ è costituito da due numeri pari e tre numeri dispari, si ha
\[\vert B \vert = \binom{45}{2} \cdot \binom{45}{3}\]
Si ha, quindi
\[p(A \vert B) = \frac{p(A \cap B)}{p(B)} = \frac{\vert A \cap B \vert}{\vert \Omega \vert} \cdot \frac{\vert \Omega \vert}{\vert B \vert} = \frac{\vert A \cap B \vert}{\vert B \vert} = \frac{3}{\binom{45}{3}} = \frac{43 \cdot 42! \cdot 3!}{45!} = \frac{6}{45 \cdot 44} = \frac{1}{330} \cong 0.003\]
In pratica, con maggiori informazioni, la probabilità aumenta, almeno in questo caso. Tuttavia, può capitare che l'\textbf{informazione aggiuntiva} \quotes{si è verificato $B$} sia \textbf{ininfluente}.

\vspace{2em}
\noindent
\textbf{Esempio}: Lanciando due volte una moneta, si ottiene il seguente spazio degli eventi elementari:
\[\Omega := \{(T,T),(T,C),(C,T),(C,C)\}\]
cioé le disposizioni di classe $2$ sull'insieme $\{T,C\}$. Si consierino gli eventi
\[A:=\text{\quotes{esce testa al secondo lancio}}=\{(T,T),(C,T)\}\]
\[B:=\text{\quotes{esce testa al primo lancio}}=\{(T,T),(T,C)\}\]
Si ha che $\vert \Omega \vert = 4$, $\vert A \vert = \vert B \vert = 2$, $\vert A \cap B \vert = 1$, in quanto $A \cap B = \{(T,T)\}$. Dunque, usando la probabilità uniforme
\[p(A) = \frac{1}{2} \hspace{1em} \text{e} \hspace{1em} p(A \vert B) = \frac{p(A \cap B)}{p(B)} = \frac{1}{4} \cdot 2 = \frac{1}{2}\]

\vspace{1em}
\subsection{Eventi indipendenti}
Quanto esposto finora porta alla seguente definizione:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{EVENTI INDIPENDENTI}}\\
    \parbox{\linewidth}{Due eventi $A$ e $B$ in uno spazio di probabilità si dicono \textbf{indipendenti} se
    \[\boxed{p(A \cap B) = p(A) \cdot p(B)}\]
    In particolare, se $p(B) > 0$, allora $A$ e $B$ sono indipendenti quando
    \[p(A) = p(A \vert B) = \frac{p(A \cap B)}{p(B)}\]
    cioé la probabilità di $A$ non cambia conoscendo $B$.
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Osservazione}: Si preferisce, tuttavia, la prima definizione in luogo della seconda perché copre anche il caso $p(B)=0$. Inoltre mostra come tale proprietà sia simmetrico rispetto ad $A$ e a $B$: $A$ è indipendente da $B$ \textbf{se e solo se} $B$ è indipendente da $A$.

\newpage
\noindent
\subsection{Regola della catena}
La probabilità condizionale fornisce anche la seguente \textbf{formula per l'intersezione di eventi}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{REGOLA DELLA CATENA}}\\
    \parbox{\linewidth}{Dati $n$ eventi $A_1,...,A_n$ in uno spazio di probabilità $(\Omega,\mathcal{A},p)$ tali che
    \[p\left(\bigcap_{k=1}^{n-1} A_k\right) > 0\]
    si ha
    \[p\left(\bigcap_{k=1}^{n} A_k\right) = p(A_1) \cdot p(A_2 \vert A_1) \cdot p(A_3 \vert A_2 \cap A_1) \cdot ... \cdot p\left(A_n \left \vert \bigcap_{k=1}^{n-1} A_k \right. \right)\]
    Per cui si ottiene che:
    \[\boxed{p\left(\bigcap_{k=1}^{n} A_k\right) = p(A_1) \cdot \prod_{j=2}^n p\left(A_j \left \vert \bigcap_{k=1}^{j-1} A_k \right.\right)}\]
    \vspace{-1mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Dimostrazione}: Si osservi, dapprima, che
\[\bigcap_{k=1}^j A_k \supset \bigcap_{k=1}^{n-1} A_k\]
per ogni $j \leq n-1$, quindi se
\[p \left(\bigcap_{k=1}^{n-1} A_k\right) > 0\]
allora deve essere necessariamente che
\[p \left(\bigcap_{k=1}^{j-1} A_k\right) > 0\]
Ciò permette di affermare che
\[p \left( A_j \left \vert \right. \bigcap_{k=1}^{j-1} A_k\right)\]
ha senso e il lato destro dell'eguaglianza appena scritta è ben posto. Per la dimostrazione, è conveniente procedere per induzione. Quando $n=2$, l'uguaglianza
\[p(A_1 \cap A_2) = p(A_1) \cdot p(A_2 \vert A_1)\]
è fornita dalla definizione di probabilità condizionale (quindi è certamente vera). Compiendo il passo induttivo, si supponga, allora, che tale proprietà sia vera per $n-1$, cioé che
\[p \left(\bigcap_{k=1}^{n-1} A_k\right) = p(A_1) \cdot \prod_{j=2}^{n-1} p \left(A_j \left \vert \bigcap_{k=1}^{j-1} A_k \right.\right)\]
Si ha, quindi, ancora tramite la definizione di probabilità condizionale che:
\[p \left(\bigcap_{k=1}^{n} A_k\right) = p \left( \left( \bigcap_{k=1}^{n-1} A_k\right) \cap A_n\right) = p \left(\bigcap_{k=1}^{n-1} A_k\right) \cdot p \left(A_n \left \vert \bigcap_{k=1}^{n-1} A_k \right. \right) = p(A_1) \cdot \prod_{j=2}^n p \left(A_j \left \vert  \bigcap_{k=1}^{j-1} A_k \right. \right)\]
applicando semplicemente l'ipotesi induttiva.

\vspace{1em}
\subsection{Probabilità composite}
Si consideri l'esempio seguente che mostra come usare la probabilità condizionale per costruire un modello probabilistico, cioé definire una probabilità $p$ su una $\sigma$-algebra $\mathcal{A}$ di eventi su uno spazio campione $\Omega$.\\
Lo spazio $\Omega$ sarà finito, quindi per costruire $p$ sarà sufficiente, come sempre, definire $p(\{\omega\}), \forall \omega \in \Omega$, e porre poi
\[p(A) = \sum_{\omega \in A} p(\{\omega\}), \hspace{1em} \forall A \in \mathcal{A}\]
Si dovrà, poi, costruire $p$ a partire da alcune probabilità condizionali $p(\cdot \vert B)$. Ciò è spesso utile in casi reali, dove si hanno informazioni del tipo \quotes{la probabilità che accada è questa \textbf{se}...}.

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri di disporre di due urne, che si etichettano con $\alpha$ e $\beta$:
\[\alpha \text{ contiene } \left\{
  \rowcolors{1}{white}{white}
  \begin{array}{l}
    3 \text{ palline nere}\\
    1 \text{ pallina bianca}\\
  \end{array}
\right.\]
\[\beta \text{ contiene } \left\{
  \rowcolors{1}{white}{white}
  \begin{array}{l}
    1 \text{ pallina nera}\\
    1 \text{ pallina bianca}\\
  \end{array}
\right.\]
Sapendo di scegliere una delle due urne con la stessa probabilità, e poi estrarre a caso dall'urna scelta una pallina, si determini la probabilità di estrarre una pallina nera.\\
Si consideri come spazio $\Omega$ l'insieme dei possibili output:
\[\Omega = \{\alpha_n, \alpha_b, \beta_n, \beta_b\}\]
dove
\[\left\{
  \rowcolors{1}{white}{white}
  \begin{array}{l}
    \alpha_n : \text{ si è scelta urna } \alpha \text{ ed estratto nero}\\
    \alpha_b : \text{ si è scelta urna } \alpha \text{ ed estratto bianco}\\
    \beta_n : \text{ si è scelta urna } \beta \text{ ed estratto nero}\\
    \beta_b : \text{ si è scelta urna } \beta \text{ ed estratto bianco}\\
  \end{array}
\right.\]
L'evento $A = \{\alpha_n,\alpha_b\}$ corrisponde a \quotes{l'unica scelta è la $\alpha$}, l'evento $N=\{\alpha_n,\beta_n\}$ corrisponde a \quotes{la pallina estratta è nera}.\\
Com'è noto, si assume che la scelta dell'urna abbia uguale probabilità di essere $\alpha$ oppure $\beta$, quindi
\[p(A) = \frac{1}{2}\]
Inoltre, supponendo di aver scelto l'urna $\alpha$, la probabilità di estrarre una pallina nera è
\[p(N \vert A) = \frac{3}{4}\]
Similmente, tenuto conto che all'evento $A^c = \{\beta_n,\beta_b\}$ corrisponde \quotes{l'urna scelta è la $\beta$}, si ha
\[p(N \vert A^c) = \frac{1}{2}\]
Si ottiene, quindi, sfruttando la definizione di probabilità condizionale:
\[p(\{\alpha_n\}) = p(A \cap N) = p(A) \cdot p(N \vert A) = \frac{3}{8}\]
e similmente
\[p(\{\beta_n\}) = p(A^c \cap N) = p(A^c) \cdot p(N \vert A^c) = \frac{1}{4}\]
A questo punto è possibile già rispondere alla domanda
\[p(\{\alpha_n,\beta_n\}) = p(\{\alpha_n\}) + p(\{\beta_n\}) = \frac{3}{8} + \frac{1}{4} = \frac{5}{8}\]
Ricapitolando, sapendo che
\begin{enumerate}
  \item Nell'urna $\alpha$ vi sono $3$ palline nere ed $1$ bianca, assunta la probabilità uniforme nell'estrazione, si è dedotto che \textbf{sotto} la condizione della scelta dell'urna $\alpha$ la probabilità è $\frac{3}{4}$ per il nero;
  \item Nell'urna $\beta$ vi sono $1$ pallina nera ed $1$ bianca, assunta la probabilità uniforme nell'estrazione, si è dedotto che \textbf{sotto} la condizione della scelta dell'urna $\beta$ la probabilità è $\frac{1}{2}$ per il nero;
  \item Sapendo che la scelta dell'urna $\alpha$ ha una probabilità $\frac{1}{2}$ così come quella dell'urna $\beta$, dalle probabilità condizionali di cui sopra si è ricavata la probabilità \quotes{svincolata} dalla scelta dell'urna.
\end{enumerate}

\noindent
Volendo terminare di costruire lo spazio di probabilità, tenuto conto che all'evento $N^c = \{\alpha_b,\beta_b\}$ corrisponde \quotes{la pallina estratta è bianca}, si ha che:
\[p(N^c \vert A) = \frac{1}{4} \hspace{1em} \text{e} \hspace{1em} p(N^c \vert A^c) = \frac{1}{2}\]
da cui si evince che
\[p(\{\alpha_b\}) = p(A \cap N^c) = p(A) \cdot p(N^c \vert A) = \frac{1}{2} \cdot \frac{1}{4} = \frac{1}{8}\]
e similmente
\[p(\{\beta_b\}) = p(A^c \cap N^c) = p(A^c) \cdot p(N^c \vert A^c) = \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{4}\]
In questo modo è stata determinata la probabilità di ogni evento elementare in $\Omega$, per cui ora è possibile calcolare la probabilità di qualsiasi evento complesso $A \subset \Omega$ semplicemente sfruttando la formula
\[p(A) = \sum_{\omega \in A} p(\{\omega\}), \hspace{1em} \forall A \in \mathcal{A}\]
che afferma che la probabilità di un evento complesso è pari alla somma delle probabilità dei singoli eventi elementari che lo costituiscono.

\vspace{1em}
\noindent
\subsection{Formula di disintegrazione e delle probabilità totali}
Viene di seguito esposto un metodo molto pratico per ottenere la probabilità di un evento dalle probabilità condizionali senza dover necessariamente costruire l'intero modello probabilistico:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{FORMULA DI DISINTEGRAZIONE E DELLE PROBABILITÀ TOTALI}}\\
    \parbox{\linewidth}{Sia $(\Omega,\mathcal{A},p)$ uno spazio di probabilità e sia $\{B_k\}_{k \in K} \subset \mathcal{A}$ una \textbf{partizione finita o numerabile} (cioé $K$ è costiuito da un numero finito di indici, tipo $K=\{1,...,n\}$, oppure $K=\mathbb{N}$). Allora
    \[p(A) = \sum_{k \in K} p(A \cap B_k) \hspace{1em} \forall A \in \mathcal{A} \hspace{1em} [\textbf{formula di disintegrazione}]\]
    Inoltre, se $p(B_k) > 0, \forall k \in K$, allora ha senso parlare di probabilità condizionali, per cui si ottiene
    \[p(A) = \sum_{k \in K} p(A \vert B_k) \cdot p(B_k) \hspace{1em} \forall A \in \mathcal{A} \hspace{1em} [\textbf{formula delle probabilità totali}]\]
    \vspace{1mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che essere una partizione significa che gli elementi di $\{B_k\}_{k \in K}$ sono a due a due disgiunti, cioé
\[B_k \cap B_i \neq \varnothing \hspace{1em} \text{se} \hspace{1em} i \neq k, \forall i,k \in K\]
che $\{B_k\}_{k \in K}$ è un ricoprimento di $\Omega$, cioé
\[\bigcup_{k \in K} B_k = \Omega\]

\vspace{1em}
\noindent
\textbf{Dimostrazione}:
per avere un'idea geometrica della formula di disintegrazione, si immagini $p$ come la misura (rinormalizzata) dell'area dell'evento $A$:

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[scale=0.8]
      \draw plot[smooth, tension=.7] coordinates {(-3.5,0.5) (-3,2.5) (-1,3.5) (1.5,3) (4,3.5) (5,2.5) (5,0.5) (2.5,-2) (0,-0.5) (-3,-2) (-3.5,0.5)};
      \draw plot[smooth, tension=.7] coordinates {(-1.5,1) (-1,2.5) (1.5,1.5) (3,0.5) (2.5,-0.5) (0,0) (-1,0.5) (-1.5,1)};
      \draw plot[smooth, tension=.7] coordinates {(4,3.5) (2.5,2.5) (-3.5,0.5)};
      \draw plot[smooth, tension=.7] coordinates {(5,0.5) (2.8,0) (1.8,0.5) (0.5,0.8) (0,1.6)};
      \draw plot[smooth, tension=.7] coordinates {(0,-0.5) (0.2,0.4) (0.5,0.8)};
      \draw (-2.5,-1) node[]{$B_1$};
      \draw (-2.5,2) node[]{$B_2$};
      \draw (4,2) node[]{$B_3$};
      \draw (2.5,-1) node[]{$B_4$};
      \draw (-0.5,1) node[]{$A$};
      \draw (-4.5,3) node[]{$\Omega$};
  \end{tikzpicture}
\end{figure}

\noindent
Per sapere quanto vale l'area di $A$ è sufficiente sapere quanto valgono le aree di $A \cap B_1$, $A \cap B_2$, $A \cap B_3$ e $A \cap B_4$ e sommarle tutte insieme. Formalmente, essendo $\{B_k\}_{k \in K}$ una partizione di $\Omega$ e sfruttando la proprietà distributiva dell'intersezione sull'unione, si ottiene che
\[A = A \cap \Omega = A \cap \left(\bigcup_{k\in K} B_k\right) = \bigcup_{k\in K} (A \cap B_k)\]
Ma essendo gli eventi $\{B_k\}_{k \in K}$ disgiunti, sono digiunti anche gli eventi $\{A \cap B_k\}_{k \in K}$, quindi per la $\sigma$-additività (essendo $K$ finito o numerabile)
\[p(A) = p \left(\bigcup_{k \in K} (A \cap B_k) \right) = \sum_{k \in K} p(A \cap B_k)\]
Inoltre, se $p(B_k)>0$, allora è possibile scrivere
\[p(A \cap B_k) = p(B_k) \cdot p(A \vert B_k)\]
ottenendo la formula delle probabilità totali.

\vspace{2em}
\noindent
\textbf{Esempio}: Un immediato risultato che deriva dal precedente è quello che prevede una partizione di $\Omega$ in due parti ($B$ e $B^c$)

\begin{corollary} Per ogni coppia di eventi $A$ e $B$, con $p(B) \in (0,1)$ (per cui allora $p(B^c)=1-p(B)>0$), si ha che
\[p(A)=p(A \vert B) \cdot p(B) + p(A \vert B^c) \cdot p(B^c) = p(A \vert B) \cdot p(B) + p(A \vert B^c) \cdot \left[1 - p(B)\right]\]
Tenuto conto che $\{B,B^c\}$ è una partizione di $\Omega$ e che $p(B^c) = 1-p(B)>0$.
\end{corollary}

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri l'estrazione di palline da un'urna. Se si pone $N$, come evento \quotes{la pallina estratta è nera} e che $A$ è l'evento \quotes{l'urna scelta è la $\alpha$} si era osservato che
\[p(A)=\frac{1}{2} \hspace{1em} \text{e} \hspace{1em} p(N \vert A) = \frac{3}{4} \hspace{1em} \text{e} \hspace{1em} p(N \vert A^c)=\frac{1}{2}\]
Quindi, per il corollario appena esposto
\[p(N) = p(N \vert A) \cdot p(A) + p(N \vert A^c) \cdot \left[1-p(A)\right] = \frac{3}{4} \cdot \frac{1}{2} + \frac{1}{2} \cdot \left[1-\frac{1}{2}\right]=\frac{3}{8}+\frac{1}{4}=\frac{5}{8}\]
come già ottenuto in precedenza.

\newpage
\begin{center}
  28 marzo 2022
\end{center}
\subsection{Formula di Bayes}
Si espone di seguito un importante risultato, ossia la \textbf{formula di Bayes}

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{FORMULA DI BAYES}}\\
    \parbox{\linewidth}{Sia ($\Omega$,$\mathcal{A}$,$p$) uno spazio di probabilità e siano $A$ e $B$ due eventi per cui $p(A)>0$, $p(B)>0$. Allora
    \[\boxed{p(B \vert A) = \frac{p(A \vert B) \cdot p(B)}{p(A)}} \hspace{1em} [\textbf{formula di Bayes}]\]
    Inoltre, se $p(B)\in(0,1)$ (e quindi $p(B^c)>0$) la formula di Bayes si può scrivere come
    \[p(B \vert A) = \frac{p(A \vert B) \cdot p(B)}{p(A \vert B) \cdot p(B) + p(A \vert B^c) \cdot p(B^c)} \hspace{1em} [\textbf{II versione}]\]
    Inoltre, se $\{B_k\}_{k \in K} \subset \mathcal{A}$ è una partizione di eventi (finita o numerabile) di $\Omega$ con $p(B_k)>0, \forall k \in K$, allora
    \[p(B_i \vert A) = \frac{p(A \vert B_i) \cdot p(B_i)}{p(A)} = \frac{p(A \vert B_i) \cdot p(B_i)}{\displaystyle{\sum_{k \in K} p(A \vert B_k) \cdot p(B_k)}} \hspace{1em} \forall i \in K \hspace{1em} [\textbf{III versione}]\]
    \vspace{-1mm}}\\
    \hline
\end{tabularx}

\vspace{2em}
\noindent
\textbf{Dimostrazione}: Per la dimostrazione della fortuna di Bayes, basta osservare che per definizione di probabilità condizionale si ha che
\[p(B \vert A) = \frac{p(A \cap B)}{p(A)} \hspace{1em} \text{e} \hspace{1em} p(A \vert B) = \frac{p(A \cap B)}{p(B)}\]
per cui è facile capire come si ottenga l'idetità simmetrica seguente:
\[p(B \vert A) \cdot p(A) = p(A \cap B) = p(A \vert B) \cdot p(B)\]
che può essere interpretata come: \quotes{la probabilità che accada sia $A$ che $B$ è il prodotto della probabilità che accada $A$ per la probabilità che accada $B$ sapendo che è accaduto $A$ e viceversa}.\\
Da qui è immediato evincere che:
\[p(B \vert A) = \frac{p(A \vert B) \cdot p(B)}{p(A)}\]
per le altre due formule, basta applicare al denominatore la formula delle probabilità totali e il suo corollario.

\vspace{1em}
\noindent
\textbf{Osservazione}: La III versione della formula di Bayes è detta \textbf{formula delle probabilità delle cause}: infatti, interpretando gli eventi della partizione $\{B_k\}_{k \in K}$ come \quotes{cause} al verificarsi di $A$ (e la $p(A \vert B_k)$ è appunto la probabilità che si verifichi $A$ se accade $B_k$), la formula permette di calcolare la probabilità che quando $A$ si è verificato, la causa sia stata $B_i$.

\vspace{1em}
\noindent
\textbf{Esempio $\boldsymbol{1}$}: Tornando ancora una volta alle due urne $\alpha$ e $\beta$, se la pallina estratta è nera, si determini la probabilità che l'urna scelta sia stata la $\alpha$. È noto che
\[p(A) = \frac{1}{2} \hspace{2em} p(N \vert A) = \frac{3}{4} \hspace{2em} p(N \vert A^c) = \frac{1}{2}\]
Dalla formula di Bayes, al fine di determinare $p(A \vert N)$, si ha che
\[p(A \vert N) = \frac{P(N \vert A) \cdot p(A)}{p(N \vert A) \cdot p(A) + p(N \vert A^c) \cdot [1-p(A)]} = \frac{\dfrac{3}{4} \cdot \dfrac{1}{2}}{\dfrac{5}{8}}=\frac{3}{5}\]
in cui è facile osservare che sapendo a posteriori il colore della pallina, la probabilità sulla scelta dell'urna $\alpha$ (evento $A$) sia più alta di quella non condizionata $p(A)=\frac{1}{2}$.

\vspace{1em}
\noindent
\textbf{Esempio $\boldsymbol{2}$}: Si consideri un sondaggio degli studenti del secondo anno di università, i quali hanno fornito una spiegazione di come hanno superato l'esame di Analisi I:
\begin{itemize}
  \item il $50\%$ del campione ha risposto \quotes{tanto studio};
  \item il $40\%$ del campione ha risposto \quotes{fortuna};
  \item il $10\%$ del campione ha risposto \quotes{copiando}.
\end{itemize}
È stato poi chiesto il voto con cui hanno superato l'esame:
\begin{itemize}
  \item nel primo gruppo $\frac{2}{3}$ ha preso un voto $\geq 27$;
  \item nel secondo fruppo $\frac{1}{2}$ ha preso un voto $\geq 27$;
  \item nel terzo gruppo $\frac{1}{4}$ ha preso un voto $\geq 27$.
\end{itemize}
Si valuti in che percentiale chi ha preso $\geq 27$ appartenga al primo e al terzo gruppo. Si consideri come spazio campione
\[\Omega = \{(1,n),(1,b),(2,n),(2,b),(3,n),(3,b)\}\]
dove
\begin{flalign*}
  n & = \text{ nero sta per } \geq 27\\
  b & = \text{ bianco sta per } < 27
\end{flalign*}
quindi per $k=1,2,3$ si ha che
\begin{flalign*}
  (k,n) & = \text{ sono coloro che nel } k\text{-esimo gruppo hanno un voto} \geq 27\\
  (k,b) & = \text{ sono coloro che nel } k\text{-esimo gruppo hanno un voto} < 27\\
\end{flalign*}
Si considerino, allora, gli eventi
\begin{flalign*}
  N & = \text{ \quotes{il voto è }} \geq 27 = \{(1,n),(2,n),(3,n)\}\\
  B_k & = \text{ \quotes{appartenenza al gruppo }} k =  \geq 27 = \{(k,n),(k,b)\}\\
\end{flalign*}
Si osservi che $\{B_k\}_{k \in K}$ è una partizione di $\Omega$, in quanto
\[B_1=\{(1,n),(1,b)\} \hspace{2em} B_2=\{(2,n),(2,b)\} \hspace{2em} B_3=\{(3,n),(3,b)\}\]
sono a due a due disgiunti e la loro unione produce $\Omega$. Calcolando le probabilità che vengono richieste per la risoluzione del problema si ottiene:
\[p(B_1)=\frac{1}{2} \hspace{2em} p(B_2)=\frac{2}{5} \hspace{2em} p(B_3)=\frac{1}{10}\]
Inoltre si ha che
\[p(N \vert B_1)=\frac{2}{3} \hspace{2em} p(N \vert B_2)=\frac{1}{2} \hspace{2em} p(N \vert B_3)=\frac{1}{4}\]
Pertanto, per la formula delle probabilità totali
\[p(N) = \sum_{k=1}^3 p(N \vert B_k) \cdot p(B_k) = \frac{2}{5} \cdot \frac{1}{2} + \frac{1}{2} \cdot \frac{2}{5} + \frac{1}{4} \cdot \frac{1}{10} = \frac{40+24+3}{120} = \frac{67}{120}\]
ossia la probabilità totale di prendere un voto $\geq 27$. Per la formula di Bayes si ottiene
\[p(B_1 \vert N) = \frac{p(N \vert B_1) \cdot p(B_1)}{p(N)} = \frac{\dfrac{2}{3} \cdot \dfrac{1}{2}}{\dfrac{67}{120}} = \frac{40}{67} \cong 60 \%\]
\[p(B_3 \vert N) = \frac{p(N \vert B_3) \cdot p(B_3)}{p(N)} = \frac{\dfrac{1}{4} \cdot \dfrac{1}{10}}{\dfrac{67}{120}} = \frac{3}{67} \cong 5 \%\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che si sarebbe potuto usare direttamente la formula di probabilità delle cause; si è così trovato che se uno studente ha preso $\geq 27$, al $60 \%$ proviene dal primo gruppo e al $5 \%$ dal terzo gruppo.

\vspace{1em}
\noindent
\textbf{Esempio}: Per determinare la presenza del coronavirus è stato elaborato un test clinico con la seguente efficacia:
\begin{itemize}
  \item se il virus è presente, il test risulta positivo al $99\%$;
  \item se il virus è assente, il test risulta positivo al $2\%$ (i cosiddetti falsi positivi);
\end{itemize}
Su un campione di $1000$ persone $2$ risultano avere il virus. Si supponga che un individuo scelto a caso risulti positivo al test, si determini quale probabilità risulta realmente malato.\\
Lo spazio campione è
\[\Omega=\{(+,\text{m}),(+,\text{s}),(-,\text{m}),(-,\text{s})\}\]
dove
\begin{itemize}
  \item $+$ significa test positivo
  \item $-$ significa test negativo
  \item $m$ significa esaminato malato (cioè virus presente)
  \item $s$ significa esaminato sano (cioè virus asente)
\end{itemize}
Si considerino, allora, gli eventi:
\begin{flalign*}
  A & = \text{ \quotes{il test è positivo}} = \{(+,m),(+,s)\}\\
  M & = \text{ \quotes{l'esaminato è malato}} = \{(+,m),(-,m)\}\\
\end{flalign*}
Sapendo che $p(A \vert M^c)$ è la percentuale di falsi positivi, cioé persone sane che risultano positive al test, si determini $p(M \vert A)$. È noto che
\[p(M) = \frac{1}{500} \hspace{2em} p(A \vert M) = \frac{99}{100} \hspace{2em} p(A | M^c) = \frac{2}{100}\]
Quindi, tramite la formula di Bayes si ottiene
\[p(M \vert A) = \frac{p(A \vert M) \cdot p(M)}{p(A)} = \frac{p(A \vert M) \cdot p(M)}{p(A \vert M) \cdot p(M) + p(A \vert M^c) \cdot p(M^c)} = \frac{\dfrac{99}{100} \cdot \dfrac{1}{500}}{\dfrac{99}{100} \cdot \dfrac{1}{500} + \dfrac{2}{100} \cdot \dfrac{499}{500}} = \frac{99}{1097}\]
Ciò siginfica anche che $p(M^c \vert A) \cong 0.91$ (calcolando la probabilità complementare), cioè tra le persone testate che risultano positive, $91\%$ in verità sono sane. Ciò può sembrare strano, ma se si considera un campione di $100 000$ persone, presumibilmente $200$ saranne malate (ovvero $2$ su $1000$), e $99 800$ sono sane. Se si effettua il test, si avranno
\begin{itemize}
  \item per le persone malate, un risultato positivo e corretto sul $99\%$ di esse, cioè
  \[200 \cdot \frac{99}{100}=198\]
  \item per le persone sane, un risultato positivo ed errato sul $2\%$ di esse, cioè
  \[99800 \cdot \frac{2}{100} = 1996\]
\end{itemize}
Per cui si è ottenuto che $1996+198=2194$ persone su cui il test risulta positivo, ma solo $198$ sono realmente malate ($\cong 9\%$, come calcolato in precedenza).\\
Potrebbe sembrare anomalo come risultato, ma dopo tutto i falsi positivi sono pochi: $p(A \vert M^c) = 0.02$. Il punto è che, considerando la formula di Bayes e portando un fattore del numeratore come denominatore del denominatore si ottiene
\[p(M \vert A) = \frac{p(A \vert M) \cdot p(M)}{p(A \vert M) \cdot p(M) + p(A \vert M^c) \cdot p(M^c)} = \frac{p(A \vert M)}{p(A \vert M) + \dfrac{p(A \vert M^c)}{p(M)} \cdot p(M^c)}\]
Per cui se i sani sono l'ampia maggioranza, cioé $p(M^c) \cong 1$ (nel caso descritto $499$ su $500$), affinché $p(M \vert A) \cong 1$, cioé i testati positivi siano quasi tutti malati, ciò che conta è che sia piccolo il rapporto falsi positivi e malati, ossia
\[\frac{p(A \vert M^c)}{p(M)}\]
cioè la percentuale di falsi positivi deve essere molto più bassa della percentuale dei malati
\[p(A \vert M^c) << p(M)\]

\vspace{1em}
\subsection{Indipendenza di eventi generalizzata}
Per comprendere la generalizzazione del concetto di eventi indipendenti a più di due eventi, si consideri l'esempio seguente:

\vspace{1em}
\noindent
\textbf{Esempio}: Tre scimmie giocano a dadi, ognuna lanciando un dado a $6$ facce. Si provi che gli eventi
\begin{flalign*}
  A & = \text{ \quotes{la prima e la seconda scimia ottenfono lo stesso risultato}}\\
  B & = \text{ \quotes{la seconda e la terza scimmia ottengono lo stesso risultato}}\\
\end{flalign*}
sono indipendenti. La cosa più conveniente è quella di prendere come spazio campione $\Omega=\{1,...,6\}^3$, ossia le terne di numeri da $1$ a $6$, associando alla coordinata $k$-esima il risultato del lancio del $k$-esimo dado. Così facendo è possibile scrivere:
\[A=\{(x,y,z) \in \Omega : x=y\} \hspace{2em} B=\{(x,y,z) \in \Omega : y=z\} \hspace{2em} A \cap B=\{(x,y,z) \in \Omega : x=y=z\}\]
Poiché
\[\vert \Omega \vert=6^3 \hspace{2em} \vert A \vert = \vert B \vert = 6^2 \hspace{2em} \vert A \cap B \vert = 6\]
dotando $\Omega$ di probabilità uniforme si ha
\[p(A) = p(B) = \frac{6^2}{6^3}=\frac{1}{6} \hspace{1em} \text{e} \hspace{1em} p(A \cap B)=\frac{6}{6^3}=\frac{1}{36}\]
dunque appare evidente come $p(A \cap B)=p(A) \cdot p(B)$, per cui gli eventi sono indipendenti, com'era intuitivamente ovvio.\\
Se ora si definisce $C=\{(x,y,z) \in \Omega:x=z\}$, cioé \quotes{la prima e la terza scimmia ottengono lo stesso risultato}, si vede allo stesso modo che:
\[p(A \cap C)=p(A) \cdot p(c) \hspace{1em} \text{e} \hspace{1em} p(B \cap C)=p(B) \cdot p(C)\]
cioé $A$ e $C$ sono indipendenti, come anche gli eventi $B$ e $C$. Quindi gli eventi $A$, $B$, $C$ sono a due a due indipendenti. Usando la probabilità condizionale si può scrivere che
\begin{flalign*}
  p(A) & = p(A \vert B) = p(A \vert C)\\
  p(B) & = p(B \vert A) = p(B \vert C)\\
  p(C) & = p(C \vert A) = p(C \vert B)
\end{flalign*}
Il fatto che $A$ sia indipendente sia da $B$ che da $C$ è piuttosto intuitivo. È altrettanto intuitivo, però, che $A$ non è indipendente dal fatto che $B$ e $C$ accadano entrambi, ossia dall'evento $B \cap C$.\\
In altre parole si ha che $p(A) \neq p(A \vert B \cap C)$, infatti:
\[p(A \vert B \cap C) = \frac{p(A \cap B \cap C)}{p(B \cap C)} = 1 \hspace{1em} \text{mentre} \hspace{1em} p(A)=\frac{1}{6}\]
in quanto $A \cap B \cap C = B \cap C$ (e analogamente $=A \cap B=A \cap C$) (giacchè costituito dall'insieme di tutte le terne che hanno tutte e $3$ le coordinate $x$,$y$,$z$ uguali).\\
Se $A$ fosse stato indipendente da $B \cap C$ si sarebbe dovuto ottenere che
\[p(A) = p(A \vert B \cap C) = \frac{p(A \cap B \cap C)}{p(B \cap C)} = \frac{p(A \cap B \cap C)}{p(B) \cdot p(C)}\]
essendo $B$ e $C$ indipendenti, e quindi
\[p(A) \cdot p(B) \cdot p(C) = p(A \cap B \cap C)\]
che permette di ottenere la definizione seguente:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{INDIPENDENZA TRA PIÙ DI DUE EVENTI}}\\
    \parbox{\linewidth}{Tre eventi $A$,$B$,$C$ in uno spazio di probabilità si dicono \textbf{indipendenti} se sono \textbf{indipendenti a due a due} e se vale l'eguaglianza:
    \[\boxed{p(A) \cdot p(B) \cdot p(C) = p(A \cap B \cap C)}\]
    Più in generale, data una famiglia $\{A_k\}_{k \in K}$ di eventi, si dirà che gli eventi sono indipendenti se per ogni sottoinsieme finito $J \subset K$ con $\vert J \vert \geq 2$ si ha che
    \[p \left( \bigcap_{k \in J} A_k \right) = \prod_{k \in J} p(A_k)\]
    per cui si ha indipendenza solamente quando i $k$ eventi considerati sono indipendenti due a due, tre a tre, ..., $k$ a $k$. Nel caso di tre eventi $K=\{1,2,3\}$ si avrebbe
    \[J=\{(1,2),(1,3),(2,3),(1,2,3)\}\]
    \vspace{-1mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che \textbf{l'indipendenza non gode della proprietà transitiva}: se $A$ è indipendente da $B$ e $B$ è indipendente da $C$, non è detto che $A$ sia indipendente da $C$. Per esempio, sul quadrato unitario, considerando i tre eventi

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[scale=1.5]
    \draw [draw=black] (0,0) rectangle ++(2,2);
    \draw [fill = purple!30,draw = purple!50] (0,1) rectangle ++(2,1);
    \draw (1,1.5) node[]{$A$};
  \end{tikzpicture}
  \hspace{2em}
  \begin{tikzpicture}[scale=1.5]
    \draw [draw=black] (0,0) rectangle ++(2,2);
    \draw [fill = purple!30,draw = purple!50] (0,0) rectangle ++(1,2);
    \draw (0.5,1) node[]{$B$};
  \end{tikzpicture}
  \hspace{2em}
  \begin{tikzpicture}[scale=1.5]
    \draw [draw=black] (0,0) rectangle ++(2,2);
    \draw [fill = purple!30,draw = purple!50] (0,0) rectangle ++(2,1);
    \draw (1,0.5) node[]{$C$};
  \end{tikzpicture}
\end{figure}

\noindent
Si ha, naturalmente, che
\[p(A) = p(B) = p(C) = \frac{1}{2}\]
mentre
\[p(A \cap B)=p(B \cap C)=\frac{1}{4}\]
e
\[p(A \cap C)=0\]
quindi $p(A \cap B)=p(A) \cdot p(B)$ e $p(B \cap C) = p(B) \cdot p(C)$, mentre $p(A \cap C)=0$ che è naturalmente diversa da $p(A) \cdot p(C) = 0.25$.

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri il lancio di due dadi a $6$ facce. Impiegando $\Omega=\{1,...,6\}^2$ dotato di probabilità uniforme. Considerando gli eventi
\begin{flalign*}
  A & = \text{\quotes{il risultato del secondo dado è 1,2 oppure 5}} = \{(x,y) \in \Omega : y=1,2,5\}\\
  B & = \text{\quotes{il risultato del secondo dado è 4,5 oppure 6}} = \{(x,y) \in \Omega : y=4,5,6\}\\
  C & = \text{\quotes{la somma dei risultati dei due dadi vale 9}} = \{(x,y) \in \Omega : x+y=9\}\\
\end{flalign*}
Naturalmente si ha che $C=\{(3,6),(4,5),(5,4),(6,3)\}$, mentre
\begin{flalign*}
  A \cap B & = \{(x,y) \in \Omega : y=5\}\\
  A \cap C & = \{(4,5)\}\\
  B \cap C & = \{(3,6),(4,5),(5,4)\}\\
  A \cap B \cap C& = \{(4,5)\}\\
\end{flalign*}
Quindi, tenuto conto che $\vert \Omega \vert = 36$, si ottiene che
\[p(A)=p(B)=\frac{18}{36}=\frac{1}{2} \hspace{2em} p(C)=\frac{4}{36}=\frac{1}{9} \hspace{2em} p(A \cap B)=\frac{6}{36}=\frac{1}{6}\]
\[p(B \cap C)=\frac{3}{36}=\frac{1}{12} \hspace{2em} p(A \cap C)=p(A \cap B \cap C)=\frac{1}{36}\]
da cui
\[
\left\{
\rowcolors{1}{white}{white}
\begin{array}{l}
  p(A \cap B \cap C) = \dfrac{1}{36} = p(A) \cdot p(B) \cdot p(C)\\
  p(A \cap B) = \dfrac{1}{6} \neq \dfrac{1}{4} = p(A) \cdot p(B)\\
  p(A \cap B) = \dfrac{1}{36} \neq \dfrac{1}{18} = p(A) \cdot p(C)\\
  p(B \cap C) = \dfrac{1}{12} \neq \dfrac{1}{18} = p(B) \cdot p(C)\\
\end{array}
\right.
\]
per cui gli eventi non sono indipendenti.

\vspace{1em}
\noindent
\textbf{Osservazione $\boldsymbol{1}$}: Si osservi che il fatto che $p(A \cap B \cap C) = p(A) \cdot p(B) \cdot p(C)$ nulla dice sul fatto che gli eventi $A$,$B$,$C$ siano a due a due indipendenti.

\vspace{1em}
\noindent
\textbf{Osservazione $\boldsymbol{2}$}: Se $A$ e $B$ sono eventi indipendenti, allora anche $A^c$ e $B$ lo sono, in quanto
\[p(A^c \cap B) = p(B - (A \cap B)) = p(B) - p(A \cap B)\]
per la proprietà di monotonia esposta nella \textbf{Proposizione 1} (§ \ref{sec:proposizione_1}) (essendo, ovviamente, $A \cap B \subset B$). Da ciò si ha che, essendo $A$ e $B$ indipendenti $p(A \cap B) = p(A) \cdot p(B)$, per cui:
\[p(B) - p(A) \cdot p(B) = p(B) \cdot \left[1 - p(A)\right] = p(B) \cdot p(A^c)\]
Ovviamente, visto che $(A^c)^c=A$, vale anche il viceversa (per cui se $A^c$ e $B$ sono indipendenti, allora lo sono anche $(A^c)^c$ e $B$, quindi $A$ e $B$). Più estensivamente, si è dimostrato che le seguenti affermazioni sono equivalenti:
\begin{itemize}
  \item $A$ e $B$ sono indipendenti;
  \item $A$ e $B^c$ sono indipendenti;
  \item $A^c$ e $B$ sono indipendenti;
  \item $A^c$ e $B^c$ sono indipendenti.
\end{itemize}
Un concetto che può essere generalizzato a famiglie con più di due eventi:

\vspace{1em}
\noindent
\textbf{Proposizione}: Sia $\{A_k\}_{k \in K}$ una famiglia di eventi indipendenti. Sia $J \subset K$ un sottoinsieme di indici. Per cui si definisce
\[
  B_k := \left\{
    \rowcolors{1}{white}{white}
    \begin{array}{l}
      A_k \text{ se } k \in J\\
      A_k^c \text{ se } k \in K - J
    \end{array}
  \right.
\]
Allora $\{B_k\}_{k \in K}$ è una famiglia di eventi indipendenti.

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri la famiglia $\{A_1,A_2,A_3,A_4\}$, quindi $K=\{1,2,3,4\}$ e si consideri $J=\{2,3\}$. Allora $B_1=A_1^c$, $B_2=A_2$, $B_3=A_3$, $B_4=A_4^c$.

\newpage
\noindent
\begin{center}
  31 Marzo 2022
\end{center}
\subsection{Schema delle prove indipendenti}
Si espongono, di seguito, nuovi modelli per spazi di probabilità discreti, partendo da un esempio:

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri l'esperimento seguente: lanciando $n$ volte una moneta, per la quale è $q \in (0,1)$ la probabilità di ottenere testa (per cui il fatto che $q \neq 0.5$ significa che la moneta non è equilibrata, e ovviamente la probabilità di ottenere croce sarà $p=1-q$). Si assuma, durante l'esperimento, che ogni lancio non influenzi gli altri, cioè che i risultati dei \textbf{singoli lanci siano indipendenti tra loro}.\\
Si determini con che probabilità sia ottenibile una certa $n$-pla di risultati; per esempio, se $n=7$, si vorrebbe sapere con che probabilità esce il risultato ($1$,$1$,$0$,$0$,$0$,$1$,$0$), dove per semplicità si è etichettato testa con $1$ e croce con $0$.\\
Si consideri come spazio degli eventi elementari
\[\Omega=\{0,1\}^n\]
cioé l'insieme di tutte le $n$-uple costituite da $0$ e $1$. Come di consueto, essendo $\Omega$ un insieme discreto, è possibile stabilire una probabilità $p : \mathcal{A} \longrightarrow [0,1]$, dove $\mathcal{A}$ è la $\sigma$-algebra di tutti i sottoinsieme di $\Omega$, e poi procedere a definire $p$ sugli eventi elementari, ossia quanto vale $p(\{\omega\}), \forall \omega \in \Omega$ e poi porre
\[p(A) = \sum_{\omega \in A} p(\{\omega\}) \hspace{1em} \forall A \in \mathcal{A}\]
Nel caso specifico considerato, siccome $n=7$ e $\omega=(1,1,0,0,0,1,0)$, si considerino gli eventi
\[A := \text{\quotes{esce 1 al lancio i-esimo}} \hspace{1em} \text{con} \hspace{1em} i = 1,...,7\]
Naturalmente, in funzione di tali eventi, è possibile reinterpretare l'evento elementare $\{\omega\}$ come segue:
\[\{\omega\}=A_1 \cap A_2 \cap A_3^c \cap A_4^c \cap A_5^c \cap A_6 \cap A_7^c\]
Visto che la probabilità di ottenere $1$ (cioé testa) in un singolo lancio è $q$, sarà sufficiente porre
\[p(A_i)=q \hspace{1em} \text{e} \hspace{1em} p(A_i^c)=1-q \hspace{1em} \text{con} \hspace{1em} i=1,...,7\]
Poiché gli eventi $\{A_1,...,A_7\}$ sono indipendenti, lo sono anche gli eventi $\{A_1,A_2,A_3^c,A_4^c,A_5^c,A_6,A_7^c\}$ (per quanto già dimostrato nella proposizione su famiglie di eventi dipendenti precedente, in cui si è visto come l'indipendentza commuta col complementare di eventi). Pertanto, essendo tali eventi indipendenti, la probabilità della loro intersezione (e quindi dell'evento $\{\omega\}$), per definizione di eventi indipendenti, è data dal prodotto delle probabilità dei singoli eventi:
\[p(\{\omega\}) = p(A_1) \cdot p(A_2) \cdot p(A_3^c) \cdot p(A_4^c) \cdot p(A_5^c) \cdot p(A_6) \cdot p(A_7^c) = q^3 \cdot (1-q)^4\]
in quanto $p(A_i^c)=1-q$ con $i=1,...,7$.

\vspace{1em}
\noindent
\textbf{Osservazione}: È possibile, quindi, generalizzare tale modello, indicando con $\omega_i$ la componente $i$-esima di un elemento $\omega \in \Omega$, cioé
\[\omega = (\omega_1,...,\omega_n)\]
considerando il seguente modo formale di formare gli eventi
\[A_i = \text{\quotes{esce 1 al lancio i-esimo}} = \{\omega \in \Omega : \omega_i = 1\}\]
ponendo $p(A_i)=q$. Si noti che $p(A_i^c)=1-q$ e che
\[A_i^c = \text{\quotes{esce 0 al lancio i-esimo}} = \{\omega \in \Omega : \omega_i = 0\}\]
Fissato $\omega \in \Omega$ si divide l'insieme degli indici $I=\{1,...,n\}$ in due sottofamiglie
\[I_1 := \{i \in \{1,...,n\} : \omega_i = 1\}\]
\[I_0 := \{i \in \{1,...,n\} : \omega_i = 0\}\]
Nel caso sepcifico visto in precedenza, cioé $\omega=(1,1,0,0,0,1,0)$, si ottiene
\[I_1=\{1,2,6\} \hspace{1em} \text{e} \hspace{1em} I_0=\{3,4,5,7\}\]
per cui si può scrivere $\{\omega\}$ come intersezioni di $A_i$ e dei suoi complementari, ovvero
\[\{\omega\} = \bigcap_{i \in I_1} A_i \bigcap_{i \in I_0} A_i^c\]
e quindi per l'indipendenza degli eventi $A_i$ e $A_i^c$ si ottiene che
\[p(\{\omega\})= \prod_{i \in I_1} p(A_i) \cdot \prod_{i \in I_0} p(A_i^c) = q^{\vert I_1 \vert} \cdot (1-q)^{\vert I_0 \vert}\]
In cui è facile osservare come
\[\vert I_1 \vert = \sum_{i=1}^n \omega_i \hspace{1em} \text{e} \hspace{1em} \vert I_0 \vert = n - \sum_{i=1}^n \omega_i\]
per cui, in definitiva, si può scrivere che
\[\boxed{p(\{\omega\})=q^{\displaystyle{\sum_{i=1}^n \omega_i}} \cdot (1-q)^{\displaystyle{n-\sum_{i=1}^n \omega_i}}}\]
una espressione fondamentale che porta alla seguente definizione:

 % Tabella per le definizione di concetti, etc...
 \vspace{1em}
 \rowcolors{1}{black!5}{black!5}
 \setlength{\tabcolsep}{14pt}
 \renewcommand{\arraystretch}{2}
 \noindent
 \begin{tabularx}{\textwidth}{@{}|P|@{}}
     \hline
     {\textbf{SCHEMA DELLE PROVE INDIPENDENTI}}\\
     \parbox{\linewidth}{Lo spazio di probabilità appena costruito è detto \textbf{schema delle prove indipendenti} (o anche schema delle prove ripetute, o schema di Bernoulli).
     \vspace{3mm}}\\
     \hline
 \end{tabularx}

\vspace{1em}
\noindent
Tale spazio di probabilità viene utilizzato non solo per il lancio della moneta, ma in generale in esperimenti costitui da \textbf{$\boldsymbol{n}$ prove ripetute ed indipendenti}, che possono avere solo due esiti possibili, etichettati con $1$ e $0$, e detti convenzionalmente \quotes{successo} ed \quotes{insuccesso}.\\
Ovviamente, affinché quello appena definito possa essere ritenuto uno spazio di probabilità, si sarebbe dovuto verificare che $p(\Omega)=1$, cioé che
\[\sum_{\omega \in \Omega} p \left(\{\omega\}\right)=1\]
che è certamente vero e si può verificare per induzione: infatti, per $n=1$, si possono identificare due possibili eventi $\omega_1=(1)$ e $\omega_2=(0)$, il primo con probabilità $q$, il secondo con probabilità $1-q$; allora, si ha che:
\[p(\Omega)=\sum_{\omega \in \Omega} p \left(\{\omega\}\right)=q+(1-q)=1\]
Supposta vera tale proprietà per $n$, si dimostri sia vera per $n+1$: naturalmente, aggiungendo una prova in più, si raddoppia il numero di eventi $\omega$ che si potevano considerare con sole $n$ prove, per cui, se la probabilità del singolo evento $\{\omega\}$ è
\[p(\{\omega\})=q^{\displaystyle{\sum_{i=1}^{n+1} \omega_i}} \cdot (1-q)^{\displaystyle{n+1-\sum_{i=1}^{n+1} \omega_i}}=q^{\displaystyle{\sum_{i=1}^n \omega_i}} \cdot q^{\omega_{n+1}} \cdot (1-q)^{\displaystyle{n-\sum_{i=1}^n \omega_i}} \cdot (1-q)^{1-\omega_{n+1}}\]
Ma è immediato evincere come
\[q^{\omega_{n+1}} \cdot (1-q)^{1-\omega_{n+1}}\]
possa essere valutato in funzione del valore di $\omega_{n+1}$: esso varrà $1$ per $2^n$ volte e $0$ per $2^n$ volte. Ciò significa che, impiegando l'ipotesi induttiva
\[p(\Omega)=\sum_{\omega \in \Omega} p \left(\{\omega\}\right)=
2^n k \cdot q + 2^n k \cdot (1-q) = 2^n k \cdot (q+1-q) = 2^n \cdot k\]
indicando con $k$
\[k=p(\{\omega\})=q^{\displaystyle{\sum_{i=1}^n \omega_i}} \cdot (1-q)^{\displaystyle{n-\sum_{i=1}^n \omega_i}}\]
l'espressione per determinare la probabilità di un evento $\omega$ costituito da $n$ prove; Siccome l'ipotesi induttiva permette di affermare che $2^n k = 1$, da ciò segue la tesi.

\vspace{1em}
\noindent
\textbf{Osservazione}: L'evento \quotes{nessuna delle $n$ prove ha successo} si scrive formalmente come
\[A=\{\omega \in \Omega : \omega_i \neq 1 \text{ per ogni } i=1,...,n\} = \{(0,...,0)\}\]
ed ha una probabilità
\[p(A)=(1-q)^n\]
l'evento completamentare $A^c$, cioé \quotes{almeno una delle $n$ prove ha successo}, ha quindi probabilità
\[p(A^c)=1-(1-q)^n\]
Inoltre, quale che sia $q>0$ fissato, si ha che
\[\lim_{n \to +\infty} (1-q)^n = 0\]
essendo $0<1-q<1$. Come naturale conseguenza, pertanto, si ha che
\[\lim_{n \to +\infty} 1-(1-q)^n = 1\]
Dunque, per quanto sia piccola la probabilità $q$ relativa alla singola prova, con un numero abbastanza grande di prove c'è una quasi certezza di ottenere un sucesso: fissato $\epsilon > 0$, esiste $n_0(\epsilon)$ tale che se $n \geq n_0$ allora $1-q^{n}<\epsilon$ e quindi $p(A^c)>1-\epsilon$.

\vspace{1em}
\noindent
\textbf{Esempio - Scimmai di Borel}: Si supponga di porre una scimmia davanti ad un laptop (modernizzando l'esempio): si dica se riuscirà, pigiando i stati a caso, a comporre il primo capitolo di Harry Potter.\\
Per ipotesi, sulla tastiera vi sono $25$ tasti e si suppone che ogni tasto abbia la stessa probabilità di essere premuto; inoltre, il primo capitolo è costituito da $5000$ caratteri (compresi gli spazi). Per scriverlo bisogna effettuare una specifica sequenza di battitura dei $25$ tasti, per cui è possibile descrivere tale operazione come una disposizione con ripetizione di classe $5000$ su $25$ elementi. Le possibili disposizioni, quindi, sono
\[25^{5000} \cong 10^{7000}\]
visto che ogni tasto ha la stessa probabilità di essere premuto, ogni disposizione di tasti ha la stessa probabilità di essere battuta, ed è
\[q=25^{-5000}\]
Taluna è la probabilità che la scimmia ha di scrivere il primo capitolo al primo colpo; dopo tale prima prova, però, essa potrebbe provare una seconda volta, e così via. Per quanto detto precedentemente, prendendo $\epsilon=\frac{1}{10^4}$, si ha che esiste un $n_0$ tale che se la scimmia fa $n \geq n_0$ tentativi, allora $(1-q)^n < \frac{1}{10^4}$ e quindi $p(A^c) > 1 - \frac{1}{10^4}$, cioé la probabilità di scrivere il primo capitolo è maggiore di $99.99\%$. Sembra strano, ma la verità è che la soglia $n_0$ è terribilmente alta: $(1-q)^{n_0} < \frac{1}{10^4}$ significa
\[n_0 \cdot \log(1-q) < \log \left( \frac{1}{10^4}\right)\]
Stimando dall'alto $\log \left(\frac{1}{10^4}\right)$ con $-8$ e dal basso $\log(1-q)$ con $-2q$ si ottiene che deve essere \textbf{almeno}
\[n_0 > \frac{4}{q} = 4 \cdot 25^{5000}\]
che è un valore altissimo di tentativi, concretamente impraticabile.

\vspace{1em}
\noindent
\textbf{Esercizio $\boldsymbol{1}$}: Relativamente ad uno schema di $n$ prove indipendenti e ripetute, con probabilità di successo $q$, si determini la probabilità che il primo successo avvenga alla $j$-esima prova, con $j \in \{1,...,n\}$ fissato.\\
L'evento che si sta considerando è il seguente:
\[C_j = \text{\quotes{il primo successo si verifica alla j-esima prova}} = \{\omega \in \Omega : \omega_1=...=\omega_{j-1}=0 \text{ e } \omega_j=1\}\]
che si può esprimere come intersezione degli eventi indipendenti seguente
\[C_j = A_1^c \cap ... \cap A_{j-1}^c \cap A_j\]
e la sua probabilità vale, sfruttando l'indipendenza degli eventi stessi come
\[p(C_j) = p(A_1^c) \cdot ... \cdot p(A_{j-1}^c) \cdot p(A_j) = (1-q)^{j-1} \cdot q\]
Da notare la \textbf{non dipendenza} da $n$ (che è ovvio in quanto il successo oggetto di interesse riguarda $j \leq n$ prove, quindi le $n-j$ prove successive sono ininfluenti) e si noti che tale risultato era già stato ottenuto in precedenza quando $q=\frac{1}{2}$.

\vspace{1em}
\noindent
\textbf{Esercizio $\boldsymbol{2}$}: Relativamente ad uno schema di $n$ prove indipendenti e ripetute, con probabilità di successo $q$, si determini la probabilità che $k$ prove abbiano successo, con $k \in \{1,...,n\}$ fissato.\\
L'evento che si sta considerando è
\[C_k = \text{\quotes{k prove hanno successo}} = \{\omega \in \Omega : k \text{ componenti di } \omega \text{ valgono } 1 \text{ (e } n-k \text{ valgono }0)\}\]
Quindi $\omega \in C_k$ \textbf{se e solo se} esiste una sottofamiglia di indici $H\subset \{1,...,n\}$ con $\vert H \vert = k$ (cioè csotituita da $k$ indici), in modo tale da descrivere $\omega$ come
\[\omega \in \bigcap_{h \in H} A_h \cap \bigcap_{h \in H^c} A_h^c\]
dove $H^c=\{1,...,n\} - H$. Per esempio, se $H=\{1,...,k\}$ allora si ha che
\[\bigcap_{h \in H} A_h \cap \bigcap_{h \in H^c} A_h^c = \{\omega \in \Omega : \omega_i=...=\omega_k=1, \omega_{k+1}=...=\omega_n=0\} = \{(\underbrace{1,...,1}_{k \text{ volte}},\underbrace{0,...,0}_{n-k \text{ volte}})\}\]
Dal momento che ogni elemento di $C_k$ presenta $k$ componenti non nulle, se $\omega \in C_k$, allora
\[p \left(\{\omega\}\right)=q^k \cdot (1-q)^{n-k}\]
Giacché è possibile associare ad $H$ l'evento $\omega = (\omega_1,...,\omega_2)$ con $\omega_h=1$ se $h \in H$ e $\omega_h=0$ se $h \notin H$. Chiaramente $\omega \in C_k$, per cui in questo modo è stata creata una corrispondenza biunivoca tra gli elementi di $C_k$ e e le combinazioni di classe $k$ su $\{1,...,n\}$. Si è provato che, quindi
\[\vert C_k \vert = \binom{n}{k}\]
ovvero il numero di elementi di $C_k$ è dato dal numero di sottoinsiemi di $k$ elementi su $\{1,..,n\}$.\\
Si è così ottenuto che
\[\boxed{p(C_k)=\sum_{\omega \in C_k} p(\{\omega\}) = \binom{n}{k} \cdot q^k \cdot (1-q)^{n-k}}\]
E ancora una volta tale quesito era stato già ottenuto in precedenza; la probabilità che effettuando $n$ estrazioni con reimmissione da un'urna contenente $M$ palline bianche ed $N-M$ palline nere (quindi $N$ in totale) è proprio data dalla formula seguente:
\[\binom{n}{k} s^k \cdot (1-s)^{n-k} \hspace{1em} \text{dove} \hspace{1em} s=\frac{M}{N}\]
In effetti, tale tipo di estrazion può essere visto come uno schema di $n$ prove indipendenti. La probabilità di successo, cioé di estrarre una pallina bianca, è
\[s=\frac{M}{N}\]
per ogni singola estrazione. Per tale ragione la formula ottenuta in precedenza restituisce per $q=s$ lo stesso risultato.

\newpage
\begin{center}
  4 aprile 2022
\end{center}
\section{Variabili aleatorie}
Fino a questo momento, in $\mathbb{R}^2$ è sempre stata considerata la $\sigma$-algebra di Borel seguente
\[\left\{
  \text{ogni sottoinsieme di } \mathbb{R}^2 \text{ per cui abbia senso il concetto di area}
\right\}\]
Non avendo, però, ancora gli strumenti matematici per formalizzare tale concetto, ma avendo in mente il concetto intuitivo per cui un sottoinsieme \quotes{decente} nel piano è possibile approssimarlo in area con una famiglia di rettangoli, si opta per la seguente definizione formale, chiamando \textbf{$\boldsymbol{\sigma}$-algebra di Borel in $\boldsymbol{\mathbb{R}^2}$} la più piccola $\sigma$-algebra che contiene tutti i rettangoli, cioé che contiene la famiglia
\[\{(a,b) \times (c,d) : a,b,c,d \in \mathbb{R}\}\]
ciò non significa che tale famiglia sia una $\sigma$-algebra, ma che una $\sigma$-algebra di Borel la contiene necessariamente tutta: si indica, allora, tale $\sigma$-algebra con il simbolo $\mathcal{B}(\mathbb{R}^2)$. Dal momento che la $\sigma$-algebra è chiusa rispetto alle operazioni di unione e intersezione numerabili, è possibile interpretare gli elementi della $\sigma$-algebra come unioni o intersezioni numerabili di rettangoli: ciò significa che ogni sottoinsieme di $\mathbb{R}^2$ di cui è possibile misurare l'area (quindi in particolar modo le figure geometriche classiche) appartiene a $\mathcal{B}(\mathbb{R}^2)$.\\
Analogamente, si può definire la $\sigma$-algebra di Borel in $\mathbb{R}^3$ come la più piccola $\sigma$-algebra che contiene la famiglia dei parallelepipedi
\[\left\{\prod_{k=1}^{3} (a_k,b_k) : a_k,b_k \in \mathbb{R}, \text{ con } k=1,2,3\right\}\]
Similmente si definisce la $\sigma$-algebra di Borel su $\mathbb{R}$ la più piccola $\sigma$-algebra che contiene la famiglia degli intervalli limitati e aperti seguente
\[\{(a,b):a,b \in \mathbb{R}\}\]
È utile designare tali $\sigma$-algebre con $\mathcal{B}(\mathbb{R}^3)$ e $\mathcal{B}(\mathbb{R})$ o più semplicemente con $\mathcal{B}$ quando la dimensione è implicita nel contesto.\\
Incominciando ad analizzare $\mathcal{B}=\mathcal{B}(\mathbb{R})$, dalle proprietà di una $\sigma$-algebra, segue che $\mathcal{B}$ contiene anche
\begin{itemize}
  \item intervalli del tipo $(-\infty,a),(a,+\infty)$, in quanto
  \[(-\infty,a) = \bigcup_{k=1}^{\infty} (a-k,a) \hspace{3em} (a,+\infty) = \bigcup_{k=1}^{\infty} (a,a+k)\]
  essendo la $\sigma$-algebra di Borel chiusa rispetto all'unione numerabile.
  \item intervalli del tipo $(-\infty,a],[a,+\infty]$ in quanto
  \[(-\infty,a]=\mathbb{R}-(a,+\infty) \hspace{3em} [a,+\infty)=\mathbb{R}-(-\infty,a)\]
  essendo la $\sigma$-algebra di Borel chiusa rispetto al complementare.
  \item intervalli del tipo $[a,b]$ in quanto
  \[[a,b]=(-\infty,b]\cap[a,+\infty)\]
  essendo la $\sigma$-algebra di Borel chiusa rispetto all'intersezione numerabile.
\end{itemize}

\newpage
\noindent
Di seguito si espone la definizione di \textbf{variabile aleatoria}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{VARIABILE ALEATORIA}}\\
    \parbox{\linewidth}{Sia $(\Omega,\mathcal{A},p)$ uno spazio di probabilità. Allora si chiamerà \textbf{variabile aleatoria} un'applicazione
    \[\mathcal{X} : \Omega \longrightarrow \mathbb{R}\]
    tale per cui, $\forall B \in \mathcal{B}$
    \[\mathcal{X}^{-1}(B) = \{\omega \in \Omega : \mathcal{X}(\omega) \in B\} \in \mathcal{A}\]
    \vspace{-1mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
In altre parole, una variabile aleatoria consente di considerare un sottoinsieme di $\mathbb{R}$, chiamato $B$ (che sia almeno decente, cioé in $\mathcal{B}$) e riportarlo su $\Omega$ dentro la famiglia $\mathcal{A}$ così da poterlo misurare tramite $p$ (cioé assegnargli la probabilità $p \left(\mathcal{X}^{-1}(B)\right)$).

\begin{lemma}
  Una funzione
  \[\mathcal{X} : \Omega \longrightarrow \mathbb{R}\]
  è una variabile aleatoria \textbf{se e solo se} una delle seguenti conidizioni è soddisfatta
  \[
    \rowcolors{1}{white}{white}
    \begin{array}{llll}
      \mathcal{X}^{-1} \left((a,b)\right) & = \{\omega \in \Omega : \mathcal{X}(\omega) \in (a,b)\} \in \mathcal{A}, & \hspace{1em} \forall a,b \in \mathbb{R}\\
      \mathcal{X}^{-1} \left([a,b]\right) & = \{\omega \in \Omega : \mathcal{X}(\omega) \in [a,b]\} \in \mathcal{A}, & \hspace{1em} \forall a,b \in \mathbb{R}\\
      \mathcal{X}^{-1} \left((-\infty,a)\right) &= \{\omega \in \Omega : \mathcal{X}(\omega) \in (-\infty,a)\} \in \mathcal{A}, & \hspace{1em} \forall a \in \mathbb{R}\\
      \mathcal{X}^{-1} \left((-\infty,a]\right) &= \{\omega \in \Omega : \mathcal{X}(\omega) \in (-\infty,a]\} \in \mathcal{A}, & \hspace{1em} \forall a \in \mathbb{R}\\
    \end{array}
  \]
  ossia la controimmagine attravero $\mathcal{X}^{-1}$ di un intervallo di cui sopra è un evento, ossia appartiene a $\mathcal{A}$.
\end{lemma}

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che solo apparentemente le condizioni esposte all'interno dell Lemma precedente sono meno restrittive rispetto a quelle della definizione: infatti, nella definizione si richiede che la condizione sia soddisfatta per tutti gli elementi della $\sigma$-algebra dei boreliani (ovvero $\forall B \in \mathcal{B}$), mentre nel Lemma si fa riferimento solamente ad alcuni particolari insiemi $B \in \mathcal{B}$, che sono sempre contenuti nella $\sigma$-algebra dei boreliani.\\
Ciò comporta che ognuna delle quattro condizioni esposte nel Lemma sono necessarie per affinché una funzione $\mathcal{X}$ sia una variabile aleatoria.

\vspace{1em}
\noindent
\textbf{Dimostrazione}: Sfruttando il fatto che unione, intersezione e passaggio al complementare commutano con $\mathcal{X}^{-1}$, si vede facilmente che e \textbf{quattro condizioni sono equivalenti}.\\
Per esempio:
\[\mathcal{X}^{-1} \left((-\infty,a)\right) = \mathcal{X}^{-1} \left( \bigcup_{k=1}^\infty (a-k,a)\right) = \bigcup_{k=1}^\infty \mathcal{X}^{-1} \left((a-k,a)\right)\]
dal momento che unione e $\mathcal{X}^{-1}$ commutano. Quindi se $\mathcal{X}^{-1} \left((a-k,a)\right) \in \mathcal{A}$ per ogni $k \in \mathbb{N}$, allora anche $\mathcal{X}^{-1} \left(-\infty,a\right) \in \mathcal{A}$. Ciò prova che il primo punto implica il secondo.\\
Appurato che le quattro condizioni sono equivalenti, va verificato che la prima implica che $\mathcal{X}$ è una variabile aleatoria (mentre il viceversa diviene banale, dal momento che, per quanto detto, ognuno dei quattro intervalli considerati è necessariamente contenuto nella $\sigma$-algebra dei boreliani). Si osservi, allora, che la famiglia
\[\mathcal{X}^{-1}(\mathcal{B}) := \{\mathcal{X}^{-1}(B) : B \in \mathcal{B}\}\]
è a sua volta una $\sigma$-algebra su $\Omega$. Ma se $\mathcal{B}$, come da definizione, è la più piccola $\sigma$-algebra che contiene gli intervalli aperti e limitati $\{(a,b)\}$, allora $\mathcal{X}^{-1}(\mathcal{B})$ è la più piccola $\sigma$-algebra che contiene $\{\mathcal{X}^{-1}(a,b)\}$. Ma allora, se è soddisfatta la prima condizione delle quattro esposte, significa che $\mathcal{X}^{-1}(a,b) \subset \mathcal{A}$ ed essendo $\mathcal{X}^{-1}(\mathcal{B})$ la più piccola $\sigma$-algebra che contiene $\{\mathcal{X}^{-1}(a,b)\}$, per \textbf{minimalità} deve essere che $\mathcal{X}^{\mathcal{B}} \subset \mathcal{A}$.\\
In altre parole, dire che $\mathcal{X}$ è una variabile aleatoria significa, per definizione, che $\mathcal{X}^{-1}(\mathcal{B}) \subset \mathcal{A}$. Ora, così come $\mathcal{B}$ è la più piccola $\sigma$-algebra includente $\{(a,b) : a,b \in \mathbb{R}\}$, $\mathcal{X}^{-1}(\mathcal{B})$ è la più piccola $\sigma$-algebra includente $\{\mathcal{X}^{-1}((a,b)) : a,b \in \mathbb{R}\}$. Quindi, se $\{\mathcal{X}^{-1}((a,b)) : a,b \in \mathbb{R}\}$ è inclusa in $\mathcal{A}$, automaticamente lo è $\mathcal{X}^{-1}(\mathcal{B})$ per \textbf{minimalità}.

\vspace{1em}
\noindent
\textbf{Notazione}: Per comodità, si usano le notazioni
\begin{itemize}
  \item $\{\mathcal{X} \in B\}$ per $\{\omega \in \Omega : \mathcal{X}(\omega) \in B\}$ o similmente per $\mathcal{X}^{-1}(B)$ con $B \in \mathcal{B}$;
  \item $\{a < \mathcal{X} < b\}$ per $\{\omega \in \Omega : \mathcal{X}(\omega) \in (a,b)\}$ o similmente per $\mathcal{X}^{-1}((a,b))$ con $a,b \in \mathbb{R}$;
  \item $\{\mathcal{X} < a\}$ per $\{\omega \in \Omega : \mathcal{X}(\omega) \in (-\infty,a)\}$ similmente per $\mathcal{X}^{-1}((-\infty,a))$ con $a \in \mathbb{R}$.
\end{itemize}
e così via.\\
Inoltre, data una variabile aleatoria $\mathcal{X}$, gli eventi $\{\mathcal{X} \in B\}$ con $B \in \mathcal{B}$ sono detti \textbf{generati} da $\mathcal{X}$.

\vspace{1em}
\noindent
\textbf{Osservazione $\boldsymbol{1}$}: Si osservi che $\forall a \in \mathbb{R}$, $\{a\} = (-\infty,a] \cap [a,+\infty) \in \mathcal{B}$, quindi se $\mathcal{X}$ è una variabile aleatoria, allora
\[\{\omega \in \Omega : \mathcal{X}(\omega) = a\} \in \mathcal{A}\]
Anche in questo caso si impiegherà la notazione semplificata $\{\mathcal{X}=a\}$ per indicare tale insieme, ossia l'evento aggregato costituito dagli eventi elementari che presentano immagine $a$ attraverso la funzione $\mathcal{X}$.

\vspace{1em}
\noindent
\textbf{Osservazione $\boldsymbol{2}$}: Data una variabile aleatoria $\mathcal{X}$, è possibile considerare su $\mathcal{B}$ la probabilità $p_{\mathcal{X}}(B)=p \left(\{\mathcal{X} \in B\}\right)$:
\[
  \begin{tikzcd}
    \underset{\displaystyle{\mathcal{A}}}{\Omega} \arrow{r}{\mathcal{X}} \arrow[swap]{dr}{p} & \underset{\displaystyle{\mathcal{B}}}{\mathbb{R}} \arrow{d}{p_{\mathcal{X}}}\\
     & {[0,1]}
  \end{tikzcd}
\]
È facile capire come tale definizione abbia senso, giacchè $\{\mathcal{X} \in B\} = \mathcal{X}^{-1}(B) \in \mathcal{A}$.\\
Inoltre, $p_{\mathcal{X}}$ è detta \textbf{legge} (o \textbf{distribuzione}) di $\mathcal{X}$, in quando permette di capire quale sia la probabilità che $\mathcal{X}$ assuma i valori di un insieme boreliano $B$.

\vspace{1em}
\noindent
\textbf{Osservazione $\boldsymbol{3}$}: Quando $(\Omega, \mathcal{A}, p)$ è uno spazio di \textbf{probabilità discreto} e la $\sigma$-algebra $\mathcal{A}$ è la famiglia di tutti i sottoinsiemi di $\Omega$, banalmente ogni funzione
\[\mathcal{X} : \Omega \longrightarrow \mathbb{R}\]
è una variabile aleatoria, in quanto, ovviamente
\[\{\mathcal{X} \in B\} \in \mathcal{A} \hspace{1em} \forall B \in \mathcal{B}\]
Tuttavia, non sempre si opera su uno spazio di probabilità discreto, per cui bisogna impiegare il Lemma precedente al fine di verificare che una funzione $\mathcal{X}$ sia a tutti gli effetti una variabile aleatoria.

\vspace{1em}
\subsection{Variabili aleatorie discrete}
La prima categoria di variabili aleatorie che vengono considerate riguarda le \textbf{variabili aleatorie discrete}, di cui di seguito si fornisce la definizione:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{VARIABILE ALEATORIA DISCRETA}}\\
    \parbox{\linewidth}{Una \textbf{variabile aleatoria} $\mathcal{X}$ si definisce \textbf{discreta} quando assume al più una quantità numerabile di valori, ossia $\mathcal{X}(\Omega)=\{x_1,...,x_n,...\}$ (ossia il codominio di $\mathcal{X}$ è un insieme finito o al più numerabile).\vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\subsubsection{Densità associata ad una variabile aleatoria discreta}
Data una \textbf{variabile aleatoria} $\mathcal{X}$, considerando la funzione $q : \mathbb{R} \longrightarrow [0,1]$ definita da
\[q(x) = p \left(\{\mathcal{X}=x\}\right)\]
si ha che
\begin{itemize}
  \item $q(x)=0$ con eccezione dei valori $x_1,...,x_n,...$ assunti da $\mathcal{X}$ (ossia la funzione $q$ è quasi sempre nulla tranne che per i valori assunti da $\mathcal{X}$), in quanto se $x \notin \{x_1,...,x_n,...\}$ allora si ha che $\{\omega \in \Omega : \mathcal{X}(\omega)=x\}=\varnothing$ ed essendo un insieme vuoto ha probabilità nulla;
  \item $\displaystyle{\sum_{x \in \mathbb{R}} q(x) = \sum_n q(x_n) = \sum_n p \left(\{\mathcal{X}=x_n\}\right) = p \left(\bigcup_{n} \{\mathcal{X}=x_n\}\right)} = p(\Omega)=1$\\\\
  La quale è una somma di un numero finito o al più numerabile di valori (ossia una somma finita o serie).
\end{itemize}
Tenuto conto che gli insiemi $\{\mathcal{X}=x_n\}$ sono digiunti e la loro unione copre totalmente $\Omega$. La funzione $q$ è detta \textbf{densità} associata a $\mathcal{X}$.

\vspace{1em}
\noindent
\textbf{Osservazione}: Tramite la densità $q$ è possibile calcolare $p_{\mathcal{X}}$, ossia la legge o distribuzione di $\mathcal{X}$. Infatti, tenuto conto che, dato un $B \in \mathcal{B}$
\[\{\mathcal{X} \in B\} = \{\omega \in \Omega : \mathcal{X}(\omega) \in B\} = \bigcup_{x \in B} \{\omega \in \Omega : \mathcal{X}(\omega)=x\} = \bigcup_{x \in B} \{\mathcal{X}=x\}\]
è possibile affermare che
\[p_{\mathcal{X}}(B) =p \left(\{\mathcal{X}\in B\}\right) = \sum_{x \in B} p \left(\{\mathcal{X} = x\}\right) = \sum_{x \in B} q(x)\]
essendo una \textbf{sommatoria contabile}, per quanto già detto, di eventi $\{\mathcal{X}=x\}$ ovviamente \textbf{disgiunti} (per cui la probabilità dell'unione è data dalla somma delle probabilità dei singoli eventi).\\
In pratica è una naturale estensione di quanto già si faceva in precedenza, quando si definiva la probabilità sugli eventi elementari $p(\{\omega\})$ con $\omega \in \Omega$ e e poi si definiva la probabilità di eventi aggregati $A$ come
\[p(A)=\sum_{\omega \in A} p(\{\omega\})\]
Pertanto, al fine di stabilire la probabilità che \quotes{$\mathcal{X}$ assuma determinati valori} non è necessario conoscere completamente $\mathcal{X}$, ma solo sapere qual è la sua densità $q$.

\vspace{1em}
\noindent
\begin{lemma}
  Dato uno spazio di probabilità ($\Omega$, $\mathcal{A}$, $p$) e una funzione $\mathcal{X} : \Omega \longrightarrow \mathbb{R}$ che assume un \textbf{numero di valori al più numerabile}, $\mathcal{X}$ risulta essere una variabile aleatoria \textbf{se e solo se} $\{\mathcal{X}=x\} \in \mathcal{A}, \forall x \in \mathbb{R}$.
\end{lemma}

\vspace{1em}
\noindent
\textbf{Dimostrazione}: Ovviamente, se $\mathcal{X}$ è una \textbf{variabile aleatoria}, allora $\{\mathcal{X}=x\} \in \mathcal{A}$, in quanto $\{x\} \in \mathcal{B}$ (essendo $\{x\}=[x,x]$).\\
Viceversa, dato $B \in \mathcal{B}$, è possibile scrivere, per quanto già visto in precedenza,
\[\{\mathcal{X} \in B\} = \bigcup_{x \in B \cap \mathcal{X}(\Omega)} \{\mathcal{X}=x\}\]
che appartiene necessariamente ad $\mathcal{A}$ essendo l'unione al più numerabile di eventi (disgiunti) del tipo $\{\mathcal{X}=x\}$ che per ipotesi appartengono ad $\mathcal{A}$.

\vspace{1em}
\noindent
\textbf{Osservazione $\boldsymbol{1}$}: Per lo stesso motivo, se $\mathcal{X} : \Omega \longrightarrow \mathbb{R}$ è una variabile aleatoria discreta, allora $\{\mathcal{X} \in B\} \in \mathcal{A}$ quale che sia $B \in \mathbb{R}$, anche se tale $B \notin \mathcal{B}$, sempre perché
\[\{\mathcal{X} \in B\} = \bigcup_{x \in B \cap \mathcal{X}(\Omega)} \{\mathcal{X}=x\}\]
ossia l'evento $\{\mathcal{X} \in B\}$ si esprime come unione finita o al più numerabile di eventi che per ipotesi, essendo $\mathcal{X}$ variabile aleatoria, appartengono a $\mathcal{A}$.

\vspace{1em}
\noindent
\textbf{Osservazione $\boldsymbol{2}$}: Per quanto già osservato, è sufficiente conoscere la densità $q$ di $\mathcal{X}$ al fine di manipolare $\mathcal{X}$, senza determinare specificatamente $\mathcal{X}$; non solo, ma addirittura è sufficiente solamente disporre di $q$, senza nemmeno $\mathcal{X}$ per poter ottenere la legge o distribuzione associata, come esposto nella seguente proposizione:

\vspace{1em}
\noindent
\textbf{Proposizione}: Sia $q : \mathbb{R} \longrightarrow [0,1]$ una funzione tale che
\begin{enumerate}
  \item $q=0$ tranne che su una quantità al più numerabile di punti;
  \item $\displaystyle{\sum_{x \in \mathbb{R}} q(x)=1}$ (la quale è una sommatoria che ha significato, essendo una somma finita o al più numerabile, quindi una serie, per quanto già esposto in precedenza);
\end{enumerate}
Allora esiste uno spazio di probabilità ($\Omega$, $\mathcal{A}$, $p$) e una variabile aleatoria $\mathcal{X} : \Omega \longrightarrow \mathbb{R}$ avente $q$ come densità.

\vspace{1em}
\noindent
\textbf{Dimostrazione}: Sia $\Omega := \{x \in \mathbb{R} : q(x) \neq 0\}$. Per il primo punto della proposizione, si ha che $\Omega$ è necessariamente finito o al più numerabile. Questo fatto permette di considerare su $\Omega$ la $\sigma$-algebra $\mathcal{A}$ costituita da tutti i sottoinsiemi di $\Omega$.\\
Dopodichè si definisce una probabilità $p : \mathcal{A} \longrightarrow [0,1]$, ponendo
\[p \left(\{x\}\right) = q(x) \hspace{1em} \forall x \in \Omega\]
e poi estendendo come al solito
\[p(A) = \sum_{x \in A} p \left(\{x\}\right) \hspace{1em} \forall A \in \mathcal{A}\]
Per l'ipotesi assunta al secondo punto della proposizione, taluna è effettivamente una probabilità (giacché $p(\Omega)=\displaystyle{\sum_{x \in \mathbb{R}} p \left(\{\omega\}\right) = \sum q(x)=1}$).\\
Infine è sufficiente definire una mappa $\mathcal{X} : \Omega \longrightarrow \mathbb{R}$ ponendo
\[\mathcal{X}(\omega) = \omega \hspace{1em} \forall \omega \in \Omega\]
ossia l'applicazione identica. Dal momento che la $\sigma$-algebra $\mathcal{A}$ comprende tutti i sottoinsiemi di $\Omega$, $\mathcal{X}$ è banalmente una variabile aleatoria (per quanto già osservato in precedenza, in quanto $\{\mathcal{X} \in B\} \in \mathcal{A} \forall B \in \mathcal{B}$).\\
Pertanto, per costruzione
\[p \left(\{\mathcal{X}=x\}\right) = p \left(\{\omega \in \Omega : \mathcal{X}(\omega) = x\}\right) = p \left(\{x\}\right) = q(x)\]
essendo $\mathcal{X}$ l'applicazione identica, per cui $\omega=x$. Pertanto $q(x)$ è a tutti gli effetti la densità della variabile aleatoria $\mathcal{X}$ definita in precedenza.\\
Quindi una densità non solo individua la distribuzione di una variabile aleatoria, ma è sostanzialmente l'attore principale.

\newpage
\noindent
\subsection{Densità binomiale}
Di seguito si espone la definizione di \textbf{densità binomiale}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{DENSITÀ BINOMIALE}}\\
    \parbox{\linewidth}{Siano $n \in \mathbb{N}$ e $q \in (0,1)$ due numeri fissati. Si chiamerà, allora, \textbf{densità binomiale} di parametri $n$ e $q$ la funzione così definita
    \[
      q(x) = \left\{
      \begin{array}{ll}
        \displaystyle{\binom{n}{x} \cdot q^x \cdot (1-q)^{n-x}} & x=0,1,...,n\\
        0 & \text{altrimenti}
      \end{array}
      \right.
    \]
    denotata con il simbolo $\mathcal{B}(n,q)$.
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Osservazione}: Per verificare che a tutti gli effetti tale funzione $q(x)$ sia una densità, bisognerebbe dimostrare le due proprietà precedentemente esposte:
\begin{enumerate}
  \item $q=0$ tranne che su una quantità al più numerabile di punti (che è ovvio per la costruzione di $q(x)$);
  \item $\displaystyle{\sum_{x \in \mathbb{R}} q(x)=1}$
\end{enumerate}
che sono certamente verificate e lo si può dimostrare per induzione.

\vspace{1em}
\noindent
\textbf{Esempio}: Si riconsideri lo schema delle prove indipendenti, per un numero $n$ di ripetizioni ognuna con probabilità $q$ di successo. Lo spazio di probabilità discreto, in questo caso, è
\[\Omega = \{0,1\}^n\]
per cui allo $0$ si associa l'insuccesso, mentre a $1$ il successo. La probabilità $p$, invece, è determinata da
\[p(\{\omega\})=q^{\displaystyle{\sum_{i=1}^n \omega_i}} \cdot (1-q)^{\displaystyle{n-\sum_{i=1}^n \omega_i}} \hspace{1em} \forall \omega \in \Omega\]
con $\omega_i$ la componente $i$-esima di $\omega$. Sarà, ora, sufficiente definire la mappa $\mathcal{X} : \Omega \longrightarrow \mathbb{R}$ tramite
\[\mathcal{X}(\omega) = \sum_{i=1}^n \omega_i = \left\{\text{ quante volte compare } 1 \text{ nella }n\text{-upla } \omega \right\}\]
cioé $\mathcal{X}$ conta in un evento elementare $\omega$. Taluna, inoltre, è sicuramente una variabile aleatoria (siccome si sta operando su uno spazio di probabilità discreto in cui la $\sigma$-algebra $\mathcal{A}$ è data da tutti i sottoinsiemi di $\Omega$).\\
Per determinare la densità di $\mathcal{X}$, si osserva che dato $x \in \mathbb{R}$
\[\{\mathcal{X}=x\}= \left\{\omega \in \Omega : \sum_{i=1}^n \omega_i = x \right\}\]
cioè l'evento costituito dalle $n$-uple avventi come somma delle componenti $x$. Dal momento che $\omega$ ha componenti che sono $0$ oppure $1$, $\{\mathcal{X}=x\}$ sarà non vuoto solamente quando $x$ è un intero compreso tra $0$ ed $n$, per cui rientra nella definizione fornita:
\[
  q(x) = \left\{
  \rowcolors{1}{white}{white}
  \begin{array}{ll}
    \displaystyle{\binom{n}{x} \cdot q^x \cdot (1-q)^{n-x}} & x=0,1,...,n\\
    0 & \text{altrimenti}
  \end{array}
  \right.
\]
Fissato $k \in [0,1,...,n]$, ognuno degli eventi elementari $\omega \in \{\mathcal{X}=k\}$ ha probabilità
\[p(\{\omega\})=q^{\displaystyle{\sum_{i=1}^n \omega_i}} \cdot (1-q)^{\displaystyle{n-\sum_{i=1}^n \omega_i}} = q^k \cdot (1-q)^{n-k}\]
dal momento che, essendo $\omega \in \{\mathcal{X}=k\}$, il numero di $1$ presenti nella $n$-upla è proprio dato da
\[k=\sum_{i=1}^n \omega_i\]
Inoltre è noto che il numero totale degli elementi in $\{\mathcal{X}=k\}$ è pari alle combinazioni semplici di classe $k$ su $n$ oggetti: è sufficiente, infatti, decidere all'interno della $n$-upla dove collocare $k$ \quotes{$1$} (ed $n-k$ \quotes{$0$}). Si è, quindi, ottenuto che
\[\left \vert \{\mathcal{X}=k\}\right \vert=\binom{n}{k} \hspace{1em} \text{e} \hspace{1em} p \left(\{\mathcal{X}=k\}\right)=\binom{n}{k}q^k(1-q)^{n-k}\]
che è un risultato già ottenuto in precedenza, trattando dello schema delle prove indipendenti.

\vspace{1em}
\noindent
\textbf{Osservazione}: È stato dunque provato che $p\{\mathcal{X}=x\}=q(x), \forall x \in \mathbb{R}$.\\
È interessante, inoltre, osservare che il significato della distribuzione $p_{\mathcal{X}}$ associata ad $\mathcal{X}$ sta proprio nella probabilità di ottenere successo nelle operazioni sperimentali: dato un range di valori $B \subset \mathbb{R}$, si ha che $p_{\mathcal{X}}(B)=p\left(\{\mathcal{X}\in B\}\right)$ è proprio la probabilità di ottenere esperimenti con un numero di successi nel range di $B$.

\vspace{1em}
\noindent
\textbf{Esempio}: I bulloni prodotti da una ditta rissultano difettosi con probabilità del $20 \%$ e vengono messi in commercio in confesioni da $3$ pezzi ciascuna. Si determini, allora, la probabilità che in una confezione vi sia al più un bullone difettoso.\\
Supponendo che l'essere uno dei bulloni difettosi sia indipendente dal fatto che lo siano gli altri, è possibile inquadrare il problema nello schema delle prove ripetute. Precisamente, tre prove in cui il successo significa bullone a norma ed insuccesso bullone difettoso. La variabile aleatoria che si adopererà è quella appena introdottoa, cioè $\mathcal{X} : \Omega \longrightarrow \mathbb{R}$ definita da
\[\mathcal{X}(\omega)=\sum_{i=1}^3 \omega_i\]
Dal momento che viene richiesto che vi siano almeno due bulloni a norma nella confezione, si sta considerando il range $B=[2,+\infty)$. Ovviamente, però, è noto che $q(x)=0$ quando $x \neq 0,1,2,3$, per cui il range effetivo diviene $B=[2,3]$. Inoltre, la probabilitù che il singolo bullone sia a norma è, ovviamente $20\%=\frac{4}{5}$, quindi
\[p_{\mathcal{X}}(B) = p \left(\{\mathcal{X}\in B\}\right) = \sum_{x \in B} q(x)=q(2)+q(3)\]
ciò, naturalment, corrisponde a
\[\underbrace{\binom{3}{2} \cdot \left(\frac{4}{5}\right)^2 \cdot \left(1-\frac{4}{5}\right)^1}_{k=2} + \underbrace{\binom{3}{2} \cdot \left(\frac{4}{5}\right)^3 \cdot \left(1-\frac{4}{5}\right)^0}_{k=3}=0.896\]
in quanto la densità $q(x)$ di $\mathcal{X}$ è la densità binomiale $\displaystyle{\mathcal{B} \left(3,\frac{4}{5}\right)}$.

\newpage
\begin{center}
  7 aprile 2022
\end{center}
La densità di una variabile aleatoria è l'elemento fondamentale per determinare la probabilità associata ad un particolare evento assunto da una variabile aleatoria.

\vspace{1em}
\subsection{Densità ipergeometrica}
Di seguito si espone la definizione di \textbf{densità ipergeometrica}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{DENSITÀ IPERGEOMETRICA}}\\
    \parbox{\linewidth}{Siano $a$, $b$, $n$ tre numeri interi strettamente positivi tali che $n \leq a+b$. Si ponga
    \[k_1=\text{max}(n-b,0) \hspace{1em} \text{e} \hspace{1em} k_2=\text{min}(a,n)\]
    in cui, chiaramente, $k_1 \leq k_2$. Si chiama, allora, \textbf{densità ipergeometrica} di parametri $a$, $b$, $n$ la funzione così definita
    \[
      q(x) = \left\{
      \begin{array}{ll}
        \dfrac{\displaystyle{\binom{a}{x}\binom{b}{n-x}}}{\displaystyle{\binom{a+b}{n}}} & x=k_1,k_1+1,...,k_2\\
        0 & \text{altrimenti}
      \end{array}
      \right.
    \]
    che spesso viene indicata con il simbolo IPER($n$,$a$,$b$).
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che $x \geq k_1$ implica che $x \geq 0$ ed $n-x \leq b$, mentre $x \leq k_2$ implica $x \leq a$ ed $n-x \geq 0$. Quindi i coefficienti binomiali hanno senso e sono non nulli.\\
È possibile, inoltre, dimostrare tramite \textbf{induzione} che
\[\sum_{x \in \mathbb{R}} q(x) = 1\]

\vspace{1em}
\noindent
\textbf{Esempio}: Si supponga, ancora una volta, di disporre di un'urna con $N$ palline di due colori: $M$ bianche ed $N-M$ nere. Si supponga di effettuare $n$ estrazioni sucessive senza reimmissione.\\
È noto che lo spazio da considerare al fine di moddellizzare tale situazione è
\[\Omega = \{\text{combinazione di classe } n \text{ su } N \text{ oggetti}\}\]
numerando le palline ed identificando ogni possibile combinaizone, ed assegnando la probabilità uniforme:
\[p \left(\{\omega\}\right) = \frac{1}{\vert \Omega \vert} = \frac{1}{\displaystyle{\binom{N}{n}}} \hspace{1em} \forall \omega \in \Omega\]
Si consideri, ora, la variabile aleatoria $\mathcal{X} : \Omega \longrightarrow \mathbb{R}$ definita da
\[\mathcal{X}(\omega) = \text{ numero di palline bianche estratte}\]
È immediato osservare che $\mathcal{X}$ assume valori interi e taluni sono minori di $k_2= \text{min}\{n,M\}$ (in quanto le palline bianche estratte non possono essere più delle palline bianche totali) e maggiori di $k_1=\text{max}\{0,n-(N-M)\}$ (in quanto le palline nere estratte non possono essere più delle palline nere totali, e quindi quelle bianche estratte non possono essere meno di $n-(N-M)$).\\
Calcolando, ora, la densità di $\mathcal{X}$, si ottiene che $\{\mathcal{X=x}\}$ è non vuoto solo se $x$ è un intero $k \in [k_1,k_2]$ per quanto visto in precedenza.\\
L'evento $\{\mathcal{X}=k\}$ corrisponde alla situazione in cui $k$ palline estratte sono bianche. Ne è stata già calcolato in precedenza la probabilità:
\[p \left(\{\mathcal{X}=k\}\right)=\dfrac{\displaystyle{\binom{N}{k}\binom{N-M}{n-k}}}{\displaystyle{\binom{N}{n}}}\]
quindi la densità di $\mathcal{X}$ è di tipo ipergeometrico con parametri $a=M$, $b=N-M$, $n$.

\vspace{1em}
\subsection{Densità}
Si consideri l'esempio seguente:

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri uno schema di $n$ prove indipendenti, ognuna avente probabilità di successo $q$. Lo spazio di probabà discreto è
\[\Omega=\{0,1\}^n \text{ con probabilità } p(\{\omega\}) = q^{\sum_{i=1}^n \omega_i} \cdot (1-q)^{n-\sum_{i=1}^n \omega_i}\]
Già in precedenza era stata valutata la probabilità dei due eventi
\[A_k := \text{\quotes{ esattamente k prove hanno successo }} = \{\omega \in \Omega : \sum_{i=1}^n \omega_i = k\}\]
\[B_j := \text{\quotes{ il primo successo si verifica alla j-esima prova }} = \{\omega \in \Omega : \omega_i = 0 \hspace{1em} \text{con} i < j \hspace{1em} \text{e} \hspace{1em} \omega_j=1\}\]











\end{document}
